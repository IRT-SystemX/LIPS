{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to create an augmented simulator and how to train it. \n",
    "\n",
    "As always on these notebooks, we use the `Benchmark1` to demonstrate how to perform this task.\n",
    "\n",
    "On the first section, we explain how to use a model that is already available on this reposotiry. The second section is dedicated to the explanation of what is needed to create a different kind of `AugmentedSimulator` with a different Neural Network archiecture with a customized loss etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the benchmark dataset\n",
    "\n",
    "As always the first step is always to load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lips.neurips_benchmark import NeuripsBenchmark1\n",
    "path_benchmark = os.path.join(\"reference_data\")\n",
    "neurips_benchmark1 = NeuripsBenchmark1(path_benchmark=path_benchmark,\n",
    "                                       load_data_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an available model\n",
    "\n",
    "In this section we explain how to tune an available model. We take the example of the `FullyConnectedAS` that is an available fully connected neural network.\n",
    "\n",
    "This section supposes that you already have a \"model\" (for example based on neural networks) that meets the `AugmentedSimulator` interface. If you do not have it already, the next section will cover the main principles.\n",
    "\n",
    "**NB** The creation of the 'augmented_simulator' depends on each type of 'augmented_simulator'. \n",
    "\n",
    "The first step is to create the class you want to use, with the meta parameters you want to test. For this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = os.path.join(\"trained_models\")\n",
    "if not os.path.exists(path_save):\n",
    "    os.mkdir(path_save)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import FullyConnectedAS\n",
    "\n",
    "# the three lines bellow might be familiar to the tensorflow users. They tell tensorflow to not take all\n",
    "# the GPU video RAM for the model.\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for el in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(el, True)\n",
    "\n",
    "my_simulator = FullyConnectedAS(name=\"test_FullyConnectedAS\",\n",
    "                                # `attr_x` represents the variables of the dataset you want to use to predict \n",
    "                                # the output.\n",
    "                                attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\", \"line_status\", \"topo_vect\"),\n",
    "                                # `attr_y` represents the variables of the dataset you want to predict\n",
    "                                # we predict everything needed, you can try to change them if you want, add some \n",
    "                                # others etc.\n",
    "                                attr_y=(\"a_or\", \"a_ex\"),\n",
    "                                # `sizes_layer` represents the size of each hidden layer in the neural network. The number\n",
    "                                # of layers is determined by the length of this list, for example\n",
    "                                sizes_layer=(300, 300, 300, 300),\n",
    "                                # `lr` is the learning rate\n",
    "                                lr=3e-4, \n",
    "                                # `layer` is the type of keras layer you want to use. We don't recommend to \n",
    "                                # change it\n",
    "                                layer=Dense,\n",
    "                                # `layer_act` is the activation function you want to use after each layer\n",
    "                                layer_act=\"relu\",\n",
    "                                # `loss` is the training loss\n",
    "                                loss=\"mse\",  # loss used to train the model\n",
    "                                # `batch_size` is the size of the batch for training\n",
    "                                batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to train it. For example here we will train it for 200 epochs.\n",
    "\n",
    "**NB** You are responsible to use the correct dataset for training your model ! You can make experiments by training on the `test` set or on the `test_ood_topo` set if you want but we don't recommend you do to so !\n",
    "\n",
    "**NB** This code is generic and should work for all `AugementedSimulator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator.train(nb_iter=200,\n",
    "                   train_dataset=neurips_benchmark1.train_dataset,\n",
    "                   val_dataset=neurips_benchmark1.val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator.save(path_save)\n",
    "my_simulator.save_metadata(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate the augmented simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or evaluate it on the test dataset as in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A log file including some verifications is created at root directory with the name logs.log\n"
     ]
    }
   ],
   "source": [
    "metrics_per_dataset = neurips_benchmark1.evaluate_augmented_simulator(my_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once saved, if you want to reuse it you can do exactly as we did in the previous notebook:\n",
    "```python\n",
    "relaoded_simulator = FullyConnectedAS(name=\"test_FullyConnectedAS\")  # the name should match! The other things are loaded from the directory\n",
    "relaoded_simulator.load_metadata(path_baselines)\n",
    "relaoded_simulator.init()\n",
    "relaoded_simulator.restore(path_baselines)\n",
    "```\n",
    "\n",
    "And you are good to go !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAP nets\n",
    "The leap nets allows to take into account the topology in the latent space, and have a more robust generalization performance than a simple fully connected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = os.path.join(\"trained_models\")\n",
    "if not os.path.exists(path_save):\n",
    "    os.mkdir(path_save)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import LeapNetAS\n",
    "\n",
    "# the three lines bellow might be familiar to the tensorflow users. They tell tensorflow to not take all\n",
    "# the GPU video RAM for the model.\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for el in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(el, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "leapNet = LeapNetAS(name=\"test_leapNetAS\",\n",
    "                    # `attr_x` represents the variables of the dataset you want to use to predict \n",
    "                    # the output.\n",
    "                    attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    # `attr_y` represents the variables of the dataset you want to predict\n",
    "                    # we predict everything needed, you can try to change them if you want, add some \n",
    "                    # others etc.\n",
    "                    attr_y=(\"a_or\", \"a_ex\"),\n",
    "                    # `lr` is the learning rate\n",
    "                    lr=3e-4, \n",
    "                    # `layer` is the type of keras layer you want to use. We don't recommend to \n",
    "                    # change it\n",
    "                    layer=Dense,\n",
    "                    # `layer_act` is the activation function you want to use after each layer\n",
    "                    layer_act=\"relu\",\n",
    "                    # `loss` is the training loss\n",
    "                    loss=\"mse\",  # loss used to train the model\n",
    "                    # `batch_size` is the size of the batch for training\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator.train(nb_iter=200,\n",
    "                   train_dataset=neurips_benchmark1.train_dataset,\n",
    "                   val_dataset=neurips_benchmark1.val_dataset\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_dataset = neurips_benchmark1.evaluate_augmented_simulator(my_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code another type of \"augmented_simulator\"\n",
    "\n",
    "We provide only a single type of augmented simulator as of now. More baselines will be added with, we hope the growth of the community.\n",
    "\n",
    "Coding another type of \"augmented simulator\" is not difficult. Finding one that work well for all the criteria is of course a different challenge.\n",
    "\n",
    "Basically, an augmented simulator should:\n",
    "\n",
    "- inherit from `AugmentedSimulator`\n",
    "- implements the methods `save_metadata` and `load_metadata`\n",
    "- implements the methods `save` and `restore`\n",
    "- implements the method `init` that can for example, create the neural network from its meta parameters\n",
    "- implements the method `train` that will train the augmented simulator for a given number of steps (it is not mandatory to make such function, some `AugmentedSimulator` might not require any training at all)\n",
    "- implements the method `predict` method that will make some predictions and return a dictionnary containing the predictions for all variable types.\n",
    "\n",
    "More information is given on the documentation. And a fully working example is given in the `FullyConnectedAS` class.\n",
    "\n",
    "This is it, nothing more is required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RTE",
   "language": "python",
   "name": "rte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

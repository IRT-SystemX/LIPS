{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baselines (Power Grid use case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate how we can evaluate the results of a baseline on a given benchmark.\n",
    "\n",
    "It will be split into two part. The first part will focus on the evaluation of a baseline that does not requires any training (the `DCApproximatrionAC`). On the second part, we will show how to load a baseline (or any other `AugmentedSimulator`) and evaluate it on a `Benchmark` of our choice.\n",
    "\n",
    "As for the first notebook, we demonstrate this capability for the case of `NeuripsBenchmark1`.\n",
    "\n",
    "**NB** This notebook supposes that the data for the benchmark are already available. If they are not, please generate them or download them.\n",
    "\n",
    "**NB** The `DCApproximatrionAC` baseline requires the `grid2op` python package.\n",
    "\n",
    "**To learn more about the training procedure, visit the next notebook [$\\rightarrow$](./03_TrainAnAugmentedSimulator.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- [Evaluation on Benchmark1](#benchmark1)\n",
    "  - [DC approximation](#bench1-dc)\n",
    "  - [Trained simulator](#bench1-fc)\n",
    "  - [Comparison](#bench1-comp)\n",
    "- [Evaluation on Benchmark2](#benchmark2)\n",
    "  - [DC approximation](#bench2-dc)\n",
    "  - [Trained simulator](#bench2-fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pprint import pprint\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from lips.utils import get_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Benchmark1 <a id=\"benchmark1\"></a>\n",
    "Benchmark1 for power grid use case concerns the risk identification (security analysis). For more details concerning the benchmark scenario, refer to `Notebook 01`, or also to our article and the LIPS documentation available [here](https://lips.readthedocs.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial step: load the dataset\n",
    "\n",
    "A common dataset will be used for evaluate the two augmented simulator. This initial step aims at loading it once and for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 18:56:17.545232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-01 18:56:17.545301: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark name:  Benchmark1\n",
      "Environment name:  l2rpn_case14_sandbox\n",
      "Output attributes:  ('a_or', 'a_ex')\n",
      "Evaluation criteria: \n",
      "{'IndRed': ['TIME_INF'],\n",
      " 'ML': ['MSE_avg', 'MAE_avg', 'mape_avg', 'mape_90_avg', 'TIME_INF'],\n",
      " 'OOD': ['MSE_avg', 'MAE_avg', 'mape_avg', 'mape_90_avg', 'TIME_INF'],\n",
      " 'Physics': ['CURRENT_POS']}\n"
     ]
    }
   ],
   "source": [
    "# to verify the config is loaded appropriately for this benchmark\n",
    "print(\"Benchmark name: \", benchmark1.config.section_name)\n",
    "print(\"Environment name: \", benchmark1.config.get_option(\"env_name\"))\n",
    "print(\"Output attributes: \", benchmark1.config.get_option(\"attr_y\"))\n",
    "print(\"Evaluation criteria: \")\n",
    "pprint(benchmark1.config.get_option(\"eval_dict\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DC approximation <a id=\"bench1-dc\"></a>\n",
    "\n",
    "We remind that the `grid2op` library is required for this part. You can install it with `pip install grid2op` if you do not have it already.\n",
    "\n",
    "First we will create the \"augmented simulator\". As opposed to the second model we will expose here, this method require access to a powergrid. This is one of the reason we need grid2op. \n",
    "\n",
    "The way to load each `AugmentedSimulator` is specific. Here for example we load the DCApproximation that will use the same powergrid as the one used to generate the data in the previous Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next few lines are specific for each benchmark and each `AugmentedSimulator`\n",
    "import grid2op\n",
    "import warnings\n",
    "from lips.physical_simulator.dcApproximationAS import DCApproximationAS\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    env = grid2op.make(benchmark1.config.get_option(\"env_name\"), test=True)\n",
    "    grid_path = pathlib.Path(env.get_path_env()) / \"grid.json\"\n",
    "\n",
    "dc_sim = DCApproximationAS(name=\"dc_approximation\", \n",
    "                           benchmark_name=\"Benchmark1\",\n",
    "                           config_path=BENCH_CONFIG_PATH,\n",
    "                           grid_path=grid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is loaded, there is a common interface to evaluate its performance, on a dataset. This is showed in the cell bellow where we evaluate a physics based simulator `DCApproximation` on these two dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate dc: 100%|█████████████████████████████████████████████████████| 10000/10000 [03:23<00:00, 49.26it/s]\n",
      "evaluate dc: 100%|█████████████████████████████████████████████████████| 10000/10000 [03:21<00:00, 49.59it/s]\n",
      "evaluate dc: 100%|█████████████████████████████████████████████████████| 10000/10000 [03:18<00:00, 50.36it/s]\n"
     ]
    }
   ],
   "source": [
    "EVAL_SAVE_PATH = get_path(EVALUATION_PATH, benchmark1)\n",
    "dc_metrics_per_dataset = benchmark1.evaluate_simulator(augmented_simulator=dc_sim,\n",
    "                                                       dataset=\"all\", # other values : \"val\", \"test\", \"test_ood_topo\"\n",
    "                                                       save_path=EVAL_SAVE_PATH,\n",
    "                                                       save_predictions=True\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the evaluation terminated, we can analyze the evaluation criteria in more details. We have analyzed the peformance wrt. four evaluation criteria categories which are:\n",
    "\n",
    "- `ML`: Machine learning related metrics (computing the accuracy of augmented simulators);\n",
    "- `Physics`: physics compliances which verify the physics laws (equations) on the predictions of an augmented simulator;\n",
    "- `IndRed`: Industrial Readiness which verifies whether the proposed augmented simulators could be exploited in industriy;\n",
    "- `OOD`: which verifies the out-of-distribution generalization capacity of the augmented simulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-related performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.1408511172541828\n",
      "MAPE90 for a_ex:  0.13240412951825123\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", dc_metrics_per_dataset[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", dc_metrics_per_dataset[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.1608534769924919\n",
      "MAPE90 for a_ex:  0.149238631980091\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", dc_metrics_per_dataset[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", dc_metrics_per_dataset[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics compliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CURRENT_POS'])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_metrics_per_dataset[\"test\"][\"Physics\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : when there is no violation, create although the key and force it to take value zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: {}\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", dc_metrics_per_dataset[\"test\"][\"Physics\"][\"CURRENT_POS\"])#[\"a_or\"][\"Violation_proportion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: {}\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", dc_metrics_per_dataset[\"test_ood_topo\"][\"Physics\"][\"CURRENT_POS\"])#[\"a_or\"][\"Violation_proportion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it is possible to study the metrics on the different dataset. For example, if we want the \"MSE\" error on the \"test\" dataset (with a similar distribution as the training one):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A learned baseline \"augmented simulator\" <a id=\"bench1-fc\"></a>\n",
    "\n",
    "Along with some dataset, we provide also some baseline (from a trained neural network). This baseline is made of a fully connected neural network that takes the available input of the powergrid and tries to predict all the output of the simulator.\n",
    "\n",
    "The fully connected neural network is made of XXX layer each with YYY units.\n",
    "\n",
    "It is learned for KKK epochs on the training set of the `Benchmark1`.\n",
    "\n",
    "**NB** These baselines are not yet fully trained, and some hyper parameters still need to be optimized. We intend on doing that before the official release of the benchmark for the Neurips conference.\n",
    "\n",
    "First we need to load the baseline and initialize it properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "# rebuild the baseline architecture\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)\n",
    "\n",
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as for the DC approximation, we can evaluate it on the test datasets of the benchmark.\n",
    "\n",
    "This is done with the same command, by indicating the learned augmented simulator `tf_fc` as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: log the losses\n",
    "# EVAL_SAVE_PATH = get_path(EVALUATION_PATH, benchmark1)\n",
    "tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                              eval_batch_size=10000,\n",
    "                                              dataset=\"all\",\n",
    "                                              shuffle=False,\n",
    "                                              save_path=None,\n",
    "                                              save_predictions=False\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of two augmented simulator <a id=\"bench1-comp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can compare the two \"augmented simulators\". For example, if we want to compare the MAPE90 (mean absolute percentage error compute for last 10% quantile) on the test dataset (with a distribution similar to the training distribution) for currents (A) at two extremity of power lines, we might compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC Approximation\n",
      "Dataset : test\n",
      "MAPE90     : {'a_or': 0.2054102762347278, 'a_ex': 0.18943869874874716}\n",
      "MSE_avg    : {'a_or': 91723.53006148033, 'a_ex': 131732.91079220167}\n",
      "MAE_avg    : {'a_or': 114.3059446624192, 'a_ex': 143.16579138645758}\n",
      "Dataset : test_ood_topo\n",
      "mape_90_avg : {'a_or': 0.2227085624215881, 'a_ex': 0.20711185760666956}\n",
      "MSE_avg    : {'a_or': 107658.54513807358, 'a_ex': 155649.85692985042}\n",
      "MAE_avg    : {'a_or': 123.67567242785628, 'a_ex': 155.63737545351296}\n"
     ]
    }
   ],
   "source": [
    "ML_metrics = \"ML\"\n",
    "dataset_name = \"test\"\n",
    "print(\"DC Approximation\")\n",
    "print(f\"Dataset : {dataset_name}\")\n",
    "print(\"{:<10} : {}\".format(\"MAPE90\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"mape_90_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MSE_avg\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"MSE_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MAE_avg\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"MAE_avg\"]))\n",
    "dataset_name = \"test_ood_topo\"\n",
    "print(f\"Dataset : {dataset_name}\")\n",
    "print(\"{:<10} : {}\".format(\"mape_90_avg\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"mape_90_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MSE_avg\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"MSE_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MAE_avg\", dc_metrics_per_dataset[dataset_name][ML_metrics][\"MAE_avg\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Connected Augmented Simulator\n",
      "Dataset : test\n",
      "mape_90_avg : {'a_or': 0.005971284397153569, 'a_ex': 0.005959986222812791}\n",
      "MSE_avg    : {'a_or': 21.65915870666504, 'a_ex': 44.23374557495117}\n",
      "MAE_avg    : {'a_or': 2.7974419593811035, 'a_ex': 3.8893446922302246}\n",
      "Dataset : test_ood_topo\n",
      "mape_90_avg : {'a_or': 0.17957805279569528, 'a_ex': 0.17880120699511942}\n",
      "MSE_avg    : {'a_or': 12364.6455078125, 'a_ex': 23608.12109375}\n",
      "MAE_avg    : {'a_or': 52.66007614135742, 'a_ex': 74.55868530273438}\n"
     ]
    }
   ],
   "source": [
    "ML_metrics = \"ML\"\n",
    "dataset_name = \"test\"\n",
    "print(\"Fully Connected Augmented Simulator\")\n",
    "print(f\"Dataset : {dataset_name}\")\n",
    "print(\"{:<10} : {}\".format(\"mape_90_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"mape_90_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MSE_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"MSE_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MAE_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"MAE_avg\"]))\n",
    "dataset_name = \"test_ood_topo\"\n",
    "print(f\"Dataset : {dataset_name}\")\n",
    "print(\"{:<10} : {}\".format(\"mape_90_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"mape_90_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MSE_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"MSE_avg\"]))\n",
    "print(\"{:<10} : {}\".format(\"MAE_avg\", tf_fc_metrics[dataset_name][ML_metrics][\"MAE_avg\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physic compliance\n",
    "In comparison to DC approximation, which is by nature respects most of the physical laws, a trained augmented simulator could make some errors when verifying physics compliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23% of currents at the origin side of power lines violate the current positivity.\n"
     ]
    }
   ],
   "source": [
    "physic_compliances = \"Physics\"\n",
    "dataset_name = \"test\"\n",
    "current_violation = tf_fc_metrics[dataset_name][physic_compliances][\"CURRENT_POS\"][\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"{:.2f}% of currents at the origin side of power lines violate the current positivity.\".format(current_violation*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of negative current values (Amp) : 0.02\n"
     ]
    }
   ],
   "source": [
    "current_error = tf_fc_metrics[dataset_name][physic_compliances][\"CURRENT_POS\"][\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"The sum of negative current values (Amp) : {:.2f}\".format(current_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industrial readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033661603927612305"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"test\"\n",
    "tf_fc_metrics[dataset_name][\"IndRed\"][\"TIME_INF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the computation time required by physical solvers, there is another notebook which analyzes in more details all the required steps and their computation time. In the power grid context, the security analysis (Benchmark1) could be computed in parallel and physical solvers (namely DC approximation) could compute the electricity flow very fast. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark2 <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark name:  Benchmark2\n",
      "Environment name:  l2rpn_case14_sandbox\n",
      "Output attributes:  ('a_or', 'a_ex', 'p_or', 'p_ex', 'v_or', 'v_ex')\n",
      "Evaluation criteria: \n",
      "{'IndRed': ['TIME_INF'],\n",
      " 'ML': ['MSE_avg', 'MAE_avg', 'mape_avg', 'mape_90_avg', 'TIME_INF'],\n",
      " 'OOD': ['MSE_avg', 'MAE_avg', 'mape_avg', 'mape_90_avg', 'TIME_INF'],\n",
      " 'Physics': ['CURRENT_POS',\n",
      "             'VOLTAGE_POS',\n",
      "             'LOSS_POS',\n",
      "             'DISC_LINES',\n",
      "             'CHECK_LOSS',\n",
      "             'CHECK_GC',\n",
      "             'CHECK_LC',\n",
      "             'CHECK_VOLTAGE_EQ']}\n"
     ]
    }
   ],
   "source": [
    "# to verify the config is loaded appropriately for this benchmark\n",
    "print(\"Benchmark name: \", benchmark2.config.section_name)\n",
    "print(\"Environment name: \", benchmark2.config.get_option(\"env_name\"))\n",
    "print(\"Output attributes: \", benchmark2.config.get_option(\"attr_y\"))\n",
    "print(\"Evaluation criteria: \")\n",
    "pprint(benchmark2.config.get_option(\"eval_dict\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DC approximation <a id=\"bench2-dc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next few lines are specific for each benchmark and each `AugmentedSimulator`\n",
    "import grid2op\n",
    "import warnings\n",
    "from lips.physical_simulator.dcApproximationAS import DCApproximationAS\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    env = grid2op.make(benchmark2.config.get_option(\"env_name\"), test=True)\n",
    "    grid_path = pathlib.Path(env.get_path_env()) / \"grid.json\"\n",
    "\n",
    "dc_sim = DCApproximationAS(name=\"dc_approximation\", \n",
    "                           benchmark_name=\"Benchmark2\",\n",
    "                           config_path=BENCH_CONFIG_PATH,\n",
    "                           grid_path=grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SAVE_PATH = get_path(EVALUATION_PATH, benchmark2)\n",
    "dc_metrics_per_dataset_bench2 = benchmark2.evaluate_simulator(augmented_simulator=dc_sim,\n",
    "                                                              dataset=\"all\", # other values : \"val\", \"test\", \"test_ood_topo\"\n",
    "                                                              save_path=EVAL_SAVE_PATH,\n",
    "                                                              save_predictions=True\n",
    "                                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-related performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.1575609916428136\n",
      "MAPE90 for a_ex:  0.14730832052856613\n",
      "MAPE for p_or:  0.0921423999325571\n",
      "MAPE for p_ex:  0.08787188867809301\n",
      "MAE for p_or:  1.140607839753558\n",
      "MAE for p_ex:  1.026569282669907\n",
      "MAPE for v_or:  0.020920751203534725\n",
      "MAPE for v_ex:  0.033166301338939726\n",
      "MAE for v_or:  0.6651214754772188\n",
      "MAE for v_ex:  0.9825881892442705\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])\n",
    "print(\"MAPE for p_or: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_avg\"][\"p_or\"])\n",
    "print(\"MAPE for p_ex: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_avg\"][\"p_ex\"])\n",
    "print(\"MAE for p_or: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"MAE_avg\"][\"p_or\"])\n",
    "print(\"MAE for p_ex: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"MAE_avg\"][\"p_ex\"])\n",
    "print(\"MAPE for v_or: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_avg\"][\"v_or\"])\n",
    "print(\"MAPE for v_ex: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"mape_avg\"][\"v_ex\"])\n",
    "print(\"MAE for v_or: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"MAE_avg\"][\"v_or\"])\n",
    "print(\"MAE for v_ex: \", dc_metrics_per_dataset_bench2[\"test\"][\"ML\"][\"MAE_avg\"][\"v_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.16061949592695715\n",
      "MAPE90 for a_ex:  0.15209429645818998\n",
      "MAPE for p_or:  0.08811211862205569\n",
      "MAPE for p_ex:  0.08532031022804058\n",
      "MAE for p_or:  1.1736193180608905\n",
      "MAE for p_ex:  1.0713623671817072\n",
      "MAPE for v_or:  0.021399578333099696\n",
      "MAPE for v_ex:  0.03433434072231821\n",
      "MAE for v_or:  0.7879805879878998\n",
      "MAE for v_ex:  1.119801747493744\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])\n",
    "print(\"MAPE for p_or: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"p_or\"])\n",
    "print(\"MAPE for p_ex: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"p_ex\"])\n",
    "print(\"MAE for p_or: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"p_or\"])\n",
    "print(\"MAE for p_ex: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"p_ex\"])\n",
    "print(\"MAPE for v_or: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"v_or\"])\n",
    "print(\"MAPE for v_ex: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"v_ex\"])\n",
    "print(\"MAE for v_or: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"v_or\"])\n",
    "print(\"MAE for v_ex: \", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"v_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics compliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CURRENT_POS', 'VOLTAGE_POS', 'LOSS_POS', 'DISC_LINES', 'CHECK_LOSS', 'CHECK_GC', 'CHECK_LC', 'CHECK_VOLTAGE_EQ'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : when there is no violation, create although the key and force it to take value zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: {}\n",
      "2) Voltage positivity violation: {}\n",
      "3) Loss positivity violation: {}\n",
      "4) Disconnected lines violation: {}\n",
      "5) Violation of loss to be between [1,4]% of production: 0.0\n",
      "6) Violation of global conservation: 100.0% and its weighted mape: 0.9999998971074707\n",
      "7) Violation of local conservation: 7.142857142857142% and its weighted mape: 0.01564590303591114\n",
      "8) Violation proportion of voltage equality at subs: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CURRENT_POS\"])#[\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"2) Voltage positivity violation:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"VOLTAGE_POS\"])\n",
    "print(\"3) Loss positivity violation:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"LOSS_POS\"])\n",
    "print(\"4) Disconnected lines violation:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"DISC_LINES\"])\n",
    "print(\"5) Violation of loss to be between [1,4]% of production:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_LOSS\"][\"violation_percentage\"])\n",
    "print(\"6) Violation of global conservation: {}% and its weighted mape: {}\".format(dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_GC\"][\"violation_percentage\"], dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_GC\"][\"wmape\"]))\n",
    "print(\"7) Violation of local conservation: {}% and its weighted mape: {}\".format(dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_LC\"][\"violation_percentage\"], dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_LC\"][\"mape\"]))\n",
    "print(\"8) Violation proportion of voltage equality at subs:\", dc_metrics_per_dataset_bench2[\"test\"][\"Physics\"][\"CHECK_VOLTAGE_EQ\"][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: {}\n",
      "2) Voltage positivity violation: {}\n",
      "3) Loss positivity violation: {}\n",
      "4) Disconnected lines violation: {}\n",
      "5) Violation of loss to be between [1,4]% of production: 0.0\n",
      "6) Violation of global conservation: 100.0% and its weighted mape: 1.0000000047503754\n",
      "7) Violation of local conservation: 7.142857142857142% and its weighted mape: 0.017686318493588492\n",
      "8) Violation proportion of voltage equality at subs: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CURRENT_POS\"])#[\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"2) Voltage positivity violation:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"VOLTAGE_POS\"])\n",
    "print(\"3) Loss positivity violation:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"LOSS_POS\"])\n",
    "print(\"4) Disconnected lines violation:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"DISC_LINES\"])\n",
    "print(\"5) Violation of loss to be between [1,4]% of production:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_LOSS\"][\"violation_percentage\"])\n",
    "print(\"6) Violation of global conservation: {}% and its weighted mape: {}\".format(dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_GC\"][\"violation_percentage\"], dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_GC\"][\"wmape\"]))\n",
    "print(\"7) Violation of local conservation: {}% and its weighted mape: {}\".format(dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_LC\"][\"violation_percentage\"], dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_LC\"][\"mape\"]))\n",
    "print(\"8) Violation proportion of voltage equality at subs:\", dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"Physics\"][\"CHECK_VOLTAGE_EQ\"][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industrial Readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time for test dataset: 82.65s\n",
      "Inference time for OOD dataset: 83.23s\n"
     ]
    }
   ],
   "source": [
    "print(f'Inference time for test dataset: {dc_metrics_per_dataset_bench2[\"test\"][\"IndRed\"][\"TIME_INF\"]:.2f}s')\n",
    "print(f'Inference time for OOD dataset: {dc_metrics_per_dataset_bench2[\"test_ood_topo\"][\"IndRed\"][\"TIME_INF\"]:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A learned baseline \"augmented simulator\" <a id=\"bench2-fc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "# rebuild the baseline architecture\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark2\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 10000/10000 [01:35<00:00, 104.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 10000/10000 [01:44<00:00, 95.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 10000/10000 [01:53<00:00, 88.09it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                              eval_batch_size=10000,\n",
    "                                              dataset=\"all\",\n",
    "                                              shuffle=False,\n",
    "                                              save_path=None,\n",
    "                                              save_predictions=False\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-related performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.00553678925446738\n",
      "MAPE90 for a_ex:  0.005456813673975014\n",
      "MAPE for p_or:  0.00862245834005605\n",
      "MAPE for p_ex:  0.008477684781870975\n",
      "MAE for p_or:  0.09964931011199951\n",
      "MAE for p_ex:  0.09761589020490646\n",
      "MAPE for v_or:  0.0008934855407541078\n",
      "MAPE for v_ex:  0.0009033801352338108\n",
      "MAE for v_or:  0.08649304509162903\n",
      "MAE for v_ex:  0.06617464125156403\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])\n",
    "print(\"MAPE for p_or: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_avg\"][\"p_or\"])\n",
    "print(\"MAPE for p_ex: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_avg\"][\"p_ex\"])\n",
    "print(\"MAE for p_or: \", tf_fc_metrics[\"test\"][\"ML\"][\"MAE_avg\"][\"p_or\"])\n",
    "print(\"MAE for p_ex: \", tf_fc_metrics[\"test\"][\"ML\"][\"MAE_avg\"][\"p_ex\"])\n",
    "print(\"MAPE for v_or: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_avg\"][\"v_or\"])\n",
    "print(\"MAPE for v_ex: \", tf_fc_metrics[\"test\"][\"ML\"][\"mape_avg\"][\"v_ex\"])\n",
    "print(\"MAE for v_or: \", tf_fc_metrics[\"test\"][\"ML\"][\"MAE_avg\"][\"v_or\"])\n",
    "print(\"MAE for v_ex: \", tf_fc_metrics[\"test\"][\"ML\"][\"MAE_avg\"][\"v_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90 for a_or:  0.10189347921949823\n",
      "MAPE90 for a_ex:  0.10297622874045956\n",
      "MAPE for p_or:  0.1474770308588949\n",
      "MAPE for p_ex:  0.14722551116875618\n",
      "MAE for p_or:  1.7987455129623413\n",
      "MAE for p_ex:  1.7728211879730225\n",
      "MAPE for v_or:  0.004895506811582385\n",
      "MAPE for v_ex:  0.004960453650383261\n",
      "MAE for v_or:  0.4244811534881592\n",
      "MAE for v_ex:  0.34588271379470825\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90 for a_or: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_or\"])\n",
    "print(\"MAPE90 for a_ex: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_90_avg\"][\"a_ex\"])\n",
    "print(\"MAPE for p_or: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"p_or\"])\n",
    "print(\"MAPE for p_ex: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"p_ex\"])\n",
    "print(\"MAE for p_or: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"p_or\"])\n",
    "print(\"MAE for p_ex: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"p_ex\"])\n",
    "print(\"MAPE for v_or: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"v_or\"])\n",
    "print(\"MAPE for v_ex: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"mape_avg\"][\"v_ex\"])\n",
    "print(\"MAE for v_or: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"v_or\"])\n",
    "print(\"MAE for v_ex: \", tf_fc_metrics[\"test_ood_topo\"][\"ML\"][\"MAE_avg\"][\"v_ex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics compliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: 0.0114725\n",
      "2) Voltage positivity violation: 0.013675\n",
      "3) Loss positivity violation: 0.16484\n",
      "4) Disconnected lines violation: {}\n",
      "5) Violation of loss to be between [1,4]% of production: 0.18\n",
      "6) Violation of global conservation: 99.4% and its weighted mape: 0.027306463569402695\n",
      "7) Violation of local conservation: 89.68071428571427% and its weighted mape: 0.005147016994604063\n",
      "8) Violation proportion of voltage equality at subs: 0.9976333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", (tf_fc_metrics[\"test\"][\"Physics\"][\"CURRENT_POS\"][\"a_or\"][\"Violation_proportion\"]+tf_fc_metrics[\"test\"][\"Physics\"][\"CURRENT_POS\"][\"a_ex\"][\"Violation_proportion\"])/2)#[\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"2) Voltage positivity violation:\", (tf_fc_metrics[\"test\"][\"Physics\"][\"VOLTAGE_POS\"][\"v_or\"][\"Violation_proportion\"]+tf_fc_metrics[\"test\"][\"Physics\"][\"VOLTAGE_POS\"][\"v_ex\"][\"Violation_proportion\"])/2)\n",
    "print(\"3) Loss positivity violation:\", tf_fc_metrics[\"test\"][\"Physics\"][\"LOSS_POS\"][\"violation_proportion\"])\n",
    "print(\"4) Disconnected lines violation:\", tf_fc_metrics[\"test\"][\"Physics\"][\"DISC_LINES\"])\n",
    "print(\"5) Violation of loss to be between [1,4]% of production:\", tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_LOSS\"][\"violation_percentage\"])\n",
    "print(\"6) Violation of global conservation: {}% and its weighted mape: {}\".format(tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_GC\"][\"violation_percentage\"], tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_GC\"][\"wmape\"]))\n",
    "print(\"7) Violation of local conservation: {}% and its weighted mape: {}\".format(tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_LC\"][\"violation_percentage\"], tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_LC\"][\"mape\"]))\n",
    "print(\"8) Violation proportion of voltage equality at subs:\", tf_fc_metrics[\"test\"][\"Physics\"][\"CHECK_VOLTAGE_EQ\"][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOD Generalization Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Current positivity violation: 0.012065\n",
      "2) Voltage positivity violation: 0.013049999999999999\n",
      "3) Loss positivity violation: 0.20383\n",
      "4) Disconnected lines violation: {}\n",
      "5) Violation of loss to be between [1,4]% of production: 0.36\n",
      "6) Violation of global conservation: 99.81% and its weighted mape: 0.1251574009656906\n",
      "7) Violation of local conservation: 97.77785714285714% and its weighted mape: 0.023546348125150923\n",
      "8) Violation proportion of voltage equality at subs: 0.99536875\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Current positivity violation:\", (tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CURRENT_POS\"][\"a_or\"][\"Violation_proportion\"]+tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CURRENT_POS\"][\"a_ex\"][\"Violation_proportion\"])/2)#[\"a_or\"][\"Violation_proportion\"]\n",
    "print(\"2) Voltage positivity violation:\", (tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"VOLTAGE_POS\"][\"v_or\"][\"Violation_proportion\"]+tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"VOLTAGE_POS\"][\"v_ex\"][\"Violation_proportion\"])/2)\n",
    "print(\"3) Loss positivity violation:\", tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"LOSS_POS\"][\"violation_proportion\"])\n",
    "print(\"4) Disconnected lines violation:\", tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"DISC_LINES\"])\n",
    "print(\"5) Violation of loss to be between [1,4]% of production:\", tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_LOSS\"][\"violation_percentage\"])\n",
    "print(\"6) Violation of global conservation: {}% and its weighted mape: {}\".format(tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_GC\"][\"violation_percentage\"], tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_GC\"][\"wmape\"]))\n",
    "print(\"7) Violation of local conservation: {}% and its weighted mape: {}\".format(tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_LC\"][\"violation_percentage\"], tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_LC\"][\"mape\"]))\n",
    "print(\"8) Violation proportion of voltage equality at subs:\", tf_fc_metrics[\"test_ood_topo\"][\"Physics\"][\"CHECK_VOLTAGE_EQ\"][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industrial Readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time for test dataset: 0.33s\n",
      "Inference time for OOD dataset: 0.28s\n"
     ]
    }
   ],
   "source": [
    "print(f'Inference time for test dataset: {tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"]:.2f}s')\n",
    "print(f'Inference time for OOD dataset: {tf_fc_metrics[\"test_ood_topo\"][\"IndRed\"][\"TIME_INF\"]:.2f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips",
   "language": "python",
   "name": "lips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

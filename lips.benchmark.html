<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lips.benchmark package &mdash; LIPS 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lips.config package" href="lips.config.html" />
    <link rel="prev" title="lips.augmented_simulators package" href="lips.augmented_simulators.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> LIPS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">GETTING STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Getting started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TECHNICAL DOCUMENTATION</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lips.augmented_simulators.html">lips.augmented_simulators package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">lips.benchmark package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-lips.benchmark.Benchmark">lips.benchmark.Benchmark module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-lips.benchmark.powergridBenchmark">lips.benchmark.powergridBenchmark module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lips.config.html">lips.config package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.dataset.html">lips.dataset package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.evaluation.html">lips.evaluation package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.logger.html">lips.logger package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.metrics.html">lips.metrics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.neurips_benchmark.html">lips.neurips_benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="lips.physical_simulator.html">lips.physical_simulator package</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GUIDE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="help.html">Help</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">LIPS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>lips.benchmark package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lips.benchmark.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-lips.benchmark">
<span id="lips-benchmark-package"></span><h1>lips.benchmark package<a class="headerlink" href="#module-lips.benchmark" title="Permalink to this headline"></a></h1>
<p><strong>Classes:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#module-lips.benchmark.Benchmark" title="lips.benchmark.Benchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Benchmark</span></code></a>(benchmark_name[, dataset, ...])</p></td>
<td><p>Benchmark Base Class</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#lips.benchmark.PowerGridBenchmark" title="lips.benchmark.PowerGridBenchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PowerGridBenchmark</span></code></a>(benchmark_path[, ...])</p></td>
<td><p>PowerGrid Benchmark class</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lips.benchmark.</span></span><span class="sig-name descname"><span class="pre">Benchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">benchmark_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.dataset.html#lips.dataset.dataSet.DataSet" title="lips.dataset.dataSet.DataSet"><span class="pre">lips.dataset.dataSet.DataSet</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicsSolver.PhysicsSolver" title="lips.physical_simulator.physicsSolver.PhysicsSolver"><span class="pre">lips.physical_simulator.physicsSolver.PhysicsSolver</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.evaluation.html#lips.evaluation.evaluation.Evaluation" title="lips.evaluation.evaluation.Evaluation"><span class="pre">lips.evaluation.evaluation.Evaluation</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/Benchmark.html#Benchmark"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.Benchmark" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Benchmark Base Class</p>
<p>Benchmark class that takes a test dataset, a simulator (physical or augmented) and an
evaluator object and evaluates the simulator on test dataset with respect to required
metrics requested by evaluator</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.benchmark_name">
<span class="sig-name descname"><span class="pre">benchmark_name</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.benchmark_name" title="Permalink to this definition"></a></dt>
<dd><p>a name attributed to the corresponding experiment</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.dataset" title="Permalink to this definition"></a></dt>
<dd><p>an object of <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> class which containing the data for training, validation and testing, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">DataSet</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.augmented_simulator">
<span class="sig-name descname"><span class="pre">augmented_simulator</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.augmented_simulator" title="Permalink to this definition"></a></dt>
<dd><p>This is an object of Physical or Augmneted simulator including the prediction results, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">AugmentedSimulator</span></code>, <code class="docutils literal notranslate"><span class="pre">PhysicsSolver</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.evaluation">
<span class="sig-name descname"><span class="pre">evaluation</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.evaluation" title="Permalink to this definition"></a></dt>
<dd><p>It allows to evaluate the performance of the simulator with respect to various point of views
It should be parameterized before passing to benchmark class to include appropriate metrics
otherwise, it is initialized using an empty dictionary, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="lips.evaluation.html#lips.evaluation.Evaluation" title="lips.evaluation.Evaluation">Evaluation</a>, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.benchmark_path">
<span class="sig-name descname"><span class="pre">benchmark_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.benchmark_path" title="Permalink to this definition"></a></dt>
<dd><p>the path used to save the benchmark results, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.log_path">
<span class="sig-name descname"><span class="pre">log_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.log_path" title="Permalink to this definition"></a></dt>
<dd><p>the path of logger, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.config_path">
<span class="sig-name descname"><span class="pre">config_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.config_path" title="Permalink to this definition"></a></dt>
<dd><p>the path of config file, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<p><strong>Methods:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.evaluate_simulator">
<em class="property"><span class="pre">abstractmethod</span> </em><span class="sig-name descname"><span class="pre">evaluate_simulator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="lips.dataset.html#lips.dataset.dataSet.DataSet" title="lips.dataset.dataSet.DataSet"><span class="pre">lips.dataset.dataSet.DataSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicalSimulator.PhysicalSimulator" title="lips.physical_simulator.physicalSimulator.PhysicalSimulator"><span class="pre">lips.physical_simulator.physicalSimulator.PhysicalSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/lips/benchmark/Benchmark.html#Benchmark.evaluate_simulator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.Benchmark.evaluate_simulator" title="Permalink to this definition"></a></dt>
<dd><p>This function will evalute a simulator (physical or augmented) using various criteria predefined in evaluator object
on a <code class="docutils literal notranslate"><span class="pre">single</span> <span class="pre">test</span> <span class="pre">dataset</span></code>. It can be overloaded or called to evaluate the performance on multiple datasets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="lips.dataset.html#lips.dataset.DataSet" title="lips.dataset.DataSet"><em>DataSet</em></a>) – a test dataset on which the augmented simulator should be performed and evaluated by</p></li>
<li><p><strong>augmented_simulator</strong> (<a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.AugmentedSimulator" title="lips.augmented_simulators.AugmentedSimulator"><em>AugmentedSimulator</em></a>) – a trained augmented simulator which should be evaluated</p></li>
<li><p><strong>batch_size</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>) – evaluation batch size</p></li>
<li><p><strong>save_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – if indicated the evaluation results will be saved to indicated path</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing the evaluation results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lips.benchmark.PowerGridBenchmark">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lips.benchmark.</span></span><span class="sig-name descname"><span class="pre">PowerGridBenchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">benchmark_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'Benchmark1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_data_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.evaluation.html#lips.evaluation.powergrid_evaluation.PowerGridEvaluation" title="lips.evaluation.powergrid_evaluation.PowerGridEvaluation"><span class="pre">lips.evaluation.powergrid_evaluation.PowerGridEvaluation</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_ood_topo_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_chronics_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_ood_topo_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.PowerGridBenchmark" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lips.benchmark.Benchmark.Benchmark" title="lips.benchmark.Benchmark.Benchmark"><code class="xref py py-class docutils literal notranslate"><span class="pre">lips.benchmark.Benchmark.Benchmark</span></code></a></p>
<p>PowerGrid Benchmark class</p>
<p>This class allows to benchmark a power grid scenario which are defined in a config file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>benchmark_path</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) – path to the benchmark</p></li>
<li><p><strong>config_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – path to the configuration file. If config_path is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default config file
present in config module will be used by using the benchmark_name as the section, by default None</p></li>
<li><p><strong>benchmark_name</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>, optional) – the benchmark name which is used in turn as the config section, by default “Benchmark1”</p></li>
<li><p><strong>load_data_set</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional) – whether to load the already generated datasets, by default False</p></li>
<li><p><strong>evaluation</strong> (Union[<code class="docutils literal notranslate"><span class="pre">PowerGridEvaluation</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – a <code class="docutils literal notranslate"><span class="pre">PowerGridEvaluation</span></code> instance. If not indicated, the benchmark creates its
own evaluation instance using appropriate config, by default None</p></li>
<li><p><strong>log_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – path to the logs, by default None</p></li>
</ul>
</dd>
</dl>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>Add all the seeds into the config file</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>An independent class for each benchmark is maybe a better idea.
This class can be served as the base class for powergrid and a specific class for each benchmark
can extend this class.</p>
</div>
<p><strong>Methods:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.PowerGridBenchmark.load" title="lips.benchmark.PowerGridBenchmark.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>()</p></td>
<td><p>load the already generated datasets</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#lips.benchmark.PowerGridBenchmark.generate" title="lips.benchmark.PowerGridBenchmark.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a>(nb_sample_train, nb_sample_val, ...)</p></td>
<td><p>generate the different datasets required for the benchmark</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.PowerGridBenchmark.evaluate_simulator" title="lips.benchmark.PowerGridBenchmark.evaluate_simulator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_simulator</span></code></a>([dataset, ...])</p></td>
<td><p>evaluate a trained augmented simulator on one or multiple test datasets</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.PowerGridBenchmark.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.PowerGridBenchmark.load" title="Permalink to this definition"></a></dt>
<dd><p>load the already generated datasets</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.PowerGridBenchmark.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nb_sample_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_test_ood_topo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.PowerGridBenchmark.generate" title="Permalink to this definition"></a></dt>
<dd><p>generate the different datasets required for the benchmark</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.PowerGridBenchmark.evaluate_simulator">
<span class="sig-name descname"><span class="pre">evaluate_simulator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicalSimulator.PhysicalSimulator" title="lips.physical_simulator.physicalSimulator.PhysicalSimulator"><span class="pre">lips.physical_simulator.physicalSimulator.PhysicalSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_flow</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.evaluate_simulator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.PowerGridBenchmark.evaluate_simulator" title="Permalink to this definition"></a></dt>
<dd><p>evaluate a trained augmented simulator on one or multiple test datasets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>str</em><em>, </em><em>optional</em>) – dataset on which the evaluation should be performed, by default “all”</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – the batch size for inference, by default 32</p></li>
<li><p><strong>save_path</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – the path that the evaluation results should be saved, by default None</p></li>
<li><p><strong>active_flow</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to compute the KCL for active_flow, by default True</p></li>
</ul>
</dd>
</dl>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>TODO: add active flow in config file</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the results dictionary</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – Unknown dataset selected</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-lips.benchmark.Benchmark">
<span id="lips-benchmark-benchmark-module"></span><h2>lips.benchmark.Benchmark module<a class="headerlink" href="#module-lips.benchmark.Benchmark" title="Permalink to this headline"></a></h2>
<p><strong>Classes:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.Benchmark.Benchmark" title="lips.benchmark.Benchmark.Benchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Benchmark</span></code></a>(benchmark_name[, dataset, ...])</p></td>
<td><p>Benchmark Base Class</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lips.benchmark.Benchmark.</span></span><span class="sig-name descname"><span class="pre">Benchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">benchmark_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.dataset.html#lips.dataset.dataSet.DataSet" title="lips.dataset.dataSet.DataSet"><span class="pre">lips.dataset.dataSet.DataSet</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicsSolver.PhysicsSolver" title="lips.physical_simulator.physicsSolver.PhysicsSolver"><span class="pre">lips.physical_simulator.physicsSolver.PhysicsSolver</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.evaluation.html#lips.evaluation.evaluation.Evaluation" title="lips.evaluation.evaluation.Evaluation"><span class="pre">lips.evaluation.evaluation.Evaluation</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/Benchmark.html#Benchmark"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Benchmark Base Class</p>
<p>Benchmark class that takes a test dataset, a simulator (physical or augmented) and an
evaluator object and evaluates the simulator on test dataset with respect to required
metrics requested by evaluator</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.benchmark_name">
<span class="sig-name descname"><span class="pre">benchmark_name</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.benchmark_name" title="Permalink to this definition"></a></dt>
<dd><p>a name attributed to the corresponding experiment</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.dataset" title="Permalink to this definition"></a></dt>
<dd><p>an object of <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> class which containing the data for training, validation and testing, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">DataSet</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.augmented_simulator">
<span class="sig-name descname"><span class="pre">augmented_simulator</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.augmented_simulator" title="Permalink to this definition"></a></dt>
<dd><p>This is an object of Physical or Augmneted simulator including the prediction results, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">AugmentedSimulator</span></code>, <code class="docutils literal notranslate"><span class="pre">PhysicsSolver</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.evaluation">
<span class="sig-name descname"><span class="pre">evaluation</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.evaluation" title="Permalink to this definition"></a></dt>
<dd><p>It allows to evaluate the performance of the simulator with respect to various point of views
It should be parameterized before passing to benchmark class to include appropriate metrics
otherwise, it is initialized using an empty dictionary, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="lips.evaluation.html#lips.evaluation.Evaluation" title="lips.evaluation.Evaluation">Evaluation</a>, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.benchmark_path">
<span class="sig-name descname"><span class="pre">benchmark_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.benchmark_path" title="Permalink to this definition"></a></dt>
<dd><p>the path used to save the benchmark results, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.log_path">
<span class="sig-name descname"><span class="pre">log_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.log_path" title="Permalink to this definition"></a></dt>
<dd><p>the path of logger, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.config_path">
<span class="sig-name descname"><span class="pre">config_path</span></span><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.config_path" title="Permalink to this definition"></a></dt>
<dd><p>the path of config file, by default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional</p>
</dd>
</dl>
</dd></dl>

<p><strong>Methods:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.Benchmark.Benchmark.evaluate_simulator" title="lips.benchmark.Benchmark.Benchmark.evaluate_simulator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_simulator</span></code></a>(dataset[, ...])</p></td>
<td><p>This function will evalute a simulator (physical or augmented) using various criteria predefined in evaluator object on a <code class="docutils literal notranslate"><span class="pre">single</span> <span class="pre">test</span> <span class="pre">dataset</span></code>.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.Benchmark.Benchmark.evaluate_simulator">
<em class="property"><span class="pre">abstractmethod</span> </em><span class="sig-name descname"><span class="pre">evaluate_simulator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="lips.dataset.html#lips.dataset.dataSet.DataSet" title="lips.dataset.dataSet.DataSet"><span class="pre">lips.dataset.dataSet.DataSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicalSimulator.PhysicalSimulator" title="lips.physical_simulator.physicalSimulator.PhysicalSimulator"><span class="pre">lips.physical_simulator.physicalSimulator.PhysicalSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/lips/benchmark/Benchmark.html#Benchmark.evaluate_simulator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.Benchmark.Benchmark.evaluate_simulator" title="Permalink to this definition"></a></dt>
<dd><p>This function will evalute a simulator (physical or augmented) using various criteria predefined in evaluator object
on a <code class="docutils literal notranslate"><span class="pre">single</span> <span class="pre">test</span> <span class="pre">dataset</span></code>. It can be overloaded or called to evaluate the performance on multiple datasets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="lips.dataset.html#lips.dataset.DataSet" title="lips.dataset.DataSet"><em>DataSet</em></a>) – a test dataset on which the augmented simulator should be performed and evaluated by</p></li>
<li><p><strong>augmented_simulator</strong> (<a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.AugmentedSimulator" title="lips.augmented_simulators.AugmentedSimulator"><em>AugmentedSimulator</em></a>) – a trained augmented simulator which should be evaluated</p></li>
<li><p><strong>batch_size</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>) – evaluation batch size</p></li>
<li><p><strong>save_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – if indicated the evaluation results will be saved to indicated path</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary containing the evaluation results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-lips.benchmark.powergridBenchmark">
<span id="lips-benchmark-powergridbenchmark-module"></span><h2>lips.benchmark.powergridBenchmark module<a class="headerlink" href="#module-lips.benchmark.powergridBenchmark" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt>Licence:</dt><dd><p>Copyright (c) 2021, IRT SystemX (<a class="reference external" href="https://www.irt-systemx.fr/en/">https://www.irt-systemx.fr/en/</a>)
See AUTHORS.txt
This Source Code Form is subject to the terms of the Mozilla Public License, version 2.0.
If a copy of the Mozilla Public License, version 2.0 was not distributed with this file,
you can obtain one at <a class="reference external" href="http://mozilla.org/MPL/2.0/">http://mozilla.org/MPL/2.0/</a>.
SPDX-License-Identifier: MPL-2.0
This file is part of LIPS, LIPS is a python platform for power networks benchmarking</p>
</dd>
</dl>
<p><strong>Classes:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark" title="lips.benchmark.powergridBenchmark.PowerGridBenchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PowerGridBenchmark</span></code></a>(benchmark_path[, ...])</p></td>
<td><p>PowerGrid Benchmark class</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="lips.benchmark.powergridBenchmark.PowerGridBenchmark">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lips.benchmark.powergridBenchmark.</span></span><span class="sig-name descname"><span class="pre">PowerGridBenchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">benchmark_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'Benchmark1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_data_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.evaluation.html#lips.evaluation.powergrid_evaluation.PowerGridEvaluation" title="lips.evaluation.powergrid_evaluation.PowerGridEvaluation"><span class="pre">lips.evaluation.powergrid_evaluation.PowerGridEvaluation</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_ood_topo_env_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_chronics_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_ood_topo_actor_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lips.benchmark.Benchmark.Benchmark" title="lips.benchmark.Benchmark.Benchmark"><code class="xref py py-class docutils literal notranslate"><span class="pre">lips.benchmark.Benchmark.Benchmark</span></code></a></p>
<p>PowerGrid Benchmark class</p>
<p>This class allows to benchmark a power grid scenario which are defined in a config file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>benchmark_path</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) – path to the benchmark</p></li>
<li><p><strong>config_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – path to the configuration file. If config_path is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default config file
present in config module will be used by using the benchmark_name as the section, by default None</p></li>
<li><p><strong>benchmark_name</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>, optional) – the benchmark name which is used in turn as the config section, by default “Benchmark1”</p></li>
<li><p><strong>load_data_set</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional) – whether to load the already generated datasets, by default False</p></li>
<li><p><strong>evaluation</strong> (Union[<code class="docutils literal notranslate"><span class="pre">PowerGridEvaluation</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – a <code class="docutils literal notranslate"><span class="pre">PowerGridEvaluation</span></code> instance. If not indicated, the benchmark creates its
own evaluation instance using appropriate config, by default None</p></li>
<li><p><strong>log_path</strong> (Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>], optional) – path to the logs, by default None</p></li>
</ul>
</dd>
</dl>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>Add all the seeds into the config file</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>An independent class for each benchmark is maybe a better idea.
This class can be served as the base class for powergrid and a specific class for each benchmark
can extend this class.</p>
</div>
<p><strong>Methods:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.load" title="lips.benchmark.powergridBenchmark.PowerGridBenchmark.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>()</p></td>
<td><p>load the already generated datasets</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.generate" title="lips.benchmark.powergridBenchmark.PowerGridBenchmark.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a>(nb_sample_train, nb_sample_val, ...)</p></td>
<td><p>generate the different datasets required for the benchmark</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.evaluate_simulator" title="lips.benchmark.powergridBenchmark.PowerGridBenchmark.evaluate_simulator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_simulator</span></code></a>([dataset, ...])</p></td>
<td><p>evaluate a trained augmented simulator on one or multiple test datasets</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.powergridBenchmark.PowerGridBenchmark.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.load" title="Permalink to this definition"></a></dt>
<dd><p>load the already generated datasets</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.powergridBenchmark.PowerGridBenchmark.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nb_sample_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_sample_test_ood_topo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.generate" title="Permalink to this definition"></a></dt>
<dd><p>generate the different datasets required for the benchmark</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lips.benchmark.powergridBenchmark.PowerGridBenchmark.evaluate_simulator">
<span class="sig-name descname"><span class="pre">evaluate_simulator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">augmented_simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lips.physical_simulator.html#lips.physical_simulator.physicalSimulator.PhysicalSimulator" title="lips.physical_simulator.physicalSimulator.PhysicalSimulator"><span class="pre">lips.physical_simulator.physicalSimulator.PhysicalSimulator</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lips.augmented_simulators.html#lips.augmented_simulators.augmentedSimulator.AugmentedSimulator" title="lips.augmented_simulators.augmentedSimulator.AugmentedSimulator"><span class="pre">lips.augmented_simulators.augmentedSimulator.AugmentedSimulator</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_flow</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/lips/benchmark/powergridBenchmark.html#PowerGridBenchmark.evaluate_simulator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lips.benchmark.powergridBenchmark.PowerGridBenchmark.evaluate_simulator" title="Permalink to this definition"></a></dt>
<dd><p>evaluate a trained augmented simulator on one or multiple test datasets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>str</em><em>, </em><em>optional</em>) – dataset on which the evaluation should be performed, by default “all”</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – the batch size for inference, by default 32</p></li>
<li><p><strong>save_path</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – the path that the evaluation results should be saved, by default None</p></li>
<li><p><strong>active_flow</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to compute the KCL for active_flow, by default True</p></li>
</ul>
</dd>
</dl>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<p>TODO: add active flow in config file</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the results dictionary</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – Unknown dataset selected</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lips.augmented_simulators.html" class="btn btn-neutral float-left" title="lips.augmented_simulators package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lips.config.html" class="btn btn-neutral float-right" title="lips.config package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, IRT SystemX.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
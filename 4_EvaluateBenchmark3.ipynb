{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c5aeb5",
   "metadata": {},
   "source": [
    "# Initial step: load the dataset (Benchmark3)\n",
    "\n",
    "A common dataset generated in the context of second benchmark will be used to evaluate the augmented simulators. This initial step aims at loading it once and for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1650b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from lips.neurips_benchmark import NeuripsBenchmark3\n",
    "path_benchmark = os.path.join(\"reference_data\")\n",
    "neurips_benchmark3 = NeuripsBenchmark3(path_benchmark=path_benchmark,\n",
    "                                       load_data_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136be48",
   "metadata": {},
   "source": [
    "# Training an augmented simulator \n",
    "In this benchmark the augmented simulators will predict all the power flow related variables (active $p$ and reactive $q$ powers, voltages $v$ and currents $a$) alongside the voltage angles ($\\theta$) contrary to the first and second benchmarks which were concentrated only on power flow variables.\n",
    "\n",
    "## Fully connected architecture\n",
    "In this section we explain how to tune an available model. We take the example of the `FullyConnectedAS` that is an available fully connected neural network.\n",
    "\n",
    "The first step is to create the class you want to use, with the meta parameters you want to test. For this example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd0d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = os.path.join(\"trained_models\")\n",
    "if not os.path.exists(path_save):\n",
    "    os.mkdir(path_save)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import FullyConnectedAS\n",
    "\n",
    "# the three lines bellow might be familiar to the tensorflow users. They tell tensorflow to not take all\n",
    "# the GPU video RAM for the model.\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for el in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(el, True)\n",
    "\n",
    "simulator_FC = FullyConnectedAS(name=\"test_FullyConnectedAS_benchmark3\",\n",
    "                                # `attr_x` represents the variables of the dataset you want to use to predict \n",
    "                                # the output.\n",
    "                                attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\", \"line_status\", \"topo_vect\"),\n",
    "                                # `attr_y` represents the variables of the dataset you want to predict\n",
    "                                # flow variables alongside the angles are added\n",
    "                                attr_y=(\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"q_ex\", \"q_or\", \"v_or\", \"v_ex\", \"load_v\", \"prod_q\", \"theta_or\", \"theta_ex\"),\n",
    "                                # `sizes_layer` represents the size of each hidden layer in the neural network. The number\n",
    "                                # of layers is determined by the length of this list, for example\n",
    "                                sizes_layer=(300, 300, 300, 300),\n",
    "                                # `lr` is the learning rate\n",
    "                                lr=3e-4, \n",
    "                                # `layer` is the type of keras layer you want to use. We don't recommend to \n",
    "                                # change it\n",
    "                                layer=Dense,\n",
    "                                # `layer_act` is the activation function you want to use after each layer\n",
    "                                layer_act=\"relu\",\n",
    "                                # `loss` is the training loss\n",
    "                                loss=\"mse\",  # loss used to train the model\n",
    "                                # `batch_size` is the size of the batch for training\n",
    "                                batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0394531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2801 - val_loss: 0.0166\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 3/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 5/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 6/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 15/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 9.8327e-04 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 9.8560e-04 - val_loss: 0.0015\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 9.9302e-04 - val_loss: 0.0010\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 9.2677e-04 - val_loss: 0.0010\n",
      "Epoch 21/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 9.1704e-04 - val_loss: 8.8764e-04\n",
      "Epoch 23/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 7.7729e-04 - val_loss: 9.2555e-04\n",
      "Epoch 24/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 7.9630e-04 - val_loss: 8.8069e-04\n",
      "Epoch 25/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 7.6314e-04 - val_loss: 0.0010\n",
      "Epoch 26/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 7.4973e-04 - val_loss: 8.5774e-04\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.9814e-04 - val_loss: 8.4937e-04\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 7.4208e-04 - val_loss: 7.8622e-04\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 7.0323e-04 - val_loss: 7.5159e-04\n",
      "Epoch 30/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.4645e-04 - val_loss: 7.5198e-04\n",
      "Epoch 31/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.6102e-04 - val_loss: 7.1489e-04\n",
      "Epoch 32/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.3741e-04 - val_loss: 6.1642e-04\n",
      "Epoch 33/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.9785e-04 - val_loss: 8.2496e-04\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.9447e-04 - val_loss: 7.1200e-04\n",
      "Epoch 35/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.8316e-04 - val_loss: 8.1439e-04\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.1394e-04 - val_loss: 6.8897e-04\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.9699e-04 - val_loss: 6.4507e-04\n",
      "Epoch 38/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.4260e-04 - val_loss: 8.3972e-04\n",
      "Epoch 39/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.6576e-04 - val_loss: 6.4306e-04\n",
      "Epoch 40/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.5208e-04 - val_loss: 0.0013\n",
      "Epoch 41/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.7522e-04 - val_loss: 7.7473e-04\n",
      "Epoch 42/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 6.0198e-04 - val_loss: 5.8693e-04\n",
      "Epoch 43/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.9649e-04 - val_loss: 6.7825e-04\n",
      "Epoch 44/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 5.4530e-04 - val_loss: 5.7298e-04\n",
      "Epoch 45/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 4.7659e-04 - val_loss: 8.1889e-04\n",
      "Epoch 46/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 5.0730e-04 - val_loss: 7.7016e-04\n",
      "Epoch 47/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.5798e-04 - val_loss: 8.1270e-04\n",
      "Epoch 48/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.6252e-04 - val_loss: 5.9657e-04\n",
      "Epoch 49/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.7312e-04 - val_loss: 6.5299e-04\n",
      "Epoch 50/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.5640e-04 - val_loss: 5.7950e-04\n",
      "Epoch 51/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.7990e-04 - val_loss: 7.5388e-04\n",
      "Epoch 52/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.0507e-04 - val_loss: 5.4620e-04\n",
      "Epoch 53/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.6381e-04 - val_loss: 4.7991e-04\n",
      "Epoch 54/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.3781e-04 - val_loss: 0.0010\n",
      "Epoch 55/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.6734e-04 - val_loss: 5.3254e-04\n",
      "Epoch 56/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.4708e-04 - val_loss: 5.3902e-04\n",
      "Epoch 57/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.6001e-04 - val_loss: 6.6261e-04\n",
      "Epoch 58/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.5658e-04 - val_loss: 6.7228e-04\n",
      "Epoch 59/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.3257e-04 - val_loss: 4.8556e-04\n",
      "Epoch 60/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.3932e-04 - val_loss: 5.1441e-04\n",
      "Epoch 61/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.2008e-04 - val_loss: 5.0564e-04\n",
      "Epoch 62/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.5996e-04 - val_loss: 4.8257e-04\n",
      "Epoch 63/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.8573e-04 - val_loss: 5.0396e-04\n",
      "Epoch 64/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.5839e-04 - val_loss: 6.2873e-04\n",
      "Epoch 65/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.1589e-04 - val_loss: 6.6250e-04\n",
      "Epoch 66/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.1409e-04 - val_loss: 4.6909e-04\n",
      "Epoch 67/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.9006e-04 - val_loss: 4.6474e-04\n",
      "Epoch 68/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 4.3987e-04 - val_loss: 4.5880e-04\n",
      "Epoch 69/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.9609e-04 - val_loss: 5.7203e-04\n",
      "Epoch 70/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.1000e-04 - val_loss: 4.2607e-04\n",
      "Epoch 71/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.5920e-04 - val_loss: 8.3002e-04\n",
      "Epoch 72/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.4637e-04 - val_loss: 4.2049e-04\n",
      "Epoch 73/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.9736e-04 - val_loss: 4.4653e-04\n",
      "Epoch 74/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.7999e-04 - val_loss: 6.0975e-04\n",
      "Epoch 75/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.6910e-04 - val_loss: 3.4576e-04\n",
      "Epoch 76/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.1051e-04 - val_loss: 3.6940e-04\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 3.5739e-04 - val_loss: 3.5092e-04\n",
      "Epoch 78/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 5.8855e-04 - val_loss: 3.6860e-04\n",
      "Epoch 79/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.5022e-04 - val_loss: 5.9229e-04\n",
      "Epoch 80/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4466e-04 - val_loss: 7.4453e-04\n",
      "Epoch 81/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 4.5856e-04 - val_loss: 4.6692e-04\n",
      "Epoch 82/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.5001e-04 - val_loss: 6.3207e-04\n",
      "Epoch 83/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.6265e-04 - val_loss: 4.1316e-04\n",
      "Epoch 84/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4618e-04 - val_loss: 3.0900e-04\n",
      "Epoch 85/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2092e-04 - val_loss: 3.7666e-04\n",
      "Epoch 86/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2800e-04 - val_loss: 6.3574e-04\n",
      "Epoch 87/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.6222e-04 - val_loss: 3.5451e-04\n",
      "Epoch 88/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2789e-04 - val_loss: 5.2122e-04\n",
      "Epoch 89/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.7562e-04 - val_loss: 5.6547e-04\n",
      "Epoch 90/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4165e-04 - val_loss: 3.7474e-04\n",
      "Epoch 91/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4932e-04 - val_loss: 4.8441e-04\n",
      "Epoch 92/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4614e-04 - val_loss: 3.9152e-04\n",
      "Epoch 93/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4616e-04 - val_loss: 5.5885e-04\n",
      "Epoch 94/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2749e-04 - val_loss: 3.4037e-04\n",
      "Epoch 95/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.5052e-04 - val_loss: 3.9675e-04\n",
      "Epoch 96/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2378e-04 - val_loss: 4.0661e-04\n",
      "Epoch 97/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.0781e-04 - val_loss: 3.2587e-04\n",
      "Epoch 98/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.0440e-04 - val_loss: 3.4869e-04\n",
      "Epoch 99/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.4189e-04 - val_loss: 3.8189e-04\n",
      "Epoch 100/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.0103e-04 - val_loss: 4.5113e-04\n",
      "Epoch 101/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.1923e-04 - val_loss: 3.5157e-04\n",
      "Epoch 102/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.3803e-04 - val_loss: 4.9607e-04\n",
      "Epoch 103/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.3658e-04 - val_loss: 3.2401e-04\n",
      "Epoch 104/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.4893e-04 - val_loss: 4.0566e-04\n",
      "Epoch 105/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.2643e-04 - val_loss: 2.9580e-04\n",
      "Epoch 106/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.8491e-04 - val_loss: 2.7884e-04\n",
      "Epoch 107/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6971e-04 - val_loss: 4.4844e-04\n",
      "Epoch 108/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.1646e-04 - val_loss: 3.5902e-04\n",
      "Epoch 109/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.7730e-04 - val_loss: 4.2828e-04\n",
      "Epoch 110/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.2611e-04 - val_loss: 3.0696e-04\n",
      "Epoch 111/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.8872e-04 - val_loss: 3.8924e-04\n",
      "Epoch 112/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.3136e-04 - val_loss: 2.8162e-04\n",
      "Epoch 113/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.8717e-04 - val_loss: 4.1450e-04\n",
      "Epoch 114/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.9184e-04 - val_loss: 3.0713e-04\n",
      "Epoch 115/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.9112e-04 - val_loss: 3.1283e-04\n",
      "Epoch 116/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.8961e-04 - val_loss: 2.9603e-04\n",
      "Epoch 117/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.4031e-04 - val_loss: 3.5077e-04\n",
      "Epoch 118/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.0237e-04 - val_loss: 3.5993e-04\n",
      "Epoch 119/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6640e-04 - val_loss: 5.7343e-04\n",
      "Epoch 120/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.1987e-04 - val_loss: 2.8481e-04\n",
      "Epoch 121/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6038e-04 - val_loss: 3.5693e-04\n",
      "Epoch 122/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.7259e-04 - val_loss: 3.8448e-04\n",
      "Epoch 123/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.0476e-04 - val_loss: 2.7097e-04\n",
      "Epoch 124/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.9589e-04 - val_loss: 3.1253e-04\n",
      "Epoch 125/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6777e-04 - val_loss: 4.0882e-04\n",
      "Epoch 126/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.9551e-04 - val_loss: 7.0527e-04\n",
      "Epoch 127/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.2859e-04 - val_loss: 3.2757e-04\n",
      "Epoch 128/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6198e-04 - val_loss: 3.0448e-04\n",
      "Epoch 129/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6710e-04 - val_loss: 3.8809e-04\n",
      "Epoch 130/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.7416e-04 - val_loss: 4.4317e-04\n",
      "Epoch 131/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.5467e-04 - val_loss: 2.6338e-04\n",
      "Epoch 132/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1367e-04 - val_loss: 4.1321e-04\n",
      "Epoch 133/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.4265e-04 - val_loss: 3.4364e-04\n",
      "Epoch 134/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6935e-04 - val_loss: 4.1737e-04\n",
      "Epoch 135/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.8438e-04 - val_loss: 2.4808e-04\n",
      "Epoch 136/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.2589e-04 - val_loss: 3.0722e-04\n",
      "Epoch 137/200\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 2.6714e-04 - val_loss: 2.5492e-04\n",
      "Epoch 138/200\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 2.6425e-04 - val_loss: 4.4351e-04\n",
      "Epoch 139/200\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 3.8179e-04 - val_loss: 2.8565e-04\n",
      "Epoch 140/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.0720e-04 - val_loss: 3.7997e-04\n",
      "Epoch 141/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6945e-04 - val_loss: 3.2422e-04\n",
      "Epoch 142/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.8849e-04 - val_loss: 2.4722e-04\n",
      "Epoch 143/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.4732e-04 - val_loss: 3.9447e-04\n",
      "Epoch 144/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.0346e-04 - val_loss: 3.3877e-04\n",
      "Epoch 145/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5816e-04 - val_loss: 2.7817e-04\n",
      "Epoch 146/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5195e-04 - val_loss: 2.6884e-04\n",
      "Epoch 147/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.0352e-04 - val_loss: 3.1403e-04\n",
      "Epoch 148/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.9912e-04 - val_loss: 2.7568e-04\n",
      "Epoch 149/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.7555e-04 - val_loss: 2.6610e-04\n",
      "Epoch 150/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.3410e-04 - val_loss: 3.1084e-04\n",
      "Epoch 151/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.7826e-04 - val_loss: 3.9503e-04\n",
      "Epoch 152/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5517e-04 - val_loss: 2.9022e-04\n",
      "Epoch 153/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3243e-04 - val_loss: 3.2409e-04\n",
      "Epoch 154/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 3.1711e-04 - val_loss: 2.7436e-04\n",
      "Epoch 155/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.3687e-04 - val_loss: 3.8321e-04\n",
      "Epoch 156/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.9145e-04 - val_loss: 3.4842e-04\n",
      "Epoch 157/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.5747e-04 - val_loss: 2.5295e-04\n",
      "Epoch 158/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.2291e-04 - val_loss: 2.5625e-04\n",
      "Epoch 159/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.0789e-04 - val_loss: 3.0355e-04\n",
      "Epoch 160/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4636e-04 - val_loss: 3.3207e-04\n",
      "Epoch 161/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.5122e-04 - val_loss: 3.0965e-04\n",
      "Epoch 162/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.7526e-04 - val_loss: 2.2883e-04\n",
      "Epoch 163/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4050e-04 - val_loss: 5.2600e-04\n",
      "Epoch 164/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.7998e-04 - val_loss: 2.5077e-04\n",
      "Epoch 165/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.2823e-04 - val_loss: 2.4938e-04\n",
      "Epoch 166/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3173e-04 - val_loss: 2.0437e-04\n",
      "Epoch 167/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9508e-04 - val_loss: 2.5586e-04\n",
      "Epoch 168/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4972e-04 - val_loss: 6.6427e-04\n",
      "Epoch 169/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.7650e-04 - val_loss: 2.5041e-04\n",
      "Epoch 170/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.2731e-04 - val_loss: 2.3065e-04\n",
      "Epoch 171/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1872e-04 - val_loss: 2.5343e-04\n",
      "Epoch 172/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4935e-04 - val_loss: 2.5938e-04\n",
      "Epoch 173/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9677e-04 - val_loss: 2.4299e-04\n",
      "Epoch 174/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.5485e-04 - val_loss: 3.1309e-04\n",
      "Epoch 175/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 3.3198e-04 - val_loss: 2.4624e-04\n",
      "Epoch 176/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1418e-04 - val_loss: 4.0425e-04\n",
      "Epoch 177/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4792e-04 - val_loss: 1.9549e-04\n",
      "Epoch 178/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1081e-04 - val_loss: 2.5198e-04\n",
      "Epoch 179/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3011e-04 - val_loss: 3.0219e-04\n",
      "Epoch 180/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3802e-04 - val_loss: 2.1885e-04\n",
      "Epoch 181/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.2885e-04 - val_loss: 2.1490e-04\n",
      "Epoch 182/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9265e-04 - val_loss: 2.3171e-04\n",
      "Epoch 183/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1690e-04 - val_loss: 2.1281e-04\n",
      "Epoch 184/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4323e-04 - val_loss: 2.8744e-04\n",
      "Epoch 185/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.0430e-04 - val_loss: 4.9403e-04\n",
      "Epoch 186/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3729e-04 - val_loss: 2.3708e-04\n",
      "Epoch 187/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1610e-04 - val_loss: 3.1117e-04\n",
      "Epoch 188/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.8348e-04 - val_loss: 2.8252e-04\n",
      "Epoch 189/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9590e-04 - val_loss: 2.1208e-04\n",
      "Epoch 190/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.2149e-04 - val_loss: 1.7741e-04\n",
      "Epoch 191/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.8852e-04 - val_loss: 3.8509e-04\n",
      "Epoch 192/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.9540e-04 - val_loss: 2.4450e-04\n",
      "Epoch 193/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.8593e-04 - val_loss: 2.8710e-04\n",
      "Epoch 194/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.0251e-04 - val_loss: 5.7522e-04\n",
      "Epoch 195/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5202e-04 - val_loss: 2.3834e-04\n",
      "Epoch 196/200\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.2363e-04 - val_loss: 2.1910e-04\n",
      "Epoch 197/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.1995e-04 - val_loss: 2.3494e-04\n",
      "Epoch 198/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3530e-04 - val_loss: 3.1718e-04\n",
      "Epoch 199/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.3733e-04 - val_loss: 1.8914e-04\n",
      "Epoch 200/200\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9099e-04 - val_loss: 2.1634e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19080184040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator_FC.train(nb_iter=200,\n",
    "                   train_dataset=neurips_benchmark3.train_dataset,\n",
    "                   val_dataset=neurips_benchmark3.val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff82345",
   "metadata": {},
   "source": [
    "save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754b3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_FC.save(path_save)\n",
    "simulator_FC.save_metadata(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b9026",
   "metadata": {},
   "source": [
    "load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e0cecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trained_models = os.path.join(\"trained_models\")\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import FullyConnectedAS\n",
    "\n",
    "# recreate the baseline\n",
    "simulator_FC = FullyConnectedAS(name=\"test_FullyConnectedAS_benchmark3\",\n",
    "                                attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\", \"line_status\", \"topo_vect\"),\n",
    "                                attr_y=(\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"q_ex\", \"q_or\", \"v_or\", \"v_ex\", \"load_v\", \"prod_q\", \"theta_or\", \"theta_ex\"),\n",
    "                                sizes_layer=(300, 300, 300, 300),\n",
    "                                lr=3e-4, \n",
    "                                layer=Dense,\n",
    "                                layer_act=\"relu\",\n",
    "                                loss=\"mse\",  # loss used to train the model\n",
    "                                batch_size=128)\n",
    "# TODO create a wrapper for these 3 calls\n",
    "simulator_FC.load_metadata(path_trained_models)\n",
    "simulator_FC.init()\n",
    "simulator_FC.restore(path_trained_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817dae3",
   "metadata": {},
   "source": [
    "# Evaluate the augmented simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "737e4c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A log file including some verifications is created at root directory with the name logs.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n"
     ]
    }
   ],
   "source": [
    "fc_metrics_per_dataset = neurips_benchmark3.evaluate_augmented_simulator(simulator_FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f30624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val', 'test', 'test_ood_topo'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_benchmark3.predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bc10208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a_or', 'a_ex', 'p_or', 'p_ex', 'q_ex', 'q_or', 'v_or', 'v_ex', 'load_v', 'prod_q', 'theta_or', 'theta_ex'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_benchmark3.predictions[\"test\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966f52f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prod_p', 'prod_v', 'load_p', 'load_q', 'line_status', 'topo_vect', 'a_or', 'a_ex', 'p_or', 'p_ex', 'q_or', 'q_ex', 'prod_q', 'load_v', 'v_or', 'v_ex', 'theta_or', 'theta_ex', 'load_theta', 'gen_theta', 'storage_theta'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_benchmark3._test_dataset.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0abfde93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gen_theta',\n",
       " 'line_status',\n",
       " 'load_p',\n",
       " 'load_q',\n",
       " 'load_theta',\n",
       " 'prod_p',\n",
       " 'prod_v',\n",
       " 'storage_theta',\n",
       " 'topo_vect'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_benchmark3._test_dataset.data.keys() - neurips_benchmark3.predictions[\"test\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "891788d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd8ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ref_obs\", neurips_benchmark3._test_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84812d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"predictions\", neurips_benchmark3.predictions[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67cc7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a_file = open(\"predictions_FC_test.pkl\", \"wb\")\n",
    "pickle.dump(neurips_benchmark3.predictions[\"test\"], a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"predictions_FC_ood.pkl\", \"wb\")\n",
    "pickle.dump(neurips_benchmark3.predictions[\"test_ood_topo\"], a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898bfb6f",
   "metadata": {},
   "source": [
    "### ML Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f38bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90\n",
      "{'a_ex': 0.00453048923659429,\n",
      " 'a_or': 0.004571197769038052,\n",
      " 'p_ex': 0.005380266589622638,\n",
      " 'p_or': 0.005441060604053268,\n",
      " 'q_ex': 0.010820239959033444,\n",
      " 'q_or': 0.012243016250860288,\n",
      " 'theta_ex': 0.00594510889206132,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.0020258985388451065,\n",
      " 'v_or': 0.002116077964796591}\n",
      "MAPE\n",
      "{'a_ex': 0.01206509496029071,\n",
      " 'a_or': 0.012328329055745853,\n",
      " 'load_v': 0.00014130105748821816,\n",
      " 'p_ex': 0.012246075987036283,\n",
      " 'p_or': 0.0122042014707874,\n",
      " 'prod_q': 0.005787441796298978,\n",
      " 'q_ex': 0.014143698071288905,\n",
      " 'q_or': 0.012699580187556642,\n",
      " 'theta_ex': 0.006121490332365712,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.0018207928324632107,\n",
      " 'v_or': 0.0018710782328293402}\n",
      "MAE\n",
      "{'a_ex': 2.4359219074249268,\n",
      " 'a_or': 1.7547935247421265,\n",
      " 'load_v': 0.007250834722071886,\n",
      " 'p_ex': 0.1440560519695282,\n",
      " 'p_or': 0.1459747850894928,\n",
      " 'prod_q': 0.13227196037769318,\n",
      " 'q_ex': 0.06623383611440659,\n",
      " 'q_or': 0.06187693402171135,\n",
      " 'theta_ex': 0.044860786692496345,\n",
      " 'theta_or': 0.040842502893081604,\n",
      " 'v_ex': 0.13230030238628387,\n",
      " 'v_or': 0.17376762628555298}\n",
      "NRMSE\n",
      "{'a_ex': 0.0026326198130846024,\n",
      " 'a_or': 0.002676862059161067,\n",
      " 'load_v': 0.0026577089447528124,\n",
      " 'p_ex': 0.002096419222652912,\n",
      " 'p_or': 0.002078092424198985,\n",
      " 'prod_q': 0.0024680679198354483,\n",
      " 'q_ex': 0.00199810229241848,\n",
      " 'q_or': 0.0022701218258589506,\n",
      " 'theta_ex': 0.0014248494279098197,\n",
      " 'theta_or': 0.0016439154070428826,\n",
      " 'v_ex': 0.0025774065870791674,\n",
      " 'v_or': 0.0027398192323744297}\n"
     ]
    }
   ],
   "source": [
    "ML_metrics = 0\n",
    "print(\"MAPE90\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][ML_metrics][\"mape90\"])\n",
    "print(\"MAPE\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][ML_metrics][\"mape_avg\"])\n",
    "print(\"MAE\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][ML_metrics][\"MAE_avg\"])\n",
    "print(\"NRMSE\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][ML_metrics][\"NRMSE_avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1849099",
   "metadata": {},
   "source": [
    "### OOD Generalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83072b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90\n",
      "{'a_ex': 0.20107159106043712,\n",
      " 'a_or': 0.2010885507612319,\n",
      " 'p_ex': 0.23931476475031105,\n",
      " 'p_or': 0.241871617038327,\n",
      " 'q_ex': 0.34331784958160283,\n",
      " 'q_or': 0.36442009321746427,\n",
      " 'theta_ex': 0.15957073813573144,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.03118037104864476,\n",
      " 'v_or': 0.030783094899299146}\n",
      "MAPE\n",
      "{'a_ex': 0.21175651492018047,\n",
      " 'a_or': 0.2150390137056632,\n",
      " 'p_ex': 0.2739599888702738,\n",
      " 'p_or': 0.2756300244671787,\n",
      " 'q_ex': 0.2712641773304669,\n",
      " 'q_or': 0.2659483474492036,\n",
      " 'theta_ex': 0.1304486416400271,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.027558933854545786,\n",
      " 'v_or': 0.027649661776876232}\n",
      "MAE\n",
      "{'a_ex': 65.6705551147461,\n",
      " 'a_or': 45.574684143066406,\n",
      " 'p_ex': 3.94745135307312,\n",
      " 'p_or': 4.019582748413086,\n",
      " 'q_ex': 1.6291145086288452,\n",
      " 'q_or': 1.5206332206726074,\n",
      " 'theta_ex': 1.7184120090077706,\n",
      " 'theta_or': 1.6142652562770508,\n",
      " 'v_ex': 2.8946361541748047,\n",
      " 'v_or': 3.7403595447540283}\n",
      "NRMSE\n",
      "{'a_ex': 0.056359924376010895,\n",
      " 'a_or': 0.056323640048503876,\n",
      " 'p_ex': 0.050281137228012085,\n",
      " 'p_or': 0.05012497305870056,\n",
      " 'q_ex': 0.04576147347688675,\n",
      " 'q_or': 0.045869551599025726,\n",
      " 'theta_ex': 0.043334392142782986,\n",
      " 'theta_or': 0.04193623235744974,\n",
      " 'v_ex': 0.07286673039197922,\n",
      " 'v_or': 0.07425205409526825}\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"mape90\"])\n",
    "print(\"MAPE\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"mape_avg\"])\n",
    "print(\"MAE\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"MAE_avg\"])\n",
    "print(\"NRMSE\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"NRMSE_avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1204e",
   "metadata": {},
   "source": [
    "### Physics compliance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f91f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pos\n",
      "0.035045\n",
      "0.03378\n",
      "voltage pos\n",
      "0.031935\n",
      "0.03212\n",
      "loss\n",
      "0.220215\n",
      "line_status\n",
      "{'a_ex_not_null': 11860.0,\n",
      " 'a_or_not_null': 11860.0,\n",
      " 'a_violations': 1.0,\n",
      " 'p_ex_not_null': 11860.0,\n",
      " 'p_or_not_null': 11860,\n",
      " 'p_violations': 1.0,\n",
      " 'q_ex_not_null': 11860.0,\n",
      " 'q_or_not_null': 11860.0,\n",
      " 'q_violations': 1.0}\n",
      "KCL\n",
      "Violation percentage:  93.5364864864865\n"
     ]
    }
   ],
   "source": [
    "print(\"current pos\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"currents\"][\"a_or\"][\"Violation_proportion\"])\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"currents\"][\"a_ex\"][\"Violation_proportion\"])\n",
    "print(\"voltage pos\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"voltages\"][\"v_or\"][\"Violation_proportion\"])\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"voltages\"][\"v_ex\"][\"Violation_proportion\"])\n",
    "\n",
    "print(\"loss\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"loss\"][\"violation_proportion\"])\n",
    "print(\"line_status\")\n",
    "pprint(fc_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"line_status\"])\n",
    "print(\"KCL\")\n",
    "print(\"Violation percentage: \", fc_metrics_per_dataset[\"test\"][1][\"KCL\"][\"violation_percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ba7d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'violation_prop_obs_level': 1.0,\n",
       " 'violation_prop_sub_level': 0.4843142857142857}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_metrics_per_dataset[\"test\"][1][\"KCL_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eea949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pos\n",
      "0.02754\n",
      "0.02741\n",
      "voltage pos\n",
      "0.01226\n",
      "0.012315\n",
      "loss\n",
      "0.362545\n",
      "line_status\n",
      "{'a_ex_not_null': 21843.0,\n",
      " 'a_or_not_null': 21843.0,\n",
      " 'a_violations': 1.0,\n",
      " 'p_ex_not_null': 21843.0,\n",
      " 'p_or_not_null': 21843,\n",
      " 'p_violations': 1.0,\n",
      " 'q_ex_not_null': 21843.0,\n",
      " 'q_or_not_null': 21843.0,\n",
      " 'q_violations': 1.0}\n",
      "KCL\n",
      "Violation percentage:  99.11331916448944\n"
     ]
    }
   ],
   "source": [
    "print(\"current pos\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"currents\"][\"a_or\"][\"Violation_proportion\"])\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"currents\"][\"a_ex\"][\"Violation_proportion\"])\n",
    "print(\"voltage pos\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"voltages\"][\"v_or\"][\"Violation_proportion\"])\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"voltages\"][\"v_ex\"][\"Violation_proportion\"])\n",
    "\n",
    "print(\"loss\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"loss\"][\"violation_proportion\"])\n",
    "print(\"line_status\")\n",
    "pprint(fc_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"line_status\"])\n",
    "#pprint(dc_metrics_per_dataset[\"test_ood_topo\"][1])\n",
    "print(\"KCL\")\n",
    "print(\"Violation percentage: \", fc_metrics_per_dataset[\"test_ood_topo\"][1][\"KCL\"][\"violation_percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794ed1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'violation_prop_obs_level': 1.0,\n",
       " 'violation_prop_sub_level': 0.48201428571428573}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_metrics_per_dataset[\"test_ood_topo\"][1][\"KCL_new\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea4e2d",
   "metadata": {},
   "source": [
    "# LeapNets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029b975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = os.path.join(\"trained_models\")\n",
    "if not os.path.exists(path_save):\n",
    "    os.mkdir(path_save)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import LeapNetAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9207c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "leapNet = LeapNetAS(name=\"test_leapNetAS_benchmark3\",\n",
    "                    # `attr_x` represents the variables of the dataset you want to use to predict \n",
    "                    # the output.\n",
    "                    attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    # `attr_y` represents the variables of the dataset you want to predict\n",
    "                    # all the powerflow variables alongside the voltage angles\n",
    "                    attr_y=(\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"q_ex\", \"q_or\", \"v_or\", \"v_ex\", \"load_v\", \"prod_q\", \"theta_or\", \"theta_ex\"),\n",
    "                    # `lr` is the learning rate\n",
    "                    lr=3e-4, \n",
    "                    # `layer` is the type of keras layer you want to use. We don't recommend to \n",
    "                    # change it\n",
    "                    layer=Dense,\n",
    "                    # `layer_act` is the activation function you want to use after each layer\n",
    "                    layer_act=\"relu\",\n",
    "                    # `loss` is the training loss\n",
    "                    loss=\"mse\",  # loss used to train the model\n",
    "                    # `batch_size` is the size of the batch for training\n",
    "                    batch_size=128,\n",
    "                    # the method used to encode the topology vector\n",
    "                    topo_vect_to_tau=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f76e8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "782/782 [==============================] - 16s 12ms/step - loss: 16.2418 - a_or_hat_loss: 2.0659 - a_ex_hat_loss: 2.3618 - p_or_hat_loss: 2.2471 - p_ex_hat_loss: 2.1745 - q_ex_hat_loss: 3.2774 - q_or_hat_loss: 2.2160 - v_or_hat_loss: 0.2093 - v_ex_hat_loss: 0.2534 - load_v_hat_loss: 0.2285 - prod_q_hat_loss: 0.3535 - theta_or_hat_loss: 0.3973 - theta_ex_hat_loss: 0.4572 - val_loss: 0.6174 - val_a_or_hat_loss: 0.0914 - val_a_ex_hat_loss: 0.0916 - val_p_or_hat_loss: 0.0693 - val_p_ex_hat_loss: 0.0640 - val_q_ex_hat_loss: 0.1191 - val_q_or_hat_loss: 0.0857 - val_v_or_hat_loss: 0.0022 - val_v_ex_hat_loss: 0.0016 - val_load_v_hat_loss: 0.0077 - val_prod_q_hat_loss: 0.0228 - val_theta_or_hat_loss: 0.0291 - val_theta_ex_hat_loss: 0.0329\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4448 - a_or_hat_loss: 0.0651 - a_ex_hat_loss: 0.0679 - p_or_hat_loss: 0.0493 - p_ex_hat_loss: 0.0443 - q_ex_hat_loss: 0.0819 - q_or_hat_loss: 0.0596 - v_or_hat_loss: 0.0015 - v_ex_hat_loss: 0.0011 - load_v_hat_loss: 0.0062 - prod_q_hat_loss: 0.0178 - theta_or_hat_loss: 0.0243 - theta_ex_hat_loss: 0.0257 - val_loss: 0.2583 - val_a_or_hat_loss: 0.0407 - val_a_ex_hat_loss: 0.0428 - val_p_or_hat_loss: 0.0279 - val_p_ex_hat_loss: 0.0254 - val_q_ex_hat_loss: 0.0452 - val_q_or_hat_loss: 0.0316 - val_v_or_hat_loss: 7.1630e-04 - val_v_ex_hat_loss: 5.6198e-04 - val_load_v_hat_loss: 0.0042 - val_prod_q_hat_loss: 0.0112 - val_theta_or_hat_loss: 0.0142 - val_theta_ex_hat_loss: 0.0139\n",
      "Epoch 3/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1998 - a_or_hat_loss: 0.0299 - a_ex_hat_loss: 0.0318 - p_or_hat_loss: 0.0226 - p_ex_hat_loss: 0.0191 - q_ex_hat_loss: 0.0349 - q_or_hat_loss: 0.0242 - v_or_hat_loss: 5.7533e-04 - v_ex_hat_loss: 4.4245e-04 - load_v_hat_loss: 0.0034 - prod_q_hat_loss: 0.0096 - theta_or_hat_loss: 0.0119 - theta_ex_hat_loss: 0.0113 - val_loss: 0.1598 - val_a_or_hat_loss: 0.0264 - val_a_ex_hat_loss: 0.0252 - val_p_or_hat_loss: 0.0172 - val_p_ex_hat_loss: 0.0149 - val_q_ex_hat_loss: 0.0293 - val_q_or_hat_loss: 0.0193 - val_v_or_hat_loss: 3.6169e-04 - val_v_ex_hat_loss: 3.0055e-04 - val_load_v_hat_loss: 0.0028 - val_prod_q_hat_loss: 0.0076 - val_theta_or_hat_loss: 0.0082 - val_theta_ex_hat_loss: 0.0082\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1274 - a_or_hat_loss: 0.0194 - a_ex_hat_loss: 0.0195 - p_or_hat_loss: 0.0146 - p_ex_hat_loss: 0.0123 - q_ex_hat_loss: 0.0232 - q_or_hat_loss: 0.0152 - v_or_hat_loss: 3.1930e-04 - v_ex_hat_loss: 2.5127e-04 - load_v_hat_loss: 0.0024 - prod_q_hat_loss: 0.0070 - theta_or_hat_loss: 0.0068 - theta_ex_hat_loss: 0.0064 - val_loss: 0.1192 - val_a_or_hat_loss: 0.0201 - val_a_ex_hat_loss: 0.0178 - val_p_or_hat_loss: 0.0131 - val_p_ex_hat_loss: 0.0126 - val_q_ex_hat_loss: 0.0213 - val_q_or_hat_loss: 0.0136 - val_v_or_hat_loss: 2.4050e-04 - val_v_ex_hat_loss: 1.9913e-04 - val_load_v_hat_loss: 0.0019 - val_prod_q_hat_loss: 0.0064 - val_theta_or_hat_loss: 0.0058 - val_theta_ex_hat_loss: 0.0059\n",
      "Epoch 5/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0943 - a_or_hat_loss: 0.0148 - a_ex_hat_loss: 0.0141 - p_or_hat_loss: 0.0103 - p_ex_hat_loss: 0.0095 - q_ex_hat_loss: 0.0174 - q_or_hat_loss: 0.0114 - v_or_hat_loss: 2.0588e-04 - v_ex_hat_loss: 1.8246e-04 - load_v_hat_loss: 0.0017 - prod_q_hat_loss: 0.0055 - theta_or_hat_loss: 0.0046 - theta_ex_hat_loss: 0.0046 - val_loss: 0.0958 - val_a_or_hat_loss: 0.0160 - val_a_ex_hat_loss: 0.0148 - val_p_or_hat_loss: 0.0102 - val_p_ex_hat_loss: 0.0094 - val_q_ex_hat_loss: 0.0178 - val_q_or_hat_loss: 0.0117 - val_v_or_hat_loss: 1.6520e-04 - val_v_ex_hat_loss: 1.5253e-04 - val_load_v_hat_loss: 0.0017 - val_prod_q_hat_loss: 0.0050 - val_theta_or_hat_loss: 0.0044 - val_theta_ex_hat_loss: 0.0046\n",
      "Epoch 6/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0778 - a_or_hat_loss: 0.0121 - a_ex_hat_loss: 0.0115 - p_or_hat_loss: 0.0082 - p_ex_hat_loss: 0.0080 - q_ex_hat_loss: 0.0146 - q_or_hat_loss: 0.0095 - v_or_hat_loss: 1.5591e-04 - v_ex_hat_loss: 1.4861e-04 - load_v_hat_loss: 0.0014 - prod_q_hat_loss: 0.0047 - theta_or_hat_loss: 0.0037 - theta_ex_hat_loss: 0.0039 - val_loss: 0.0797 - val_a_or_hat_loss: 0.0128 - val_a_ex_hat_loss: 0.0121 - val_p_or_hat_loss: 0.0079 - val_p_ex_hat_loss: 0.0079 - val_q_ex_hat_loss: 0.0155 - val_q_or_hat_loss: 0.0098 - val_v_or_hat_loss: 1.3706e-04 - val_v_ex_hat_loss: 1.3298e-04 - val_load_v_hat_loss: 0.0013 - val_prod_q_hat_loss: 0.0044 - val_theta_or_hat_loss: 0.0039 - val_theta_ex_hat_loss: 0.0038\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0656 - a_or_hat_loss: 0.0101 - a_ex_hat_loss: 0.0097 - p_or_hat_loss: 0.0066 - p_ex_hat_loss: 0.0068 - q_ex_hat_loss: 0.0121 - q_or_hat_loss: 0.0083 - v_or_hat_loss: 1.2407e-04 - v_ex_hat_loss: 1.2888e-04 - load_v_hat_loss: 0.0012 - prod_q_hat_loss: 0.0041 - theta_or_hat_loss: 0.0031 - theta_ex_hat_loss: 0.0033 - val_loss: 0.0705 - val_a_or_hat_loss: 0.0114 - val_a_ex_hat_loss: 0.0104 - val_p_or_hat_loss: 0.0068 - val_p_ex_hat_loss: 0.0072 - val_q_ex_hat_loss: 0.0132 - val_q_or_hat_loss: 0.0088 - val_v_or_hat_loss: 1.8151e-04 - val_v_ex_hat_loss: 1.2155e-04 - val_load_v_hat_loss: 0.0012 - val_prod_q_hat_loss: 0.0040 - val_theta_or_hat_loss: 0.0037 - val_theta_ex_hat_loss: 0.0035\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0573 - a_or_hat_loss: 0.0087 - a_ex_hat_loss: 0.0084 - p_or_hat_loss: 0.0057 - p_ex_hat_loss: 0.0060 - q_ex_hat_loss: 0.0104 - q_or_hat_loss: 0.0074 - v_or_hat_loss: 1.0484e-04 - v_ex_hat_loss: 1.1862e-04 - load_v_hat_loss: 0.0011 - prod_q_hat_loss: 0.0036 - theta_or_hat_loss: 0.0028 - theta_ex_hat_loss: 0.0030 - val_loss: 0.0627 - val_a_or_hat_loss: 0.0095 - val_a_ex_hat_loss: 0.0096 - val_p_or_hat_loss: 0.0061 - val_p_ex_hat_loss: 0.0064 - val_q_ex_hat_loss: 0.0114 - val_q_or_hat_loss: 0.0080 - val_v_or_hat_loss: 1.1051e-04 - val_v_ex_hat_loss: 1.2441e-04 - val_load_v_hat_loss: 0.0017 - val_prod_q_hat_loss: 0.0035 - val_theta_or_hat_loss: 0.0031 - val_theta_ex_hat_loss: 0.0031\n",
      "Epoch 9/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0500 - a_or_hat_loss: 0.0074 - a_ex_hat_loss: 0.0074 - p_or_hat_loss: 0.0051 - p_ex_hat_loss: 0.0052 - q_ex_hat_loss: 0.0089 - q_or_hat_loss: 0.0067 - v_or_hat_loss: 9.5446e-05 - v_ex_hat_loss: 1.1400e-04 - load_v_hat_loss: 9.3011e-04 - prod_q_hat_loss: 0.0032 - theta_or_hat_loss: 0.0025 - theta_ex_hat_loss: 0.0026 - val_loss: 0.0567 - val_a_or_hat_loss: 0.0087 - val_a_ex_hat_loss: 0.0086 - val_p_or_hat_loss: 0.0059 - val_p_ex_hat_loss: 0.0063 - val_q_ex_hat_loss: 0.0101 - val_q_or_hat_loss: 0.0071 - val_v_or_hat_loss: 8.7127e-05 - val_v_ex_hat_loss: 1.0681e-04 - val_load_v_hat_loss: 9.2566e-04 - val_prod_q_hat_loss: 0.0035 - val_theta_or_hat_loss: 0.0026 - val_theta_ex_hat_loss: 0.0030\n",
      "Epoch 10/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0452 - a_or_hat_loss: 0.0068 - a_ex_hat_loss: 0.0067 - p_or_hat_loss: 0.0045 - p_ex_hat_loss: 0.0047 - q_ex_hat_loss: 0.0080 - q_or_hat_loss: 0.0060 - v_or_hat_loss: 7.5667e-05 - v_ex_hat_loss: 1.0037e-04 - load_v_hat_loss: 8.1419e-04 - prod_q_hat_loss: 0.0028 - theta_or_hat_loss: 0.0022 - theta_ex_hat_loss: 0.0023 - val_loss: 0.0552 - val_a_or_hat_loss: 0.0083 - val_a_ex_hat_loss: 0.0080 - val_p_or_hat_loss: 0.0048 - val_p_ex_hat_loss: 0.0056 - val_q_ex_hat_loss: 0.0096 - val_q_or_hat_loss: 0.0077 - val_v_or_hat_loss: 1.1118e-04 - val_v_ex_hat_loss: 1.9921e-04 - val_load_v_hat_loss: 9.8794e-04 - val_prod_q_hat_loss: 0.0032 - val_theta_or_hat_loss: 0.0036 - val_theta_ex_hat_loss: 0.0031\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0409 - a_or_hat_loss: 0.0063 - a_ex_hat_loss: 0.0062 - p_or_hat_loss: 0.0038 - p_ex_hat_loss: 0.0041 - q_ex_hat_loss: 0.0073 - q_or_hat_loss: 0.0057 - v_or_hat_loss: 7.4318e-05 - v_ex_hat_loss: 9.9531e-05 - load_v_hat_loss: 7.5809e-04 - prod_q_hat_loss: 0.0025 - theta_or_hat_loss: 0.0021 - theta_ex_hat_loss: 0.0021 - val_loss: 0.0455 - val_a_or_hat_loss: 0.0072 - val_a_ex_hat_loss: 0.0074 - val_p_or_hat_loss: 0.0041 - val_p_ex_hat_loss: 0.0043 - val_q_ex_hat_loss: 0.0083 - val_q_or_hat_loss: 0.0065 - val_v_or_hat_loss: 7.0889e-05 - val_v_ex_hat_loss: 8.0146e-05 - val_load_v_hat_loss: 6.9860e-04 - val_prod_q_hat_loss: 0.0024 - val_theta_or_hat_loss: 0.0022 - val_theta_ex_hat_loss: 0.0022\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0366 - a_or_hat_loss: 0.0057 - a_ex_hat_loss: 0.0057 - p_or_hat_loss: 0.0033 - p_ex_hat_loss: 0.0035 - q_ex_hat_loss: 0.0066 - q_or_hat_loss: 0.0051 - v_or_hat_loss: 7.7860e-05 - v_ex_hat_loss: 8.3674e-05 - load_v_hat_loss: 6.5095e-04 - prod_q_hat_loss: 0.0022 - theta_or_hat_loss: 0.0019 - theta_ex_hat_loss: 0.0019 - val_loss: 0.0421 - val_a_or_hat_loss: 0.0066 - val_a_ex_hat_loss: 0.0067 - val_p_or_hat_loss: 0.0040 - val_p_ex_hat_loss: 0.0045 - val_q_ex_hat_loss: 0.0074 - val_q_or_hat_loss: 0.0059 - val_v_or_hat_loss: 6.8312e-05 - val_v_ex_hat_loss: 8.3643e-05 - val_load_v_hat_loss: 6.1594e-04 - val_prod_q_hat_loss: 0.0022 - val_theta_or_hat_loss: 0.0021 - val_theta_ex_hat_loss: 0.0020\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0339 - a_or_hat_loss: 0.0053 - a_ex_hat_loss: 0.0053 - p_or_hat_loss: 0.0030 - p_ex_hat_loss: 0.0032 - q_ex_hat_loss: 0.0062 - q_or_hat_loss: 0.0048 - v_or_hat_loss: 5.7486e-05 - v_ex_hat_loss: 7.6823e-05 - load_v_hat_loss: 6.1839e-04 - prod_q_hat_loss: 0.0020 - theta_or_hat_loss: 0.0017 - theta_ex_hat_loss: 0.0017 - val_loss: 0.0396 - val_a_or_hat_loss: 0.0062 - val_a_ex_hat_loss: 0.0064 - val_p_or_hat_loss: 0.0038 - val_p_ex_hat_loss: 0.0041 - val_q_ex_hat_loss: 0.0071 - val_q_or_hat_loss: 0.0052 - val_v_or_hat_loss: 4.5927e-05 - val_v_ex_hat_loss: 8.0027e-05 - val_load_v_hat_loss: 5.8761e-04 - val_prod_q_hat_loss: 0.0020 - val_theta_or_hat_loss: 0.0020 - val_theta_ex_hat_loss: 0.0021\n",
      "Epoch 14/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0317 - a_or_hat_loss: 0.0050 - a_ex_hat_loss: 0.0050 - p_or_hat_loss: 0.0028 - p_ex_hat_loss: 0.0029 - q_ex_hat_loss: 0.0057 - q_or_hat_loss: 0.0044 - v_or_hat_loss: 5.3725e-05 - v_ex_hat_loss: 7.4588e-05 - load_v_hat_loss: 5.7453e-04 - prod_q_hat_loss: 0.0019 - theta_or_hat_loss: 0.0017 - theta_ex_hat_loss: 0.0016 - val_loss: 0.0371 - val_a_or_hat_loss: 0.0070 - val_a_ex_hat_loss: 0.0062 - val_p_or_hat_loss: 0.0031 - val_p_ex_hat_loss: 0.0033 - val_q_ex_hat_loss: 0.0061 - val_q_or_hat_loss: 0.0050 - val_v_or_hat_loss: 1.1810e-04 - val_v_ex_hat_loss: 1.0090e-04 - val_load_v_hat_loss: 5.5485e-04 - val_prod_q_hat_loss: 0.0022 - val_theta_or_hat_loss: 0.0018 - val_theta_ex_hat_loss: 0.0017\n",
      "Epoch 15/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0291 - a_or_hat_loss: 0.0047 - a_ex_hat_loss: 0.0047 - p_or_hat_loss: 0.0025 - p_ex_hat_loss: 0.0026 - q_ex_hat_loss: 0.0053 - q_or_hat_loss: 0.0041 - v_or_hat_loss: 5.3713e-05 - v_ex_hat_loss: 7.3373e-05 - load_v_hat_loss: 5.0977e-04 - prod_q_hat_loss: 0.0017 - theta_or_hat_loss: 0.0015 - theta_ex_hat_loss: 0.0015 - val_loss: 0.0349 - val_a_or_hat_loss: 0.0060 - val_a_ex_hat_loss: 0.0058 - val_p_or_hat_loss: 0.0029 - val_p_ex_hat_loss: 0.0030 - val_q_ex_hat_loss: 0.0061 - val_q_or_hat_loss: 0.0052 - val_v_or_hat_loss: 4.2939e-05 - val_v_ex_hat_loss: 5.7116e-05 - val_load_v_hat_loss: 4.9076e-04 - val_prod_q_hat_loss: 0.0017 - val_theta_or_hat_loss: 0.0018 - val_theta_ex_hat_loss: 0.0017\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0277 - a_or_hat_loss: 0.0044 - a_ex_hat_loss: 0.0045 - p_or_hat_loss: 0.0023 - p_ex_hat_loss: 0.0024 - q_ex_hat_loss: 0.0050 - q_or_hat_loss: 0.0040 - v_or_hat_loss: 4.7176e-05 - v_ex_hat_loss: 6.4364e-05 - load_v_hat_loss: 4.6965e-04 - prod_q_hat_loss: 0.0016 - theta_or_hat_loss: 0.0014 - theta_ex_hat_loss: 0.0014 - val_loss: 0.0347 - val_a_or_hat_loss: 0.0054 - val_a_ex_hat_loss: 0.0055 - val_p_or_hat_loss: 0.0029 - val_p_ex_hat_loss: 0.0031 - val_q_ex_hat_loss: 0.0063 - val_q_or_hat_loss: 0.0055 - val_v_or_hat_loss: 3.7353e-05 - val_v_ex_hat_loss: 6.2886e-05 - val_load_v_hat_loss: 5.5309e-04 - val_prod_q_hat_loss: 0.0020 - val_theta_or_hat_loss: 0.0018 - val_theta_ex_hat_loss: 0.0016\n",
      "Epoch 17/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0267 - a_or_hat_loss: 0.0042 - a_ex_hat_loss: 0.0043 - p_or_hat_loss: 0.0022 - p_ex_hat_loss: 0.0023 - q_ex_hat_loss: 0.0049 - q_or_hat_loss: 0.0039 - v_or_hat_loss: 4.7114e-05 - v_ex_hat_loss: 6.6357e-05 - load_v_hat_loss: 4.8559e-04 - prod_q_hat_loss: 0.0016 - theta_or_hat_loss: 0.0014 - theta_ex_hat_loss: 0.0014 - val_loss: 0.0298 - val_a_or_hat_loss: 0.0048 - val_a_ex_hat_loss: 0.0052 - val_p_or_hat_loss: 0.0024 - val_p_ex_hat_loss: 0.0026 - val_q_ex_hat_loss: 0.0054 - val_q_or_hat_loss: 0.0042 - val_v_or_hat_loss: 3.2021e-05 - val_v_ex_hat_loss: 5.6463e-05 - val_load_v_hat_loss: 4.4514e-04 - val_prod_q_hat_loss: 0.0017 - val_theta_or_hat_loss: 0.0015 - val_theta_ex_hat_loss: 0.0015\n",
      "Epoch 18/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0246 - a_or_hat_loss: 0.0040 - a_ex_hat_loss: 0.0040 - p_or_hat_loss: 0.0020 - p_ex_hat_loss: 0.0021 - q_ex_hat_loss: 0.0044 - q_or_hat_loss: 0.0036 - v_or_hat_loss: 4.1246e-05 - v_ex_hat_loss: 5.8896e-05 - load_v_hat_loss: 4.3091e-04 - prod_q_hat_loss: 0.0014 - theta_or_hat_loss: 0.0013 - theta_ex_hat_loss: 0.0012 - val_loss: 0.0302 - val_a_or_hat_loss: 0.0052 - val_a_ex_hat_loss: 0.0050 - val_p_or_hat_loss: 0.0024 - val_p_ex_hat_loss: 0.0030 - val_q_ex_hat_loss: 0.0049 - val_q_or_hat_loss: 0.0042 - val_v_or_hat_loss: 3.2532e-05 - val_v_ex_hat_loss: 5.1549e-05 - val_load_v_hat_loss: 6.7876e-04 - val_prod_q_hat_loss: 0.0018 - val_theta_or_hat_loss: 0.0014 - val_theta_ex_hat_loss: 0.0016\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0236 - a_or_hat_loss: 0.0039 - a_ex_hat_loss: 0.0039 - p_or_hat_loss: 0.0019 - p_ex_hat_loss: 0.0020 - q_ex_hat_loss: 0.0042 - q_or_hat_loss: 0.0034 - v_or_hat_loss: 4.0918e-05 - v_ex_hat_loss: 5.5614e-05 - load_v_hat_loss: 4.4626e-04 - prod_q_hat_loss: 0.0014 - theta_or_hat_loss: 0.0012 - theta_ex_hat_loss: 0.0012 - val_loss: 0.0279 - val_a_or_hat_loss: 0.0044 - val_a_ex_hat_loss: 0.0050 - val_p_or_hat_loss: 0.0021 - val_p_ex_hat_loss: 0.0024 - val_q_ex_hat_loss: 0.0049 - val_q_or_hat_loss: 0.0038 - val_v_or_hat_loss: 5.7895e-05 - val_v_ex_hat_loss: 6.0758e-05 - val_load_v_hat_loss: 4.6902e-04 - val_prod_q_hat_loss: 0.0015 - val_theta_or_hat_loss: 0.0019 - val_theta_ex_hat_loss: 0.0013\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0224 - a_or_hat_loss: 0.0037 - a_ex_hat_loss: 0.0037 - p_or_hat_loss: 0.0018 - p_ex_hat_loss: 0.0019 - q_ex_hat_loss: 0.0040 - q_or_hat_loss: 0.0032 - v_or_hat_loss: 3.7371e-05 - v_ex_hat_loss: 5.3824e-05 - load_v_hat_loss: 3.8893e-04 - prod_q_hat_loss: 0.0013 - theta_or_hat_loss: 0.0012 - theta_ex_hat_loss: 0.0011 - val_loss: 0.0267 - val_a_or_hat_loss: 0.0044 - val_a_ex_hat_loss: 0.0047 - val_p_or_hat_loss: 0.0020 - val_p_ex_hat_loss: 0.0022 - val_q_ex_hat_loss: 0.0046 - val_q_or_hat_loss: 0.0040 - val_v_or_hat_loss: 6.2453e-05 - val_v_ex_hat_loss: 1.0673e-04 - val_load_v_hat_loss: 4.5885e-04 - val_prod_q_hat_loss: 0.0015 - val_theta_or_hat_loss: 0.0014 - val_theta_ex_hat_loss: 0.0012\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0213 - a_or_hat_loss: 0.0036 - a_ex_hat_loss: 0.0035 - p_or_hat_loss: 0.0017 - p_ex_hat_loss: 0.0018 - q_ex_hat_loss: 0.0038 - q_or_hat_loss: 0.0030 - v_or_hat_loss: 3.5190e-05 - v_ex_hat_loss: 5.3190e-05 - load_v_hat_loss: 3.8466e-04 - prod_q_hat_loss: 0.0012 - theta_or_hat_loss: 0.0011 - theta_ex_hat_loss: 0.0010 - val_loss: 0.0250 - val_a_or_hat_loss: 0.0041 - val_a_ex_hat_loss: 0.0044 - val_p_or_hat_loss: 0.0020 - val_p_ex_hat_loss: 0.0022 - val_q_ex_hat_loss: 0.0047 - val_q_or_hat_loss: 0.0035 - val_v_or_hat_loss: 2.7375e-05 - val_v_ex_hat_loss: 5.0216e-05 - val_load_v_hat_loss: 4.1909e-04 - val_prod_q_hat_loss: 0.0012 - val_theta_or_hat_loss: 0.0012 - val_theta_ex_hat_loss: 0.0012\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0209 - a_or_hat_loss: 0.0035 - a_ex_hat_loss: 0.0034 - p_or_hat_loss: 0.0016 - p_ex_hat_loss: 0.0018 - q_ex_hat_loss: 0.0038 - q_or_hat_loss: 0.0030 - v_or_hat_loss: 3.3627e-05 - v_ex_hat_loss: 5.1181e-05 - load_v_hat_loss: 3.7672e-04 - prod_q_hat_loss: 0.0012 - theta_or_hat_loss: 0.0011 - theta_ex_hat_loss: 0.0010 - val_loss: 0.0240 - val_a_or_hat_loss: 0.0040 - val_a_ex_hat_loss: 0.0041 - val_p_or_hat_loss: 0.0020 - val_p_ex_hat_loss: 0.0020 - val_q_ex_hat_loss: 0.0044 - val_q_or_hat_loss: 0.0033 - val_v_or_hat_loss: 3.3401e-05 - val_v_ex_hat_loss: 4.6263e-05 - val_load_v_hat_loss: 3.6254e-04 - val_prod_q_hat_loss: 0.0014 - val_theta_or_hat_loss: 0.0012 - val_theta_ex_hat_loss: 0.0012\n",
      "Epoch 23/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0195 - a_or_hat_loss: 0.0033 - a_ex_hat_loss: 0.0032 - p_or_hat_loss: 0.0015 - p_ex_hat_loss: 0.0016 - q_ex_hat_loss: 0.0035 - q_or_hat_loss: 0.0028 - v_or_hat_loss: 3.2367e-05 - v_ex_hat_loss: 4.8467e-05 - load_v_hat_loss: 3.5581e-04 - prod_q_hat_loss: 0.0011 - theta_or_hat_loss: 0.0010 - theta_ex_hat_loss: 9.7729e-04 - val_loss: 0.0238 - val_a_or_hat_loss: 0.0039 - val_a_ex_hat_loss: 0.0041 - val_p_or_hat_loss: 0.0020 - val_p_ex_hat_loss: 0.0020 - val_q_ex_hat_loss: 0.0045 - val_q_or_hat_loss: 0.0033 - val_v_or_hat_loss: 2.8671e-05 - val_v_ex_hat_loss: 4.5152e-05 - val_load_v_hat_loss: 3.9762e-04 - val_prod_q_hat_loss: 0.0012 - val_theta_or_hat_loss: 0.0012 - val_theta_ex_hat_loss: 0.0011\n",
      "Epoch 24/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0188 - a_or_hat_loss: 0.0032 - a_ex_hat_loss: 0.0031 - p_or_hat_loss: 0.0014 - p_ex_hat_loss: 0.0016 - q_ex_hat_loss: 0.0034 - q_or_hat_loss: 0.0027 - v_or_hat_loss: 2.8897e-05 - v_ex_hat_loss: 4.6718e-05 - load_v_hat_loss: 3.2914e-04 - prod_q_hat_loss: 0.0011 - theta_or_hat_loss: 9.8909e-04 - theta_ex_hat_loss: 9.3842e-04 - val_loss: 0.0226 - val_a_or_hat_loss: 0.0037 - val_a_ex_hat_loss: 0.0039 - val_p_or_hat_loss: 0.0022 - val_p_ex_hat_loss: 0.0018 - val_q_ex_hat_loss: 0.0039 - val_q_or_hat_loss: 0.0029 - val_v_or_hat_loss: 2.0046e-05 - val_v_ex_hat_loss: 4.3165e-05 - val_load_v_hat_loss: 3.1850e-04 - val_prod_q_hat_loss: 0.0014 - val_theta_or_hat_loss: 0.0012 - val_theta_ex_hat_loss: 0.0012\n",
      "Epoch 25/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0185 - a_or_hat_loss: 0.0031 - a_ex_hat_loss: 0.0030 - p_or_hat_loss: 0.0014 - p_ex_hat_loss: 0.0015 - q_ex_hat_loss: 0.0033 - q_or_hat_loss: 0.0027 - v_or_hat_loss: 2.8146e-05 - v_ex_hat_loss: 4.4961e-05 - load_v_hat_loss: 3.5395e-04 - prod_q_hat_loss: 0.0011 - theta_or_hat_loss: 0.0010 - theta_ex_hat_loss: 9.5038e-04 - val_loss: 0.0210 - val_a_or_hat_loss: 0.0038 - val_a_ex_hat_loss: 0.0036 - val_p_or_hat_loss: 0.0016 - val_p_ex_hat_loss: 0.0018 - val_q_ex_hat_loss: 0.0035 - val_q_or_hat_loss: 0.0031 - val_v_or_hat_loss: 2.5066e-05 - val_v_ex_hat_loss: 4.9355e-05 - val_load_v_hat_loss: 3.4920e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 0.0010 - val_theta_ex_hat_loss: 0.0010\n",
      "Epoch 26/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0173 - a_or_hat_loss: 0.0030 - a_ex_hat_loss: 0.0029 - p_or_hat_loss: 0.0013 - p_ex_hat_loss: 0.0014 - q_ex_hat_loss: 0.0031 - q_or_hat_loss: 0.0025 - v_or_hat_loss: 2.3198e-05 - v_ex_hat_loss: 4.0795e-05 - load_v_hat_loss: 3.1003e-04 - prod_q_hat_loss: 9.7313e-04 - theta_or_hat_loss: 9.0501e-04 - theta_ex_hat_loss: 8.6719e-04 - val_loss: 0.0213 - val_a_or_hat_loss: 0.0036 - val_a_ex_hat_loss: 0.0039 - val_p_or_hat_loss: 0.0015 - val_p_ex_hat_loss: 0.0016 - val_q_ex_hat_loss: 0.0035 - val_q_or_hat_loss: 0.0030 - val_v_or_hat_loss: 2.2247e-05 - val_v_ex_hat_loss: 4.3597e-05 - val_load_v_hat_loss: 3.4418e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 0.0015 - val_theta_ex_hat_loss: 0.0012\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0170 - a_or_hat_loss: 0.0030 - a_ex_hat_loss: 0.0028 - p_or_hat_loss: 0.0013 - p_ex_hat_loss: 0.0014 - q_ex_hat_loss: 0.0030 - q_or_hat_loss: 0.0024 - v_or_hat_loss: 2.6943e-05 - v_ex_hat_loss: 4.3688e-05 - load_v_hat_loss: 3.1518e-04 - prod_q_hat_loss: 9.7270e-04 - theta_or_hat_loss: 9.1858e-04 - theta_ex_hat_loss: 8.4621e-04 - val_loss: 0.0208 - val_a_or_hat_loss: 0.0035 - val_a_ex_hat_loss: 0.0036 - val_p_or_hat_loss: 0.0015 - val_p_ex_hat_loss: 0.0018 - val_q_ex_hat_loss: 0.0035 - val_q_or_hat_loss: 0.0029 - val_v_or_hat_loss: 1.9888e-05 - val_v_ex_hat_loss: 3.7168e-05 - val_load_v_hat_loss: 4.1306e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 0.0012 - val_theta_ex_hat_loss: 0.0013\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0163 - a_or_hat_loss: 0.0029 - a_ex_hat_loss: 0.0027 - p_or_hat_loss: 0.0012 - p_ex_hat_loss: 0.0013 - q_ex_hat_loss: 0.0029 - q_or_hat_loss: 0.0023 - v_or_hat_loss: 2.3839e-05 - v_ex_hat_loss: 3.9582e-05 - load_v_hat_loss: 3.0801e-04 - prod_q_hat_loss: 9.3355e-04 - theta_or_hat_loss: 8.6204e-04 - theta_ex_hat_loss: 8.1559e-04 - val_loss: 0.0199 - val_a_or_hat_loss: 0.0034 - val_a_ex_hat_loss: 0.0035 - val_p_or_hat_loss: 0.0014 - val_p_ex_hat_loss: 0.0016 - val_q_ex_hat_loss: 0.0035 - val_q_or_hat_loss: 0.0031 - val_v_or_hat_loss: 2.2156e-05 - val_v_ex_hat_loss: 4.8042e-05 - val_load_v_hat_loss: 2.9616e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 9.9124e-04 - val_theta_ex_hat_loss: 9.4050e-04\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0160 - a_or_hat_loss: 0.0028 - a_ex_hat_loss: 0.0027 - p_or_hat_loss: 0.0012 - p_ex_hat_loss: 0.0013 - q_ex_hat_loss: 0.0028 - q_or_hat_loss: 0.0023 - v_or_hat_loss: 2.4146e-05 - v_ex_hat_loss: 4.1089e-05 - load_v_hat_loss: 2.8035e-04 - prod_q_hat_loss: 8.7720e-04 - theta_or_hat_loss: 8.3727e-04 - theta_ex_hat_loss: 7.8584e-04 - val_loss: 0.0193 - val_a_or_hat_loss: 0.0034 - val_a_ex_hat_loss: 0.0035 - val_p_or_hat_loss: 0.0014 - val_p_ex_hat_loss: 0.0017 - val_q_ex_hat_loss: 0.0032 - val_q_or_hat_loss: 0.0026 - val_v_or_hat_loss: 2.1333e-05 - val_v_ex_hat_loss: 3.8519e-05 - val_load_v_hat_loss: 4.5575e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 0.0011 - val_theta_ex_hat_loss: 9.0233e-04\n",
      "Epoch 30/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0155 - a_or_hat_loss: 0.0027 - a_ex_hat_loss: 0.0026 - p_or_hat_loss: 0.0012 - p_ex_hat_loss: 0.0012 - q_ex_hat_loss: 0.0027 - q_or_hat_loss: 0.0022 - v_or_hat_loss: 2.3397e-05 - v_ex_hat_loss: 3.9224e-05 - load_v_hat_loss: 2.7771e-04 - prod_q_hat_loss: 8.9386e-04 - theta_or_hat_loss: 7.8741e-04 - theta_ex_hat_loss: 7.4331e-04 - val_loss: 0.0187 - val_a_or_hat_loss: 0.0035 - val_a_ex_hat_loss: 0.0032 - val_p_or_hat_loss: 0.0015 - val_p_ex_hat_loss: 0.0014 - val_q_ex_hat_loss: 0.0032 - val_q_or_hat_loss: 0.0027 - val_v_or_hat_loss: 1.8553e-05 - val_v_ex_hat_loss: 4.1361e-05 - val_load_v_hat_loss: 2.6192e-04 - val_prod_q_hat_loss: 0.0011 - val_theta_or_hat_loss: 9.4675e-04 - val_theta_ex_hat_loss: 8.3576e-04\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0152 - a_or_hat_loss: 0.0027 - a_ex_hat_loss: 0.0025 - p_or_hat_loss: 0.0011 - p_ex_hat_loss: 0.0012 - q_ex_hat_loss: 0.0027 - q_or_hat_loss: 0.0022 - v_or_hat_loss: 2.2738e-05 - v_ex_hat_loss: 3.8340e-05 - load_v_hat_loss: 2.9525e-04 - prod_q_hat_loss: 8.6586e-04 - theta_or_hat_loss: 8.1332e-04 - theta_ex_hat_loss: 7.6484e-04 - val_loss: 0.0175 - val_a_or_hat_loss: 0.0032 - val_a_ex_hat_loss: 0.0031 - val_p_or_hat_loss: 0.0013 - val_p_ex_hat_loss: 0.0013 - val_q_ex_hat_loss: 0.0030 - val_q_or_hat_loss: 0.0025 - val_v_or_hat_loss: 2.0757e-05 - val_v_ex_hat_loss: 3.6645e-05 - val_load_v_hat_loss: 3.1031e-04 - val_prod_q_hat_loss: 9.3260e-04 - val_theta_or_hat_loss: 9.7567e-04 - val_theta_ex_hat_loss: 8.2501e-04\n",
      "Epoch 32/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0145 - a_or_hat_loss: 0.0026 - a_ex_hat_loss: 0.0025 - p_or_hat_loss: 0.0011 - p_ex_hat_loss: 0.0011 - q_ex_hat_loss: 0.0025 - q_or_hat_loss: 0.0021 - v_or_hat_loss: 2.0830e-05 - v_ex_hat_loss: 3.7278e-05 - load_v_hat_loss: 2.7895e-04 - prod_q_hat_loss: 8.2793e-04 - theta_or_hat_loss: 7.8742e-04 - theta_ex_hat_loss: 7.0840e-04 - val_loss: 0.0178 - val_a_or_hat_loss: 0.0033 - val_a_ex_hat_loss: 0.0033 - val_p_or_hat_loss: 0.0013 - val_p_ex_hat_loss: 0.0012 - val_q_ex_hat_loss: 0.0031 - val_q_or_hat_loss: 0.0025 - val_v_or_hat_loss: 1.2657e-05 - val_v_ex_hat_loss: 3.3741e-05 - val_load_v_hat_loss: 3.0222e-04 - val_prod_q_hat_loss: 9.7585e-04 - val_theta_or_hat_loss: 9.1580e-04 - val_theta_ex_hat_loss: 8.4875e-04\n",
      "Epoch 33/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0143 - a_or_hat_loss: 0.0026 - a_ex_hat_loss: 0.0024 - p_or_hat_loss: 0.0011 - p_ex_hat_loss: 0.0011 - q_ex_hat_loss: 0.0025 - q_or_hat_loss: 0.0020 - v_or_hat_loss: 2.0480e-05 - v_ex_hat_loss: 3.6644e-05 - load_v_hat_loss: 2.6638e-04 - prod_q_hat_loss: 8.0570e-04 - theta_or_hat_loss: 7.6358e-04 - theta_ex_hat_loss: 7.0305e-04 - val_loss: 0.0174 - val_a_or_hat_loss: 0.0033 - val_a_ex_hat_loss: 0.0032 - val_p_or_hat_loss: 0.0013 - val_p_ex_hat_loss: 0.0013 - val_q_ex_hat_loss: 0.0028 - val_q_or_hat_loss: 0.0027 - val_v_or_hat_loss: 2.1842e-05 - val_v_ex_hat_loss: 3.4494e-05 - val_load_v_hat_loss: 2.8030e-04 - val_prod_q_hat_loss: 8.3599e-04 - val_theta_or_hat_loss: 9.1357e-04 - val_theta_ex_hat_loss: 8.0758e-04\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0141 - a_or_hat_loss: 0.0025 - a_ex_hat_loss: 0.0024 - p_or_hat_loss: 0.0010 - p_ex_hat_loss: 0.0010 - q_ex_hat_loss: 0.0024 - q_or_hat_loss: 0.0020 - v_or_hat_loss: 1.9956e-05 - v_ex_hat_loss: 3.4670e-05 - load_v_hat_loss: 2.8004e-04 - prod_q_hat_loss: 7.8479e-04 - theta_or_hat_loss: 7.6567e-04 - theta_ex_hat_loss: 7.1474e-04 - val_loss: 0.0165 - val_a_or_hat_loss: 0.0031 - val_a_ex_hat_loss: 0.0030 - val_p_or_hat_loss: 0.0013 - val_p_ex_hat_loss: 0.0012 - val_q_ex_hat_loss: 0.0028 - val_q_or_hat_loss: 0.0023 - val_v_or_hat_loss: 1.4022e-05 - val_v_ex_hat_loss: 3.7533e-05 - val_load_v_hat_loss: 3.0891e-04 - val_prod_q_hat_loss: 8.0895e-04 - val_theta_or_hat_loss: 8.6449e-04 - val_theta_ex_hat_loss: 7.8356e-04\n",
      "Epoch 35/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0137 - a_or_hat_loss: 0.0025 - a_ex_hat_loss: 0.0024 - p_or_hat_loss: 0.0011 - p_ex_hat_loss: 0.0010 - q_ex_hat_loss: 0.0023 - q_or_hat_loss: 0.0020 - v_or_hat_loss: 2.0329e-05 - v_ex_hat_loss: 3.5241e-05 - load_v_hat_loss: 2.5442e-04 - prod_q_hat_loss: 7.5539e-04 - theta_or_hat_loss: 7.4298e-04 - theta_ex_hat_loss: 6.7606e-04 - val_loss: 0.0177 - val_a_or_hat_loss: 0.0032 - val_a_ex_hat_loss: 0.0031 - val_p_or_hat_loss: 0.0015 - val_p_ex_hat_loss: 0.0013 - val_q_ex_hat_loss: 0.0030 - val_q_or_hat_loss: 0.0023 - val_v_or_hat_loss: 4.1036e-05 - val_v_ex_hat_loss: 7.8897e-05 - val_load_v_hat_loss: 2.8941e-04 - val_prod_q_hat_loss: 0.0010 - val_theta_or_hat_loss: 0.0010 - val_theta_ex_hat_loss: 8.6327e-04\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0134 - a_or_hat_loss: 0.0024 - a_ex_hat_loss: 0.0023 - p_or_hat_loss: 0.0010 - p_ex_hat_loss: 9.9520e-04 - q_ex_hat_loss: 0.0023 - q_or_hat_loss: 0.0019 - v_or_hat_loss: 2.0195e-05 - v_ex_hat_loss: 3.4322e-05 - load_v_hat_loss: 2.4181e-04 - prod_q_hat_loss: 7.4673e-04 - theta_or_hat_loss: 7.2257e-04 - theta_ex_hat_loss: 6.5856e-04 - val_loss: 0.0160 - val_a_or_hat_loss: 0.0029 - val_a_ex_hat_loss: 0.0030 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0012 - val_q_ex_hat_loss: 0.0027 - val_q_or_hat_loss: 0.0022 - val_v_or_hat_loss: 1.9535e-05 - val_v_ex_hat_loss: 3.3912e-05 - val_load_v_hat_loss: 2.6711e-04 - val_prod_q_hat_loss: 8.9007e-04 - val_theta_or_hat_loss: 8.6231e-04 - val_theta_ex_hat_loss: 9.0500e-04\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0130 - a_or_hat_loss: 0.0024 - a_ex_hat_loss: 0.0023 - p_or_hat_loss: 9.3794e-04 - p_ex_hat_loss: 9.4036e-04 - q_ex_hat_loss: 0.0022 - q_or_hat_loss: 0.0019 - v_or_hat_loss: 1.8420e-05 - v_ex_hat_loss: 3.2829e-05 - load_v_hat_loss: 2.4984e-04 - prod_q_hat_loss: 7.3489e-04 - theta_or_hat_loss: 7.1920e-04 - theta_ex_hat_loss: 6.7077e-04 - val_loss: 0.0153 - val_a_or_hat_loss: 0.0029 - val_a_ex_hat_loss: 0.0028 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0025 - val_q_or_hat_loss: 0.0021 - val_v_or_hat_loss: 1.6016e-05 - val_v_ex_hat_loss: 3.3640e-05 - val_load_v_hat_loss: 4.1859e-04 - val_prod_q_hat_loss: 7.9373e-04 - val_theta_or_hat_loss: 7.6997e-04 - val_theta_ex_hat_loss: 6.8563e-04\n",
      "Epoch 38/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0126 - a_or_hat_loss: 0.0023 - a_ex_hat_loss: 0.0022 - p_or_hat_loss: 9.3902e-04 - p_ex_hat_loss: 9.3469e-04 - q_ex_hat_loss: 0.0021 - q_or_hat_loss: 0.0018 - v_or_hat_loss: 1.6338e-05 - v_ex_hat_loss: 3.0498e-05 - load_v_hat_loss: 2.3822e-04 - prod_q_hat_loss: 7.0935e-04 - theta_or_hat_loss: 6.6688e-04 - theta_ex_hat_loss: 6.2739e-04 - val_loss: 0.0156 - val_a_or_hat_loss: 0.0032 - val_a_ex_hat_loss: 0.0028 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0012 - val_q_ex_hat_loss: 0.0023 - val_q_or_hat_loss: 0.0023 - val_v_or_hat_loss: 2.8559e-05 - val_v_ex_hat_loss: 3.0994e-05 - val_load_v_hat_loss: 2.9066e-04 - val_prod_q_hat_loss: 8.6669e-04 - val_theta_or_hat_loss: 7.9501e-04 - val_theta_ex_hat_loss: 7.1203e-04\n",
      "Epoch 39/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0123 - a_or_hat_loss: 0.0023 - a_ex_hat_loss: 0.0022 - p_or_hat_loss: 9.1587e-04 - p_ex_hat_loss: 9.0362e-04 - q_ex_hat_loss: 0.0021 - q_or_hat_loss: 0.0018 - v_or_hat_loss: 1.7934e-05 - v_ex_hat_loss: 3.1373e-05 - load_v_hat_loss: 2.2563e-04 - prod_q_hat_loss: 6.7171e-04 - theta_or_hat_loss: 6.5410e-04 - theta_ex_hat_loss: 6.0448e-04 - val_loss: 0.0152 - val_a_or_hat_loss: 0.0028 - val_a_ex_hat_loss: 0.0028 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0027 - val_q_or_hat_loss: 0.0022 - val_v_or_hat_loss: 1.6688e-05 - val_v_ex_hat_loss: 3.2906e-05 - val_load_v_hat_loss: 2.3208e-04 - val_prod_q_hat_loss: 7.8931e-04 - val_theta_or_hat_loss: 8.0121e-04 - val_theta_ex_hat_loss: 7.6632e-04\n",
      "Epoch 40/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0120 - a_or_hat_loss: 0.0022 - a_ex_hat_loss: 0.0021 - p_or_hat_loss: 8.9251e-04 - p_ex_hat_loss: 8.6668e-04 - q_ex_hat_loss: 0.0020 - q_or_hat_loss: 0.0017 - v_or_hat_loss: 1.6437e-05 - v_ex_hat_loss: 2.9929e-05 - load_v_hat_loss: 2.1644e-04 - prod_q_hat_loss: 6.6859e-04 - theta_or_hat_loss: 6.5721e-04 - theta_ex_hat_loss: 5.9181e-04 - val_loss: 0.0152 - val_a_or_hat_loss: 0.0027 - val_a_ex_hat_loss: 0.0028 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0025 - val_q_or_hat_loss: 0.0021 - val_v_or_hat_loss: 1.2343e-05 - val_v_ex_hat_loss: 2.6370e-05 - val_load_v_hat_loss: 2.9903e-04 - val_prod_q_hat_loss: 9.3595e-04 - val_theta_or_hat_loss: 8.2667e-04 - val_theta_ex_hat_loss: 7.6298e-04\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0120 - a_or_hat_loss: 0.0022 - a_ex_hat_loss: 0.0021 - p_or_hat_loss: 9.0817e-04 - p_ex_hat_loss: 8.7936e-04 - q_ex_hat_loss: 0.0020 - q_or_hat_loss: 0.0017 - v_or_hat_loss: 1.5961e-05 - v_ex_hat_loss: 2.9457e-05 - load_v_hat_loss: 2.2329e-04 - prod_q_hat_loss: 6.6255e-04 - theta_or_hat_loss: 6.1687e-04 - theta_ex_hat_loss: 5.7969e-04 - val_loss: 0.0154 - val_a_or_hat_loss: 0.0029 - val_a_ex_hat_loss: 0.0030 - val_p_or_hat_loss: 0.0010 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0027 - val_q_or_hat_loss: 0.0021 - val_v_or_hat_loss: 1.9505e-05 - val_v_ex_hat_loss: 3.8479e-05 - val_load_v_hat_loss: 2.0291e-04 - val_prod_q_hat_loss: 8.3439e-04 - val_theta_or_hat_loss: 8.0765e-04 - val_theta_ex_hat_loss: 6.4955e-04\n",
      "Epoch 42/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0118 - a_or_hat_loss: 0.0022 - a_ex_hat_loss: 0.0021 - p_or_hat_loss: 8.9191e-04 - p_ex_hat_loss: 8.5096e-04 - q_ex_hat_loss: 0.0020 - q_or_hat_loss: 0.0017 - v_or_hat_loss: 1.9868e-05 - v_ex_hat_loss: 3.2538e-05 - load_v_hat_loss: 2.1047e-04 - prod_q_hat_loss: 6.4748e-04 - theta_or_hat_loss: 6.2452e-04 - theta_ex_hat_loss: 5.7082e-04 - val_loss: 0.0141 - val_a_or_hat_loss: 0.0026 - val_a_ex_hat_loss: 0.0027 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0010 - val_q_ex_hat_loss: 0.0024 - val_q_or_hat_loss: 0.0020 - val_v_or_hat_loss: 9.3670e-06 - val_v_ex_hat_loss: 2.3989e-05 - val_load_v_hat_loss: 2.2685e-04 - val_prod_q_hat_loss: 8.1742e-04 - val_theta_or_hat_loss: 7.1751e-04 - val_theta_ex_hat_loss: 6.4866e-04\n",
      "Epoch 43/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0115 - a_or_hat_loss: 0.0021 - a_ex_hat_loss: 0.0021 - p_or_hat_loss: 8.5492e-04 - p_ex_hat_loss: 8.1507e-04 - q_ex_hat_loss: 0.0019 - q_or_hat_loss: 0.0016 - v_or_hat_loss: 1.6008e-05 - v_ex_hat_loss: 2.8606e-05 - load_v_hat_loss: 2.0756e-04 - prod_q_hat_loss: 6.0995e-04 - theta_or_hat_loss: 6.1108e-04 - theta_ex_hat_loss: 5.5895e-04 - val_loss: 0.0133 - val_a_or_hat_loss: 0.0026 - val_a_ex_hat_loss: 0.0025 - val_p_or_hat_loss: 0.0010 - val_p_ex_hat_loss: 9.2151e-04 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 1.0132e-05 - val_v_ex_hat_loss: 2.3393e-05 - val_load_v_hat_loss: 2.1383e-04 - val_prod_q_hat_loss: 8.9430e-04 - val_theta_or_hat_loss: 6.4806e-04 - val_theta_ex_hat_loss: 6.5647e-04\n",
      "Epoch 44/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0114 - a_or_hat_loss: 0.0021 - a_ex_hat_loss: 0.0021 - p_or_hat_loss: 8.4593e-04 - p_ex_hat_loss: 8.1489e-04 - q_ex_hat_loss: 0.0019 - q_or_hat_loss: 0.0016 - v_or_hat_loss: 1.4447e-05 - v_ex_hat_loss: 2.7419e-05 - load_v_hat_loss: 1.9708e-04 - prod_q_hat_loss: 5.9612e-04 - theta_or_hat_loss: 6.1247e-04 - theta_ex_hat_loss: 5.5771e-04 - val_loss: 0.0140 - val_a_or_hat_loss: 0.0027 - val_a_ex_hat_loss: 0.0026 - val_p_or_hat_loss: 0.0010 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0022 - val_q_or_hat_loss: 0.0019 - val_v_or_hat_loss: 1.2535e-05 - val_v_ex_hat_loss: 2.3135e-05 - val_load_v_hat_loss: 2.0724e-04 - val_prod_q_hat_loss: 7.6417e-04 - val_theta_or_hat_loss: 7.4755e-04 - val_theta_ex_hat_loss: 6.8406e-04\n",
      "Epoch 45/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0112 - a_or_hat_loss: 0.0021 - a_ex_hat_loss: 0.0020 - p_or_hat_loss: 8.5162e-04 - p_ex_hat_loss: 8.1758e-04 - q_ex_hat_loss: 0.0018 - q_or_hat_loss: 0.0016 - v_or_hat_loss: 1.5136e-05 - v_ex_hat_loss: 2.6898e-05 - load_v_hat_loss: 2.0182e-04 - prod_q_hat_loss: 5.7927e-04 - theta_or_hat_loss: 5.9787e-04 - theta_ex_hat_loss: 5.4868e-04 - val_loss: 0.0137 - val_a_or_hat_loss: 0.0027 - val_a_ex_hat_loss: 0.0026 - val_p_or_hat_loss: 0.0012 - val_p_ex_hat_loss: 9.4731e-04 - val_q_ex_hat_loss: 0.0022 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 3.3233e-05 - val_v_ex_hat_loss: 3.7052e-05 - val_load_v_hat_loss: 2.1697e-04 - val_prod_q_hat_loss: 6.7580e-04 - val_theta_or_hat_loss: 6.7133e-04 - val_theta_ex_hat_loss: 6.8212e-04\n",
      "Epoch 46/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0114 - a_or_hat_loss: 0.0021 - a_ex_hat_loss: 0.0020 - p_or_hat_loss: 8.5111e-04 - p_ex_hat_loss: 8.1941e-04 - q_ex_hat_loss: 0.0019 - q_or_hat_loss: 0.0016 - v_or_hat_loss: 1.7553e-05 - v_ex_hat_loss: 2.8993e-05 - load_v_hat_loss: 2.0369e-04 - prod_q_hat_loss: 6.1349e-04 - theta_or_hat_loss: 6.0961e-04 - theta_ex_hat_loss: 5.6064e-04 - val_loss: 0.0159 - val_a_or_hat_loss: 0.0034 - val_a_ex_hat_loss: 0.0031 - val_p_or_hat_loss: 0.0010 - val_p_ex_hat_loss: 0.0010 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0022 - val_v_or_hat_loss: 1.3986e-05 - val_v_ex_hat_loss: 2.4497e-05 - val_load_v_hat_loss: 2.7667e-04 - val_prod_q_hat_loss: 9.5823e-04 - val_theta_or_hat_loss: 0.0010 - val_theta_ex_hat_loss: 7.2096e-04\n",
      "Epoch 47/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0112 - a_or_hat_loss: 0.0021 - a_ex_hat_loss: 0.0020 - p_or_hat_loss: 8.2997e-04 - p_ex_hat_loss: 8.3063e-04 - q_ex_hat_loss: 0.0018 - q_or_hat_loss: 0.0016 - v_or_hat_loss: 1.5869e-05 - v_ex_hat_loss: 2.7608e-05 - load_v_hat_loss: 2.1276e-04 - prod_q_hat_loss: 5.9759e-04 - theta_or_hat_loss: 6.0558e-04 - theta_ex_hat_loss: 5.5713e-04 - val_loss: 0.0146 - val_a_or_hat_loss: 0.0026 - val_a_ex_hat_loss: 0.0024 - val_p_or_hat_loss: 0.0013 - val_p_ex_hat_loss: 0.0015 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0021 - val_v_or_hat_loss: 9.4574e-06 - val_v_ex_hat_loss: 2.1834e-05 - val_load_v_hat_loss: 2.3264e-04 - val_prod_q_hat_loss: 9.1706e-04 - val_theta_or_hat_loss: 8.0625e-04 - val_theta_ex_hat_loss: 6.7179e-04\n",
      "Epoch 48/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0106 - a_or_hat_loss: 0.0020 - a_ex_hat_loss: 0.0019 - p_or_hat_loss: 8.0483e-04 - p_ex_hat_loss: 7.6894e-04 - q_ex_hat_loss: 0.0017 - q_or_hat_loss: 0.0015 - v_or_hat_loss: 1.2797e-05 - v_ex_hat_loss: 2.4449e-05 - load_v_hat_loss: 1.8241e-04 - prod_q_hat_loss: 5.6465e-04 - theta_or_hat_loss: 5.4825e-04 - theta_ex_hat_loss: 5.0554e-04 - val_loss: 0.0131 - val_a_or_hat_loss: 0.0024 - val_a_ex_hat_loss: 0.0025 - val_p_or_hat_loss: 9.0270e-04 - val_p_ex_hat_loss: 8.7985e-04 - val_q_ex_hat_loss: 0.0020 - val_q_or_hat_loss: 0.0019 - val_v_or_hat_loss: 8.3561e-06 - val_v_ex_hat_loss: 2.1098e-05 - val_load_v_hat_loss: 4.0413e-04 - val_prod_q_hat_loss: 6.6567e-04 - val_theta_or_hat_loss: 7.7318e-04 - val_theta_ex_hat_loss: 5.7487e-0404 - q_ex_hat_loss: 0.0018 - q_or_hat_loss: 0.0015 - v_or_hat_loss: 1.2486e-05 - v_ex_hat_loss: 2.4163e-05 - load_v_hat_loss: 1.8230e-04 - prod_q_hat_loss: 5.7091e-04 - th\n",
      "Epoch 49/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0105 - a_or_hat_loss: 0.0020 - a_ex_hat_loss: 0.0019 - p_or_hat_loss: 7.7545e-04 - p_ex_hat_loss: 7.4021e-04 - q_ex_hat_loss: 0.0017 - q_or_hat_loss: 0.0015 - v_or_hat_loss: 1.3908e-05 - v_ex_hat_loss: 2.5146e-05 - load_v_hat_loss: 2.0715e-04 - prod_q_hat_loss: 5.7142e-04 - theta_or_hat_loss: 5.3464e-04 - theta_ex_hat_loss: 4.9713e-04 - val_loss: 0.0127 - val_a_or_hat_loss: 0.0026 - val_a_ex_hat_loss: 0.0025 - val_p_or_hat_loss: 8.6241e-04 - val_p_ex_hat_loss: 8.8944e-04 - val_q_ex_hat_loss: 0.0020 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 1.3752e-05 - val_v_ex_hat_loss: 2.8204e-05 - val_load_v_hat_loss: 1.8766e-04 - val_prod_q_hat_loss: 6.2823e-04 - val_theta_or_hat_loss: 6.4727e-04 - val_theta_ex_hat_loss: 5.9156e-04\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0103 - a_or_hat_loss: 0.0020 - a_ex_hat_loss: 0.0019 - p_or_hat_loss: 7.5847e-04 - p_ex_hat_loss: 7.2706e-04 - q_ex_hat_loss: 0.0017 - q_or_hat_loss: 0.0015 - v_or_hat_loss: 1.4613e-05 - v_ex_hat_loss: 2.5826e-05 - load_v_hat_loss: 1.7998e-04 - prod_q_hat_loss: 5.2371e-04 - theta_or_hat_loss: 5.3762e-04 - theta_ex_hat_loss: 4.9454e-04 - val_loss: 0.0128 - val_a_or_hat_loss: 0.0023 - val_a_ex_hat_loss: 0.0023 - val_p_or_hat_loss: 9.9255e-04 - val_p_ex_hat_loss: 8.7509e-04 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 1.0873e-05 - val_v_ex_hat_loss: 2.3081e-05 - val_load_v_hat_loss: 1.9735e-04 - val_prod_q_hat_loss: 9.4454e-04 - val_theta_or_hat_loss: 6.9144e-04 - val_theta_ex_hat_loss: 6.0515e-04\n",
      "Epoch 51/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0103 - a_or_hat_loss: 0.0019 - a_ex_hat_loss: 0.0019 - p_or_hat_loss: 7.5705e-04 - p_ex_hat_loss: 7.3318e-04 - q_ex_hat_loss: 0.0017 - q_or_hat_loss: 0.0015 - v_or_hat_loss: 1.3132e-05 - v_ex_hat_loss: 2.4127e-05 - load_v_hat_loss: 1.8234e-04 - prod_q_hat_loss: 5.5255e-04 - theta_or_hat_loss: 5.4545e-04 - theta_ex_hat_loss: 4.9920e-04 - val_loss: 0.0126 - val_a_or_hat_loss: 0.0024 - val_a_ex_hat_loss: 0.0024 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 8.4991e-04 - val_q_ex_hat_loss: 0.0019 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 9.2556e-06 - val_v_ex_hat_loss: 2.3045e-05 - val_load_v_hat_loss: 1.9177e-04 - val_prod_q_hat_loss: 8.2731e-04 - val_theta_or_hat_loss: 6.3627e-04 - val_theta_ex_hat_loss: 5.9793e-04\n",
      "Epoch 52/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0100 - a_or_hat_loss: 0.0019 - a_ex_hat_loss: 0.0018 - p_or_hat_loss: 7.5307e-04 - p_ex_hat_loss: 7.1475e-04 - q_ex_hat_loss: 0.0016 - q_or_hat_loss: 0.0014 - v_or_hat_loss: 1.4129e-05 - v_ex_hat_loss: 2.5241e-05 - load_v_hat_loss: 1.7812e-04 - prod_q_hat_loss: 5.3552e-04 - theta_or_hat_loss: 5.1200e-04 - theta_ex_hat_loss: 4.7814e-04 - val_loss: 0.0125 - val_a_or_hat_loss: 0.0024 - val_a_ex_hat_loss: 0.0025 - val_p_or_hat_loss: 8.6806e-04 - val_p_ex_hat_loss: 9.1761e-04 - val_q_ex_hat_loss: 0.0020 - val_q_or_hat_loss: 0.0017 - val_v_or_hat_loss: 1.1585e-05 - val_v_ex_hat_loss: 2.1915e-05 - val_load_v_hat_loss: 2.1981e-04 - val_prod_q_hat_loss: 6.0540e-04 - val_theta_or_hat_loss: 6.6900e-04 - val_theta_ex_hat_loss: 5.9707e-04\n",
      "Epoch 53/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0100 - a_or_hat_loss: 0.0019 - a_ex_hat_loss: 0.0018 - p_or_hat_loss: 7.4195e-04 - p_ex_hat_loss: 7.1937e-04 - q_ex_hat_loss: 0.0016 - q_or_hat_loss: 0.0014 - v_or_hat_loss: 1.3025e-05 - v_ex_hat_loss: 2.3251e-05 - load_v_hat_loss: 1.7100e-04 - prod_q_hat_loss: 5.0849e-04 - theta_or_hat_loss: 5.1660e-04 - theta_ex_hat_loss: 4.8624e-04 - val_loss: 0.0125 - val_a_or_hat_loss: 0.0023 - val_a_ex_hat_loss: 0.0023 - val_p_or_hat_loss: 9.8983e-04 - val_p_ex_hat_loss: 8.4336e-04 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0017 - val_v_or_hat_loss: 9.1360e-06 - val_v_ex_hat_loss: 2.4136e-05 - val_load_v_hat_loss: 2.1925e-04 - val_prod_q_hat_loss: 8.3858e-04 - val_theta_or_hat_loss: 6.9036e-04 - val_theta_ex_hat_loss: 5.5364e-04\n",
      "Epoch 54/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0099 - a_or_hat_loss: 0.0019 - a_ex_hat_loss: 0.0018 - p_or_hat_loss: 7.5306e-04 - p_ex_hat_loss: 7.1805e-04 - q_ex_hat_loss: 0.0016 - q_or_hat_loss: 0.0014 - v_or_hat_loss: 1.4680e-05 - v_ex_hat_loss: 2.4993e-05 - load_v_hat_loss: 1.6949e-04 - prod_q_hat_loss: 5.1959e-04 - theta_or_hat_loss: 5.1302e-04 - theta_ex_hat_loss: 4.6989e-04 - val_loss: 0.0129 - val_a_or_hat_loss: 0.0024 - val_a_ex_hat_loss: 0.0023 - val_p_or_hat_loss: 9.8206e-04 - val_p_ex_hat_loss: 9.0656e-04 - val_q_ex_hat_loss: 0.0021 - val_q_or_hat_loss: 0.0017 - val_v_or_hat_loss: 2.4684e-05 - val_v_ex_hat_loss: 3.3964e-05 - val_load_v_hat_loss: 2.0952e-04 - val_prod_q_hat_loss: 5.6914e-04 - val_theta_or_hat_loss: 9.7241e-04 - val_theta_ex_hat_loss: 7.1620e-04\n",
      "Epoch 55/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0097 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0018 - p_or_hat_loss: 7.2453e-04 - p_ex_hat_loss: 6.8820e-04 - q_ex_hat_loss: 0.0016 - q_or_hat_loss: 0.0014 - v_or_hat_loss: 1.3805e-05 - v_ex_hat_loss: 2.3730e-05 - load_v_hat_loss: 1.6443e-04 - prod_q_hat_loss: 4.9292e-04 - theta_or_hat_loss: 5.1991e-04 - theta_ex_hat_loss: 4.7234e-04 - val_loss: 0.0125 - val_a_or_hat_loss: 0.0024 - val_a_ex_hat_loss: 0.0023 - val_p_or_hat_loss: 8.8316e-04 - val_p_ex_hat_loss: 8.8590e-04 - val_q_ex_hat_loss: 0.0019 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 1.2846e-05 - val_v_ex_hat_loss: 2.2045e-05 - val_load_v_hat_loss: 2.1236e-04 - val_prod_q_hat_loss: 7.7698e-04 - val_theta_or_hat_loss: 6.8887e-04 - val_theta_ex_hat_loss: 6.3900e-04\n",
      "Epoch 56/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0095 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0018 - p_or_hat_loss: 7.1349e-04 - p_ex_hat_loss: 6.7243e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0014 - v_or_hat_loss: 1.1948e-05 - v_ex_hat_loss: 2.1749e-05 - load_v_hat_loss: 1.7747e-04 - prod_q_hat_loss: 5.0208e-04 - theta_or_hat_loss: 4.8684e-04 - theta_ex_hat_loss: 4.4620e-04 - val_loss: 0.0115 - val_a_or_hat_loss: 0.0023 - val_a_ex_hat_loss: 0.0024 - val_p_or_hat_loss: 8.2852e-04 - val_p_ex_hat_loss: 7.9964e-04 - val_q_ex_hat_loss: 0.0017 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 8.0697e-06 - val_v_ex_hat_loss: 1.7300e-05 - val_load_v_hat_loss: 1.6074e-04 - val_prod_q_hat_loss: 5.8958e-04 - val_theta_or_hat_loss: 6.2061e-04 - val_theta_ex_hat_loss: 5.6442e-04\n",
      "Epoch 57/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0094 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 7.0886e-04 - p_ex_hat_loss: 6.7365e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.2759e-05 - v_ex_hat_loss: 2.2176e-05 - load_v_hat_loss: 1.5769e-04 - prod_q_hat_loss: 4.7732e-04 - theta_or_hat_loss: 4.7943e-04 - theta_ex_hat_loss: 4.4669e-04 - val_loss: 0.0113 - val_a_or_hat_loss: 0.0023 - val_a_ex_hat_loss: 0.0023 - val_p_or_hat_loss: 8.2260e-04 - val_p_ex_hat_loss: 6.9452e-04 - val_q_ex_hat_loss: 0.0017 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 2.1583e-05 - val_v_ex_hat_loss: 3.1001e-05 - val_load_v_hat_loss: 1.8697e-04 - val_prod_q_hat_loss: 6.8657e-04 - val_theta_or_hat_loss: 5.5870e-04 - val_theta_ex_hat_loss: 4.9248e-04\n",
      "Epoch 58/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0092 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.8393e-04 - p_ex_hat_loss: 6.4854e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.2226e-05 - v_ex_hat_loss: 2.1183e-05 - load_v_hat_loss: 1.6278e-04 - prod_q_hat_loss: 5.0347e-04 - theta_or_hat_loss: 4.6815e-04 - theta_ex_hat_loss: 4.3985e-04 - val_loss: 0.0131 - val_a_or_hat_loss: 0.0026 - val_a_ex_hat_loss: 0.0025 - val_p_or_hat_loss: 0.0011 - val_p_ex_hat_loss: 0.0010 - val_q_ex_hat_loss: 0.0020 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 3.1859e-05 - val_v_ex_hat_loss: 3.4361e-05 - val_load_v_hat_loss: 1.7250e-04 - val_prod_q_hat_loss: 5.8755e-04 - val_theta_or_hat_loss: 7.8856e-04 - val_theta_ex_hat_loss: 6.7692e-04\n",
      "Epoch 59/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0092 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.9203e-04 - p_ex_hat_loss: 6.5634e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.2063e-05 - v_ex_hat_loss: 2.0965e-05 - load_v_hat_loss: 1.6177e-04 - prod_q_hat_loss: 4.5653e-04 - theta_or_hat_loss: 4.7587e-04 - theta_ex_hat_loss: 4.3634e-04 - val_loss: 0.0123 - val_a_or_hat_loss: 0.0023 - val_a_ex_hat_loss: 0.0022 - val_p_or_hat_loss: 9.6390e-04 - val_p_ex_hat_loss: 7.9854e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0018 - val_v_or_hat_loss: 1.1620e-05 - val_v_ex_hat_loss: 2.0769e-05 - val_load_v_hat_loss: 1.9510e-04 - val_prod_q_hat_loss: 6.1899e-04 - val_theta_or_hat_loss: 7.9366e-04 - val_theta_ex_hat_loss: 8.1336e-04\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0093 - a_or_hat_loss: 0.0018 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.9796e-04 - p_ex_hat_loss: 6.7700e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.2775e-05 - v_ex_hat_loss: 2.1718e-05 - load_v_hat_loss: 1.6280e-04 - prod_q_hat_loss: 4.8040e-04 - theta_or_hat_loss: 4.8041e-04 - theta_ex_hat_loss: 4.4773e-04 - val_loss: 0.0114 - val_a_or_hat_loss: 0.0022 - val_a_ex_hat_loss: 0.0022 - val_p_or_hat_loss: 7.7743e-04 - val_p_ex_hat_loss: 8.6373e-04 - val_q_ex_hat_loss: 0.0019 - val_q_or_hat_loss: 0.0017 - val_v_or_hat_loss: 8.1751e-06 - val_v_ex_hat_loss: 1.6310e-05 - val_load_v_hat_loss: 1.6030e-04 - val_prod_q_hat_loss: 5.6228e-04 - val_theta_or_hat_loss: 5.2459e-04 - val_theta_ex_hat_loss: 4.9528e-04\n",
      "Epoch 61/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0091 - a_or_hat_loss: 0.0017 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.7277e-04 - p_ex_hat_loss: 6.5062e-04 - q_ex_hat_loss: 0.0015 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.1939e-05 - v_ex_hat_loss: 2.0313e-05 - load_v_hat_loss: 1.5594e-04 - prod_q_hat_loss: 4.8532e-04 - theta_or_hat_loss: 4.7190e-04 - theta_ex_hat_loss: 4.3915e-04 - val_loss: 0.0107 - val_a_or_hat_loss: 0.0021 - val_a_ex_hat_loss: 0.0021 - val_p_or_hat_loss: 7.4892e-04 - val_p_ex_hat_loss: 7.6039e-04 - val_q_ex_hat_loss: 0.0016 - val_q_or_hat_loss: 0.0015 - val_v_or_hat_loss: 7.7648e-06 - val_v_ex_hat_loss: 1.8796e-05 - val_load_v_hat_loss: 1.4904e-04 - val_prod_q_hat_loss: 6.0645e-04 - val_theta_or_hat_loss: 5.1976e-04 - val_theta_ex_hat_loss: 5.1034e-04\n",
      "Epoch 62/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0088 - a_or_hat_loss: 0.0017 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.6280e-04 - p_ex_hat_loss: 6.3757e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 1.0963e-05 - v_ex_hat_loss: 2.0080e-05 - load_v_hat_loss: 1.5730e-04 - prod_q_hat_loss: 4.4836e-04 - theta_or_hat_loss: 4.5163e-04 - theta_ex_hat_loss: 4.2057e-04 - val_loss: 0.0109 - val_a_or_hat_loss: 0.0020 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 7.8309e-04 - val_p_ex_hat_loss: 8.1701e-04 - val_q_ex_hat_loss: 0.0017 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 1.0556e-05 - val_v_ex_hat_loss: 1.8777e-05 - val_load_v_hat_loss: 1.7950e-04 - val_prod_q_hat_loss: 5.3588e-04 - val_theta_or_hat_loss: 6.1756e-04 - val_theta_ex_hat_loss: 6.9277e-04\n",
      "Epoch 63/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0086 - a_or_hat_loss: 0.0017 - a_ex_hat_loss: 0.0016 - p_or_hat_loss: 6.3418e-04 - p_ex_hat_loss: 6.3093e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 9.4725e-06 - v_ex_hat_loss: 1.8043e-05 - load_v_hat_loss: 1.5396e-04 - prod_q_hat_loss: 4.2776e-04 - theta_or_hat_loss: 4.3285e-04 - theta_ex_hat_loss: 4.0999e-04 - val_loss: 0.0118 - val_a_or_hat_loss: 0.0021 - val_a_ex_hat_loss: 0.0022 - val_p_or_hat_loss: 9.2418e-04 - val_p_ex_hat_loss: 7.6592e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 7.2433e-06 - val_v_ex_hat_loss: 1.4936e-05 - val_load_v_hat_loss: 2.7204e-04 - val_prod_q_hat_loss: 6.4959e-04 - val_theta_or_hat_loss: 8.6485e-04 - val_theta_ex_hat_loss: 8.1497e-04\n",
      "Epoch 64/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0089 - a_or_hat_loss: 0.0017 - a_ex_hat_loss: 0.0017 - p_or_hat_loss: 6.5247e-04 - p_ex_hat_loss: 6.2456e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0013 - v_or_hat_loss: 1.2204e-05 - v_ex_hat_loss: 2.0606e-05 - load_v_hat_loss: 1.7387e-04 - prod_q_hat_loss: 4.6885e-04 - theta_or_hat_loss: 4.6954e-04 - theta_ex_hat_loss: 4.2619e-04 - val_loss: 0.0144 - val_a_or_hat_loss: 0.0021 - val_a_ex_hat_loss: 0.0022 - val_p_or_hat_loss: 0.0012 - val_p_ex_hat_loss: 0.0020 - val_q_ex_hat_loss: 0.0031 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 8.8414e-06 - val_v_ex_hat_loss: 1.6692e-05 - val_load_v_hat_loss: 2.1053e-04 - val_prod_q_hat_loss: 5.5621e-04 - val_theta_or_hat_loss: 7.5476e-04 - val_theta_ex_hat_loss: 6.7697e-04\n",
      "Epoch 65/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0087 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0016 - p_or_hat_loss: 6.8053e-04 - p_ex_hat_loss: 6.7208e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 1.1131e-05 - v_ex_hat_loss: 1.9315e-05 - load_v_hat_loss: 1.4867e-04 - prod_q_hat_loss: 4.5898e-04 - theta_or_hat_loss: 4.5097e-04 - theta_ex_hat_loss: 4.0923e-04 - val_loss: 0.0126 - val_a_or_hat_loss: 0.0022 - val_a_ex_hat_loss: 0.0021 - val_p_or_hat_loss: 8.7035e-04 - val_p_ex_hat_loss: 8.1448e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 1.2618e-05 - val_v_ex_hat_loss: 2.5385e-05 - val_load_v_hat_loss: 3.3961e-04 - val_prod_q_hat_loss: 0.0010 - val_theta_or_hat_loss: 9.5424e-04 - val_theta_ex_hat_loss: 8.0159e-04\n",
      "Epoch 66/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0085 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0016 - p_or_hat_loss: 6.3557e-04 - p_ex_hat_loss: 6.0959e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 1.1200e-05 - v_ex_hat_loss: 1.8913e-05 - load_v_hat_loss: 1.4693e-04 - prod_q_hat_loss: 4.4657e-04 - theta_or_hat_loss: 4.4621e-04 - theta_ex_hat_loss: 4.0147e-04 - val_loss: 0.0102 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 7.9221e-04 - val_p_ex_hat_loss: 7.5888e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 1.0017e-05 - val_v_ex_hat_loss: 1.7552e-05 - val_load_v_hat_loss: 2.4622e-04 - val_prod_q_hat_loss: 5.8928e-04 - val_theta_or_hat_loss: 4.9460e-04 - val_theta_ex_hat_loss: 4.6447e-04\n",
      "Epoch 67/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0085 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0016 - p_or_hat_loss: 6.2597e-04 - p_ex_hat_loss: 6.0956e-04 - q_ex_hat_loss: 0.0014 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 1.2608e-05 - v_ex_hat_loss: 2.0046e-05 - load_v_hat_loss: 1.6347e-04 - prod_q_hat_loss: 4.3677e-04 - theta_or_hat_loss: 4.3936e-04 - theta_ex_hat_loss: 4.1051e-04 - val_loss: 0.0110 - val_a_or_hat_loss: 0.0020 - val_a_ex_hat_loss: 0.0021 - val_p_or_hat_loss: 0.0010 - val_p_ex_hat_loss: 8.4607e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 1.3311e-05 - val_v_ex_hat_loss: 2.0319e-05 - val_load_v_hat_loss: 1.7181e-04 - val_prod_q_hat_loss: 6.3690e-04 - val_theta_or_hat_loss: 4.9372e-04 - val_theta_ex_hat_loss: 5.1528e-04\n",
      "Epoch 68/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0082 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.9981e-04 - p_ex_hat_loss: 5.9360e-04 - q_ex_hat_loss: 0.0013 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 9.9539e-06 - v_ex_hat_loss: 1.7635e-05 - load_v_hat_loss: 1.3524e-04 - prod_q_hat_loss: 4.3236e-04 - theta_or_hat_loss: 4.1877e-04 - theta_ex_hat_loss: 3.8483e-04 - val_loss: 0.0099 - val_a_or_hat_loss: 0.0020 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 7.4045e-04 - val_p_ex_hat_loss: 7.3938e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 5.8244e-06 - val_v_ex_hat_loss: 1.3570e-05 - val_load_v_hat_loss: 1.7619e-04 - val_prod_q_hat_loss: 4.2622e-04 - val_theta_or_hat_loss: 4.8363e-04 - val_theta_ex_hat_loss: 4.7663e-04\n",
      "Epoch 69/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0082 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 6.0289e-04 - p_ex_hat_loss: 5.9352e-04 - q_ex_hat_loss: 0.0013 - q_or_hat_loss: 0.0012 - v_or_hat_loss: 1.0372e-05 - v_ex_hat_loss: 1.7825e-05 - load_v_hat_loss: 1.4466e-04 - prod_q_hat_loss: 4.2183e-04 - theta_or_hat_loss: 4.2127e-04 - theta_ex_hat_loss: 3.8437e-04 - val_loss: 0.0111 - val_a_or_hat_loss: 0.0020 - val_a_ex_hat_loss: 0.0019 - val_p_or_hat_loss: 7.6723e-04 - val_p_ex_hat_loss: 7.9906e-04 - val_q_ex_hat_loss: 0.0017 - val_q_or_hat_loss: 0.0015 - val_v_or_hat_loss: 8.8258e-06 - val_v_ex_hat_loss: 1.4870e-05 - val_load_v_hat_loss: 3.6410e-04 - val_prod_q_hat_loss: 6.3373e-04 - val_theta_or_hat_loss: 6.7571e-04 - val_theta_ex_hat_loss: 6.3160e-04\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0081 - a_or_hat_loss: 0.0016 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.8440e-04 - p_ex_hat_loss: 5.8684e-04 - q_ex_hat_loss: 0.0013 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 9.6114e-06 - v_ex_hat_loss: 1.6994e-05 - load_v_hat_loss: 1.4180e-04 - prod_q_hat_loss: 3.9732e-04 - theta_or_hat_loss: 4.1816e-04 - theta_ex_hat_loss: 3.8742e-04 - val_loss: 0.0108 - val_a_or_hat_loss: 0.0022 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 8.1933e-04 - val_p_ex_hat_loss: 7.0808e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 2.0717e-05 - val_v_ex_hat_loss: 3.4060e-05 - val_load_v_hat_loss: 2.0998e-04 - val_prod_q_hat_loss: 5.7397e-04 - val_theta_or_hat_loss: 5.0790e-04 - val_theta_ex_hat_loss: 5.5506e-04\n",
      "Epoch 71/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0080 - a_or_hat_loss: 0.0015 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 6.0467e-04 - p_ex_hat_loss: 5.9586e-04 - q_ex_hat_loss: 0.0013 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 1.1036e-05 - v_ex_hat_loss: 1.8534e-05 - load_v_hat_loss: 1.3014e-04 - prod_q_hat_loss: 3.8765e-04 - theta_or_hat_loss: 4.0838e-04 - theta_ex_hat_loss: 3.8752e-04 - val_loss: 0.0100 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0019 - val_p_or_hat_loss: 7.9439e-04 - val_p_ex_hat_loss: 6.6308e-04 - val_q_ex_hat_loss: 0.0018 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 6.9064e-06 - val_v_ex_hat_loss: 1.5194e-05 - val_load_v_hat_loss: 1.2135e-04 - val_prod_q_hat_loss: 5.0595e-04 - val_theta_or_hat_loss: 4.9954e-04 - val_theta_ex_hat_loss: 4.3865e-04\n",
      "Epoch 72/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0079 - a_or_hat_loss: 0.0015 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.7666e-04 - p_ex_hat_loss: 5.7303e-04 - q_ex_hat_loss: 0.0013 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 1.1016e-05 - v_ex_hat_loss: 1.8348e-05 - load_v_hat_loss: 1.3290e-04 - prod_q_hat_loss: 3.9777e-04 - theta_or_hat_loss: 4.1279e-04 - theta_ex_hat_loss: 3.7898e-04 - val_loss: 0.0093 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 6.7625e-04 - val_p_ex_hat_loss: 6.6182e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 5.5003e-06 - val_v_ex_hat_loss: 1.3074e-05 - val_load_v_hat_loss: 1.4002e-04 - val_prod_q_hat_loss: 4.7443e-04 - val_theta_or_hat_loss: 4.4636e-04 - val_theta_ex_hat_loss: 4.0785e-04\n",
      "Epoch 73/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0078 - a_or_hat_loss: 0.0015 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.6770e-04 - p_ex_hat_loss: 5.6707e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 9.1779e-06 - v_ex_hat_loss: 1.5822e-05 - load_v_hat_loss: 1.3482e-04 - prod_q_hat_loss: 4.0381e-04 - theta_or_hat_loss: 4.0160e-04 - theta_ex_hat_loss: 3.7271e-04 - val_loss: 0.0098 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0019 - val_p_or_hat_loss: 7.0514e-04 - val_p_ex_hat_loss: 7.2098e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 9.5912e-06 - val_v_ex_hat_loss: 1.6516e-05 - val_load_v_hat_loss: 1.4307e-04 - val_prod_q_hat_loss: 5.8449e-04 - val_theta_or_hat_loss: 4.6977e-04 - val_theta_ex_hat_loss: 4.1181e-04\n",
      "Epoch 74/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0077 - a_or_hat_loss: 0.0015 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.5004e-04 - p_ex_hat_loss: 5.5694e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 9.4499e-06 - v_ex_hat_loss: 1.6403e-05 - load_v_hat_loss: 1.3253e-04 - prod_q_hat_loss: 3.8442e-04 - theta_or_hat_loss: 4.0555e-04 - theta_ex_hat_loss: 3.6430e-04 - val_loss: 0.0095 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 6.3209e-04 - val_p_ex_hat_loss: 6.7494e-04 - val_q_ex_hat_loss: 0.0016 - val_q_or_hat_loss: 0.0014 - val_v_or_hat_loss: 6.4062e-06 - val_v_ex_hat_loss: 1.2160e-05 - val_load_v_hat_loss: 1.6947e-04 - val_prod_q_hat_loss: 4.4176e-04 - val_theta_or_hat_loss: 5.0310e-04 - val_theta_ex_hat_loss: 3.9431e-04\n",
      "Epoch 75/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0076 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0015 - p_or_hat_loss: 5.4672e-04 - p_ex_hat_loss: 5.4331e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 9.1242e-06 - v_ex_hat_loss: 1.5766e-05 - load_v_hat_loss: 1.2669e-04 - prod_q_hat_loss: 3.8802e-04 - theta_or_hat_loss: 3.9634e-04 - theta_ex_hat_loss: 3.5570e-04 - val_loss: 0.0092 - val_a_or_hat_loss: 0.0019 - val_a_ex_hat_loss: 0.0019 - val_p_or_hat_loss: 7.3466e-04 - val_p_ex_hat_loss: 6.2234e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 4.3570e-06 - val_v_ex_hat_loss: 1.0727e-05 - val_load_v_hat_loss: 1.4077e-04 - val_prod_q_hat_loss: 4.4152e-04 - val_theta_or_hat_loss: 4.8398e-04 - val_theta_ex_hat_loss: 4.2689e-04\n",
      "Epoch 76/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0075 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.3862e-04 - p_ex_hat_loss: 5.4235e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 7.4185e-06 - v_ex_hat_loss: 1.4160e-05 - load_v_hat_loss: 1.2858e-04 - prod_q_hat_loss: 3.8871e-04 - theta_or_hat_loss: 3.9296e-04 - theta_ex_hat_loss: 3.5921e-04 - val_loss: 0.0092 - val_a_or_hat_loss: 0.0018 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 7.0004e-04 - val_p_ex_hat_loss: 7.2245e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 6.7503e-06 - val_v_ex_hat_loss: 1.2798e-05 - val_load_v_hat_loss: 1.4147e-04 - val_prod_q_hat_loss: 4.4425e-04 - val_theta_or_hat_loss: 5.0556e-04 - val_theta_ex_hat_loss: 3.8632e-04\n",
      "Epoch 77/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0074 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.4043e-04 - p_ex_hat_loss: 5.4083e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 9.2241e-06 - v_ex_hat_loss: 1.5852e-05 - load_v_hat_loss: 1.2430e-04 - prod_q_hat_loss: 3.6775e-04 - theta_or_hat_loss: 3.7539e-04 - theta_ex_hat_loss: 3.3869e-04 - val_loss: 0.0087 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 6.3042e-04 - val_p_ex_hat_loss: 5.5521e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 4.7493e-06 - val_v_ex_hat_loss: 1.1953e-05 - val_load_v_hat_loss: 1.2788e-04 - val_prod_q_hat_loss: 4.1462e-04 - val_theta_or_hat_loss: 4.6495e-04 - val_theta_ex_hat_loss: 3.8655e-04\n",
      "Epoch 78/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0074 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.4466e-04 - p_ex_hat_loss: 5.4696e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0010 - v_or_hat_loss: 8.5503e-06 - v_ex_hat_loss: 1.4850e-05 - load_v_hat_loss: 1.4665e-04 - prod_q_hat_loss: 3.6794e-04 - theta_or_hat_loss: 3.8480e-04 - theta_ex_hat_loss: 3.5119e-04 - val_loss: 0.0089 - val_a_or_hat_loss: 0.0018 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 5.9631e-04 - val_p_ex_hat_loss: 5.6152e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 7.0174e-06 - val_v_ex_hat_loss: 1.3335e-05 - val_load_v_hat_loss: 2.4925e-04 - val_prod_q_hat_loss: 5.0870e-04 - val_theta_or_hat_loss: 4.1445e-04 - val_theta_ex_hat_loss: 4.0430e-04\n",
      "Epoch 79/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0074 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.2589e-04 - p_ex_hat_loss: 5.3103e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0010 - v_or_hat_loss: 8.8859e-06 - v_ex_hat_loss: 1.5161e-05 - load_v_hat_loss: 1.2726e-04 - prod_q_hat_loss: 3.8651e-04 - theta_or_hat_loss: 3.6981e-04 - theta_ex_hat_loss: 3.3609e-04 - val_loss: 0.0088 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 6.2150e-04 - val_p_ex_hat_loss: 6.0412e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 7.4598e-06 - val_v_ex_hat_loss: 1.3412e-05 - val_load_v_hat_loss: 1.2886e-04 - val_prod_q_hat_loss: 3.8209e-04 - val_theta_or_hat_loss: 4.9521e-04 - val_theta_ex_hat_loss: 4.0703e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0073 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.3541e-04 - p_ex_hat_loss: 5.3622e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0010 - v_or_hat_loss: 9.2216e-06 - v_ex_hat_loss: 1.5518e-05 - load_v_hat_loss: 1.3273e-04 - prod_q_hat_loss: 3.6116e-04 - theta_or_hat_loss: 3.7878e-04 - theta_ex_hat_loss: 3.4176e-04 - val_loss: 0.0088 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 6.8968e-04 - val_p_ex_hat_loss: 6.4456e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 4.9689e-06 - val_v_ex_hat_loss: 1.2055e-05 - val_load_v_hat_loss: 1.5564e-04 - val_prod_q_hat_loss: 4.9226e-04 - val_theta_or_hat_loss: 4.2312e-04 - val_theta_ex_hat_loss: 4.1133e-04\n",
      "Epoch 81/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0073 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.3568e-04 - p_ex_hat_loss: 5.2863e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0010 - v_or_hat_loss: 8.4335e-06 - v_ex_hat_loss: 1.4473e-05 - load_v_hat_loss: 1.3638e-04 - prod_q_hat_loss: 3.6882e-04 - theta_or_hat_loss: 3.7666e-04 - theta_ex_hat_loss: 3.3619e-04 - val_loss: 0.0105 - val_a_or_hat_loss: 0.0021 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 9.1408e-04 - val_p_ex_hat_loss: 0.0011 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0015 - val_v_or_hat_loss: 2.2969e-05 - val_v_ex_hat_loss: 3.2885e-05 - val_load_v_hat_loss: 1.7358e-04 - val_prod_q_hat_loss: 4.7661e-04 - val_theta_or_hat_loss: 4.2879e-04 - val_theta_ex_hat_loss: 3.8745e-04\n",
      "Epoch 82/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0074 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.5257e-04 - p_ex_hat_loss: 5.5209e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 0.0011 - v_or_hat_loss: 1.1362e-05 - v_ex_hat_loss: 1.7604e-05 - load_v_hat_loss: 1.2687e-04 - prod_q_hat_loss: 3.7856e-04 - theta_or_hat_loss: 3.7918e-04 - theta_ex_hat_loss: 3.4558e-04 - val_loss: 0.0093 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 7.5320e-04 - val_p_ex_hat_loss: 7.2560e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 1.2379e-05 - val_v_ex_hat_loss: 1.7261e-05 - val_load_v_hat_loss: 1.5997e-04 - val_prod_q_hat_loss: 5.4254e-04 - val_theta_or_hat_loss: 4.5913e-04 - val_theta_ex_hat_loss: 4.1669e-04\n",
      "Epoch 83/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0071 - a_or_hat_loss: 0.0014 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.1208e-04 - p_ex_hat_loss: 5.1674e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.9456e-04 - v_or_hat_loss: 8.3670e-06 - v_ex_hat_loss: 1.4171e-05 - load_v_hat_loss: 1.2342e-04 - prod_q_hat_loss: 3.6131e-04 - theta_or_hat_loss: 3.6054e-04 - theta_ex_hat_loss: 3.2066e-04 - val_loss: 0.0102 - val_a_or_hat_loss: 0.0018 - val_a_ex_hat_loss: 0.0020 - val_p_or_hat_loss: 9.9223e-04 - val_p_ex_hat_loss: 7.7264e-04 - val_q_ex_hat_loss: 0.0016 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 1.7024e-05 - val_v_ex_hat_loss: 2.0810e-05 - val_load_v_hat_loss: 1.2738e-04 - val_prod_q_hat_loss: 5.4591e-04 - val_theta_or_hat_loss: 6.1047e-04 - val_theta_ex_hat_loss: 4.5310e-04\n",
      "Epoch 84/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0071 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.2009e-04 - p_ex_hat_loss: 5.1492e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 0.0010 - v_or_hat_loss: 8.5111e-06 - v_ex_hat_loss: 1.4156e-05 - load_v_hat_loss: 1.2575e-04 - prod_q_hat_loss: 3.7707e-04 - theta_or_hat_loss: 3.7501e-04 - theta_ex_hat_loss: 3.3347e-04 - val_loss: 0.0093 - val_a_or_hat_loss: 0.0018 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 7.1248e-04 - val_p_ex_hat_loss: 9.0724e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 6.6958e-06 - val_v_ex_hat_loss: 1.3515e-05 - val_load_v_hat_loss: 1.3065e-04 - val_prod_q_hat_loss: 3.7670e-04 - val_theta_or_hat_loss: 6.6733e-04 - val_theta_ex_hat_loss: 4.4552e-04\n",
      "Epoch 85/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0068 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.9502e-04 - p_ex_hat_loss: 4.9985e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.6373e-04 - v_or_hat_loss: 7.0698e-06 - v_ex_hat_loss: 1.2716e-05 - load_v_hat_loss: 1.1771e-04 - prod_q_hat_loss: 3.4810e-04 - theta_or_hat_loss: 3.5003e-04 - theta_ex_hat_loss: 3.1474e-04 - val_loss: 0.0085 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 5.8598e-04 - val_p_ex_hat_loss: 5.4004e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 6.0226e-06 - val_v_ex_hat_loss: 1.0204e-05 - val_load_v_hat_loss: 1.4352e-04 - val_prod_q_hat_loss: 4.2569e-04 - val_theta_or_hat_loss: 4.3055e-04 - val_theta_ex_hat_loss: 3.9338e-04\n",
      "Epoch 86/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0070 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.0491e-04 - p_ex_hat_loss: 5.0255e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.9022e-04 - v_or_hat_loss: 9.2003e-06 - v_ex_hat_loss: 1.4506e-05 - load_v_hat_loss: 1.1958e-04 - prod_q_hat_loss: 3.4001e-04 - theta_or_hat_loss: 3.6481e-04 - theta_ex_hat_loss: 3.2819e-04 - val_loss: 0.0083 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 6.5244e-04 - val_p_ex_hat_loss: 6.0154e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 7.0294e-06 - val_v_ex_hat_loss: 1.4297e-05 - val_load_v_hat_loss: 1.5788e-04 - val_prod_q_hat_loss: 3.7626e-04 - val_theta_or_hat_loss: 4.3742e-04 - val_theta_ex_hat_loss: 3.4912e-04\n",
      "Epoch 87/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0068 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.9904e-04 - p_ex_hat_loss: 5.0205e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.6864e-04 - v_or_hat_loss: 7.9732e-06 - v_ex_hat_loss: 1.3335e-05 - load_v_hat_loss: 1.2246e-04 - prod_q_hat_loss: 3.3723e-04 - theta_or_hat_loss: 3.4611e-04 - theta_ex_hat_loss: 3.1648e-04 - val_loss: 0.0085 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 5.8472e-04 - val_p_ex_hat_loss: 6.4053e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 5.7206e-06 - val_v_ex_hat_loss: 1.0222e-05 - val_load_v_hat_loss: 1.7193e-04 - val_prod_q_hat_loss: 4.7004e-04 - val_theta_or_hat_loss: 3.9095e-04 - val_theta_ex_hat_loss: 3.7813e-04\n",
      "Epoch 88/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0071 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0014 - p_or_hat_loss: 5.2266e-04 - p_ex_hat_loss: 5.2381e-04 - q_ex_hat_loss: 0.0012 - q_or_hat_loss: 9.8293e-04 - v_or_hat_loss: 1.0954e-05 - v_ex_hat_loss: 1.5820e-05 - load_v_hat_loss: 1.3260e-04 - prod_q_hat_loss: 3.7175e-04 - theta_or_hat_loss: 3.5456e-04 - theta_ex_hat_loss: 3.2343e-04 - val_loss: 0.0093 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0018 - val_p_or_hat_loss: 7.5540e-04 - val_p_ex_hat_loss: 7.5706e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 0.0016 - val_v_or_hat_loss: 2.8545e-05 - val_v_ex_hat_loss: 3.3163e-05 - val_load_v_hat_loss: 1.0341e-04 - val_prod_q_hat_loss: 4.2250e-04 - val_theta_or_hat_loss: 4.0065e-04 - val_theta_ex_hat_loss: 3.4597e-04\n",
      "Epoch 89/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0065 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.6802e-04 - p_ex_hat_loss: 4.6179e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 9.1561e-04 - v_or_hat_loss: 6.5325e-06 - v_ex_hat_loss: 1.1727e-05 - load_v_hat_loss: 1.0736e-04 - prod_q_hat_loss: 3.3345e-04 - theta_or_hat_loss: 3.2638e-04 - theta_ex_hat_loss: 2.9839e-04 - val_loss: 0.0083 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 7.5959e-04 - val_p_ex_hat_loss: 6.6055e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 5.0415e-06 - val_v_ex_hat_loss: 1.0183e-05 - val_load_v_hat_loss: 1.6749e-04 - val_prod_q_hat_loss: 3.8307e-04 - val_theta_or_hat_loss: 4.1494e-04 - val_theta_ex_hat_loss: 4.4536e-04\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0068 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 5.0069e-04 - p_ex_hat_loss: 4.9406e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.5576e-04 - v_or_hat_loss: 8.6143e-06 - v_ex_hat_loss: 1.3474e-05 - load_v_hat_loss: 1.1472e-04 - prod_q_hat_loss: 3.3942e-04 - theta_or_hat_loss: 3.4037e-04 - theta_ex_hat_loss: 3.1265e-04 - val_loss: 0.0082 - val_a_or_hat_loss: 0.0017 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 6.4501e-04 - val_p_ex_hat_loss: 5.2588e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 4.7614e-06 - val_v_ex_hat_loss: 1.0742e-05 - val_load_v_hat_loss: 1.4790e-04 - val_prod_q_hat_loss: 5.0575e-04 - val_theta_or_hat_loss: 4.0848e-04 - val_theta_ex_hat_loss: 3.2767e-04\n",
      "Epoch 91/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0067 - a_or_hat_loss: 0.0013 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.8963e-04 - p_ex_hat_loss: 4.8577e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.3444e-04 - v_or_hat_loss: 8.0726e-06 - v_ex_hat_loss: 1.2977e-05 - load_v_hat_loss: 1.1932e-04 - prod_q_hat_loss: 3.5708e-04 - theta_or_hat_loss: 3.3815e-04 - theta_ex_hat_loss: 2.9615e-04 - val_loss: 0.0084 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 7.7740e-04 - val_p_ex_hat_loss: 5.6388e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 4.4059e-06 - val_v_ex_hat_loss: 1.0306e-05 - val_load_v_hat_loss: 1.1745e-04 - val_prod_q_hat_loss: 4.1598e-04 - val_theta_or_hat_loss: 5.0514e-04 - val_theta_ex_hat_loss: 3.7338e-04\n",
      "Epoch 92/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0066 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.9246e-04 - p_ex_hat_loss: 4.8220e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 9.3151e-04 - v_or_hat_loss: 7.9797e-06 - v_ex_hat_loss: 1.2836e-05 - load_v_hat_loss: 1.1419e-04 - prod_q_hat_loss: 3.4831e-04 - theta_or_hat_loss: 3.4480e-04 - theta_ex_hat_loss: 3.0874e-04 - val_loss: 0.0086 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 5.4905e-04 - val_p_ex_hat_loss: 5.8467e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0013 - val_v_or_hat_loss: 7.8217e-06 - val_v_ex_hat_loss: 1.5525e-05 - val_load_v_hat_loss: 1.6101e-04 - val_prod_q_hat_loss: 4.3863e-04 - val_theta_or_hat_loss: 5.3264e-04 - val_theta_ex_hat_loss: 4.3646e-04\n",
      "Epoch 93/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0066 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.8061e-04 - p_ex_hat_loss: 4.7427e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.5771e-04 - v_or_hat_loss: 8.5080e-06 - v_ex_hat_loss: 1.3516e-05 - load_v_hat_loss: 1.1309e-04 - prod_q_hat_loss: 3.3619e-04 - theta_or_hat_loss: 3.4708e-04 - theta_ex_hat_loss: 2.9446e-04 - val_loss: 0.0081 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 6.6460e-04 - val_p_ex_hat_loss: 6.0401e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 2.4090e-05 - val_v_ex_hat_loss: 2.8824e-05 - val_load_v_hat_loss: 1.0191e-04 - val_prod_q_hat_loss: 3.4504e-04 - val_theta_or_hat_loss: 3.7397e-04 - val_theta_ex_hat_loss: 3.3335e-04_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.5898e-04 - v_or_hat_loss: 8.5659e-06 - v_ex_hat_loss: 1.3584e-05 - load_v_hat_loss: 1.1320e-04 - prod_q_hat_loss: 3.3596e-04 - theta_or_hat_loss: 3.4734e-04 - theta_ex_hat_loss:\n",
      "Epoch 94/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0065 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.7621e-04 - p_ex_hat_loss: 4.6957e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 9.2389e-04 - v_or_hat_loss: 8.3011e-06 - v_ex_hat_loss: 1.3021e-05 - load_v_hat_loss: 1.1153e-04 - prod_q_hat_loss: 3.2606e-04 - theta_or_hat_loss: 3.3137e-04 - theta_ex_hat_loss: 2.7906e-04 - val_loss: 0.0078 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 6.1530e-04 - val_p_ex_hat_loss: 4.9165e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 4.7710e-06 - val_v_ex_hat_loss: 8.3826e-06 - val_load_v_hat_loss: 1.4846e-04 - val_prod_q_hat_loss: 3.2624e-04 - val_theta_or_hat_loss: 5.2824e-04 - val_theta_ex_hat_loss: 4.4479e-04\n",
      "Epoch 95/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0066 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.9136e-04 - p_ex_hat_loss: 4.7003e-04 - q_ex_hat_loss: 0.0011 - q_or_hat_loss: 9.2301e-04 - v_or_hat_loss: 8.6155e-06 - v_ex_hat_loss: 1.3178e-05 - load_v_hat_loss: 1.0892e-04 - prod_q_hat_loss: 3.3010e-04 - theta_or_hat_loss: 3.5667e-04 - theta_ex_hat_loss: 2.9933e-04 - val_loss: 0.0077 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.4009e-04 - val_p_ex_hat_loss: 6.1470e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 5.6565e-06 - val_v_ex_hat_loss: 1.2012e-05 - val_load_v_hat_loss: 1.4291e-04 - val_prod_q_hat_loss: 3.8942e-04 - val_theta_or_hat_loss: 3.7597e-04 - val_theta_ex_hat_loss: 3.3321e-04\n",
      "Epoch 96/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0064 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.6387e-04 - p_ex_hat_loss: 4.5734e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 9.0799e-04 - v_or_hat_loss: 7.6308e-06 - v_ex_hat_loss: 1.2396e-05 - load_v_hat_loss: 1.0584e-04 - prod_q_hat_loss: 3.1577e-04 - theta_or_hat_loss: 3.3043e-04 - theta_ex_hat_loss: 2.7299e-04 - val_loss: 0.0081 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 5.4733e-04 - val_p_ex_hat_loss: 4.8262e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 6.5786e-06 - val_v_ex_hat_loss: 1.1029e-05 - val_load_v_hat_loss: 1.0616e-04 - val_prod_q_hat_loss: 3.6731e-04 - val_theta_or_hat_loss: 4.3587e-04 - val_theta_ex_hat_loss: 3.7560e-04\n",
      "Epoch 97/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0063 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0013 - p_or_hat_loss: 4.5483e-04 - p_ex_hat_loss: 4.4714e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 8.8590e-04 - v_or_hat_loss: 6.8947e-06 - v_ex_hat_loss: 1.1321e-05 - load_v_hat_loss: 1.0760e-04 - prod_q_hat_loss: 3.2520e-04 - theta_or_hat_loss: 3.2523e-04 - theta_ex_hat_loss: 2.6980e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.5165e-04 - val_p_ex_hat_loss: 5.0263e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 3.3020e-06 - val_v_ex_hat_loss: 7.8107e-06 - val_load_v_hat_loss: 1.5248e-04 - val_prod_q_hat_loss: 3.9582e-04 - val_theta_or_hat_loss: 3.8947e-04 - val_theta_ex_hat_loss: 2.8059e-04\n",
      "Epoch 98/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0062 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.5453e-04 - p_ex_hat_loss: 4.4178e-04 - q_ex_hat_loss: 9.9266e-04 - q_or_hat_loss: 8.7916e-04 - v_or_hat_loss: 6.8748e-06 - v_ex_hat_loss: 1.1298e-05 - load_v_hat_loss: 1.0546e-04 - prod_q_hat_loss: 2.9999e-04 - theta_or_hat_loss: 3.1235e-04 - theta_ex_hat_loss: 2.6317e-04 - val_loss: 0.0074 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.2718e-04 - val_p_ex_hat_loss: 5.1122e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 9.9145e-04 - val_v_or_hat_loss: 4.0179e-06 - val_v_ex_hat_loss: 8.3441e-06 - val_load_v_hat_loss: 1.2257e-04 - val_prod_q_hat_loss: 3.4023e-04 - val_theta_or_hat_loss: 3.7719e-04 - val_theta_ex_hat_loss: 3.1814e-04\n",
      "Epoch 99/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0062 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.6505e-04 - p_ex_hat_loss: 4.5685e-04 - q_ex_hat_loss: 9.9415e-04 - q_or_hat_loss: 8.7963e-04 - v_or_hat_loss: 7.1333e-06 - v_ex_hat_loss: 1.1472e-05 - load_v_hat_loss: 1.1041e-04 - prod_q_hat_loss: 3.0787e-04 - theta_or_hat_loss: 3.2609e-04 - theta_ex_hat_loss: 2.6964e-04 - val_loss: 0.0083 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 6.3204e-04 - val_p_ex_hat_loss: 6.3638e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 2.2109e-05 - val_v_ex_hat_loss: 2.7705e-05 - val_load_v_hat_loss: 1.2466e-04 - val_prod_q_hat_loss: 3.7834e-04 - val_theta_or_hat_loss: 4.7333e-04 - val_theta_ex_hat_loss: 3.5465e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0064 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.7335e-04 - p_ex_hat_loss: 4.5148e-04 - q_ex_hat_loss: 0.0010 - q_or_hat_loss: 9.0041e-04 - v_or_hat_loss: 8.3633e-06 - v_ex_hat_loss: 1.2614e-05 - load_v_hat_loss: 1.1384e-04 - prod_q_hat_loss: 3.3038e-04 - theta_or_hat_loss: 3.4001e-04 - theta_ex_hat_loss: 2.7873e-04 - val_loss: 0.0082 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.7039e-04 - val_p_ex_hat_loss: 5.6809e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 9.1232e-06 - val_v_ex_hat_loss: 1.1979e-05 - val_load_v_hat_loss: 1.3357e-04 - val_prod_q_hat_loss: 4.3079e-04 - val_theta_or_hat_loss: 4.3020e-04 - val_theta_ex_hat_loss: 3.2904e-04\n",
      "Epoch 101/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0061 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.3509e-04 - p_ex_hat_loss: 4.2688e-04 - q_ex_hat_loss: 9.8295e-04 - q_or_hat_loss: 8.7360e-04 - v_or_hat_loss: 7.6246e-06 - v_ex_hat_loss: 1.1671e-05 - load_v_hat_loss: 1.0361e-04 - prod_q_hat_loss: 3.1003e-04 - theta_or_hat_loss: 3.1289e-04 - theta_ex_hat_loss: 2.6091e-04 - val_loss: 0.0077 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 6.0254e-04 - val_p_ex_hat_loss: 4.9833e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 5.4946e-06 - val_v_ex_hat_loss: 1.0079e-05 - val_load_v_hat_loss: 1.5382e-04 - val_prod_q_hat_loss: 4.8495e-04 - val_theta_or_hat_loss: 4.1596e-04 - val_theta_ex_hat_loss: 3.2545e-04\n",
      "Epoch 102/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0061 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.4120e-04 - p_ex_hat_loss: 4.2139e-04 - q_ex_hat_loss: 9.7762e-04 - q_or_hat_loss: 8.7077e-04 - v_or_hat_loss: 7.2411e-06 - v_ex_hat_loss: 1.1398e-05 - load_v_hat_loss: 1.0768e-04 - prod_q_hat_loss: 3.1212e-04 - theta_or_hat_loss: 3.1869e-04 - theta_ex_hat_loss: 2.5917e-04 - val_loss: 0.0074 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.1168e-04 - val_p_ex_hat_loss: 5.3172e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 9.8482e-04 - val_v_or_hat_loss: 5.5213e-06 - val_v_ex_hat_loss: 8.8006e-06 - val_load_v_hat_loss: 1.1272e-04 - val_prod_q_hat_loss: 3.2013e-04 - val_theta_or_hat_loss: 3.3750e-04 - val_theta_ex_hat_loss: 2.8794e-04\n",
      "Epoch 103/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0060 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.3156e-04 - p_ex_hat_loss: 4.1145e-04 - q_ex_hat_loss: 9.5008e-04 - q_or_hat_loss: 8.5094e-04 - v_or_hat_loss: 6.3054e-06 - v_ex_hat_loss: 1.0011e-05 - load_v_hat_loss: 1.0398e-04 - prod_q_hat_loss: 2.9946e-04 - theta_or_hat_loss: 3.0462e-04 - theta_ex_hat_loss: 2.5946e-04 - val_loss: 0.0077 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.3546e-04 - val_p_ex_hat_loss: 5.0330e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 8.8358e-06 - val_v_ex_hat_loss: 1.1290e-05 - val_load_v_hat_loss: 1.2353e-04 - val_prod_q_hat_loss: 3.2361e-04 - val_theta_or_hat_loss: 3.6559e-04 - val_theta_ex_hat_loss: 3.2260e-04\n",
      "Epoch 104/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0061 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.5460e-04 - p_ex_hat_loss: 4.4123e-04 - q_ex_hat_loss: 9.7864e-04 - q_or_hat_loss: 8.5036e-04 - v_or_hat_loss: 7.5600e-06 - v_ex_hat_loss: 1.1364e-05 - load_v_hat_loss: 1.0099e-04 - prod_q_hat_loss: 3.0016e-04 - theta_or_hat_loss: 3.0823e-04 - theta_ex_hat_loss: 2.6048e-04 - val_loss: 0.0072 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.3908e-04 - val_p_ex_hat_loss: 5.0516e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.8560e-04 - val_v_or_hat_loss: 3.4494e-06 - val_v_ex_hat_loss: 8.3047e-06 - val_load_v_hat_loss: 1.1478e-04 - val_prod_q_hat_loss: 3.6568e-04 - val_theta_or_hat_loss: 3.3496e-04 - val_theta_ex_hat_loss: 2.7518e-04\n",
      "Epoch 105/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0060 - a_or_hat_loss: 0.0012 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.2975e-04 - p_ex_hat_loss: 4.1123e-04 - q_ex_hat_loss: 9.6359e-04 - q_or_hat_loss: 8.4004e-04 - v_or_hat_loss: 6.7929e-06 - v_ex_hat_loss: 1.0653e-05 - load_v_hat_loss: 1.0156e-04 - prod_q_hat_loss: 2.9397e-04 - theta_or_hat_loss: 2.9797e-04 - theta_ex_hat_loss: 2.4883e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 6.1718e-04 - val_p_ex_hat_loss: 5.3806e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 5.2092e-06 - val_v_ex_hat_loss: 8.4689e-06 - val_load_v_hat_loss: 1.4783e-04 - val_prod_q_hat_loss: 3.6723e-04 - val_theta_or_hat_loss: 3.8061e-04 - val_theta_ex_hat_loss: 3.3425e-04\n",
      "Epoch 106/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0059 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.3796e-04 - p_ex_hat_loss: 4.1840e-04 - q_ex_hat_loss: 9.6259e-04 - q_or_hat_loss: 8.2957e-04 - v_or_hat_loss: 7.0052e-06 - v_ex_hat_loss: 1.0785e-05 - load_v_hat_loss: 9.8210e-05 - prod_q_hat_loss: 2.9717e-04 - theta_or_hat_loss: 2.8923e-04 - theta_ex_hat_loss: 2.5533e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 4.8215e-04 - val_p_ex_hat_loss: 5.8243e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 4.7395e-06 - val_v_ex_hat_loss: 8.9785e-06 - val_load_v_hat_loss: 1.3355e-04 - val_prod_q_hat_loss: 3.6817e-04 - val_theta_or_hat_loss: 3.2547e-04 - val_theta_ex_hat_loss: 3.0881e-04\n",
      "Epoch 107/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0059 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.3076e-04 - p_ex_hat_loss: 4.2169e-04 - q_ex_hat_loss: 9.5451e-04 - q_or_hat_loss: 8.3341e-04 - v_or_hat_loss: 6.3696e-06 - v_ex_hat_loss: 9.9284e-06 - load_v_hat_loss: 9.8745e-05 - prod_q_hat_loss: 2.9248e-04 - theta_or_hat_loss: 2.9257e-04 - theta_ex_hat_loss: 2.5187e-04 - val_loss: 0.0072 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.3145e-04 - val_p_ex_hat_loss: 5.1533e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.9402e-04 - val_v_or_hat_loss: 3.3028e-06 - val_v_ex_hat_loss: 7.7899e-06 - val_load_v_hat_loss: 1.0629e-04 - val_prod_q_hat_loss: 3.6387e-04 - val_theta_or_hat_loss: 3.6506e-04 - val_theta_ex_hat_loss: 2.9040e-04\n",
      "Epoch 108/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0059 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.1786e-04 - p_ex_hat_loss: 4.1076e-04 - q_ex_hat_loss: 9.5987e-04 - q_or_hat_loss: 8.3242e-04 - v_or_hat_loss: 7.0194e-06 - v_ex_hat_loss: 1.0768e-05 - load_v_hat_loss: 1.0177e-04 - prod_q_hat_loss: 3.0359e-04 - theta_or_hat_loss: 3.0129e-04 - theta_ex_hat_loss: 2.5475e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.1306e-04 - val_p_ex_hat_loss: 4.7556e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 3.1311e-06 - val_v_ex_hat_loss: 6.5642e-06 - val_load_v_hat_loss: 1.7570e-04 - val_prod_q_hat_loss: 3.9065e-04 - val_theta_or_hat_loss: 3.6721e-04 - val_theta_ex_hat_loss: 4.2022e-04\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0059 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.3570e-04 - p_ex_hat_loss: 4.1535e-04 - q_ex_hat_loss: 9.5336e-04 - q_or_hat_loss: 8.2284e-04 - v_or_hat_loss: 8.0420e-06 - v_ex_hat_loss: 1.1481e-05 - load_v_hat_loss: 9.8283e-05 - prod_q_hat_loss: 2.9003e-04 - theta_or_hat_loss: 2.8636e-04 - theta_ex_hat_loss: 2.5146e-04 - val_loss: 0.0076 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 5.8359e-04 - val_p_ex_hat_loss: 5.4299e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0012 - val_v_or_hat_loss: 1.5796e-05 - val_v_ex_hat_loss: 1.9338e-05 - val_load_v_hat_loss: 1.2269e-04 - val_prod_q_hat_loss: 3.6707e-04 - val_theta_or_hat_loss: 3.2714e-04 - val_theta_ex_hat_loss: 2.9022e-04.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.4845e-04 - p_ex_hat_loss: 4.2395e-04 - q_ex_hat_loss: 9.6137e-04 - q_or_hat_loss: 8.2427e-04 - v_or_hat_loss: 8.6857e-06 - v_ex_hat_loss: 1.2164e-05 - load_v_hat_loss: 9.7705e-05 - prod_q_hat_loss: 2\n",
      "Epoch 110/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0058 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0012 - p_or_hat_loss: 4.2704e-04 - p_ex_hat_loss: 4.1564e-04 - q_ex_hat_loss: 9.3269e-04 - q_or_hat_loss: 8.1569e-04 - v_or_hat_loss: 7.0534e-06 - v_ex_hat_loss: 1.0390e-05 - load_v_hat_loss: 1.0519e-04 - prod_q_hat_loss: 2.9088e-04 - theta_or_hat_loss: 2.8119e-04 - theta_ex_hat_loss: 2.4225e-04 - val_loss: 0.0069 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.2138e-04 - val_p_ex_hat_loss: 4.9775e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 9.6138e-04 - val_v_or_hat_loss: 4.1326e-06 - val_v_ex_hat_loss: 8.6127e-06 - val_load_v_hat_loss: 1.0591e-04 - val_prod_q_hat_loss: 3.6664e-04 - val_theta_or_hat_loss: 3.1433e-04 - val_theta_ex_hat_loss: 2.7667e-04\n",
      "Epoch 111/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0056 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.0221e-04 - p_ex_hat_loss: 3.8717e-04 - q_ex_hat_loss: 9.0507e-04 - q_or_hat_loss: 8.0623e-04 - v_or_hat_loss: 5.4682e-06 - v_ex_hat_loss: 8.9608e-06 - load_v_hat_loss: 8.9799e-05 - prod_q_hat_loss: 2.8383e-04 - theta_or_hat_loss: 2.7009e-04 - theta_ex_hat_loss: 2.3714e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 6.4264e-04 - val_p_ex_hat_loss: 6.3099e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.4064e-04 - val_v_or_hat_loss: 3.1969e-06 - val_v_ex_hat_loss: 7.3405e-06 - val_load_v_hat_loss: 1.1264e-04 - val_prod_q_hat_loss: 3.7618e-04 - val_theta_or_hat_loss: 3.5599e-04 - val_theta_ex_hat_loss: 3.1295e-04\n",
      "Epoch 112/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0058 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.2672e-04 - p_ex_hat_loss: 4.2299e-04 - q_ex_hat_loss: 9.3396e-04 - q_or_hat_loss: 8.1536e-04 - v_or_hat_loss: 7.4206e-06 - v_ex_hat_loss: 1.0583e-05 - load_v_hat_loss: 9.6277e-05 - prod_q_hat_loss: 2.8867e-04 - theta_or_hat_loss: 2.8346e-04 - theta_ex_hat_loss: 2.4543e-04 - val_loss: 0.0073 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.5347e-04 - val_p_ex_hat_loss: 4.8067e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 9.9561e-04 - val_v_or_hat_loss: 3.7814e-06 - val_v_ex_hat_loss: 8.6603e-06 - val_load_v_hat_loss: 1.8861e-04 - val_prod_q_hat_loss: 4.4490e-04 - val_theta_or_hat_loss: 3.2085e-04 - val_theta_ex_hat_loss: 2.8086e-04\n",
      "Epoch 113/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0057 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.0658e-04 - p_ex_hat_loss: 3.9413e-04 - q_ex_hat_loss: 9.4394e-04 - q_or_hat_loss: 8.5110e-04 - v_or_hat_loss: 7.2652e-06 - v_ex_hat_loss: 1.0729e-05 - load_v_hat_loss: 1.0349e-04 - prod_q_hat_loss: 2.7694e-04 - theta_or_hat_loss: 2.8790e-04 - theta_ex_hat_loss: 2.5037e-04 - val_loss: 0.0077 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.6765e-04 - val_p_ex_hat_loss: 4.0916e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 4.3225e-06 - val_v_ex_hat_loss: 7.7310e-06 - val_load_v_hat_loss: 1.5134e-04 - val_prod_q_hat_loss: 4.5767e-04 - val_theta_or_hat_loss: 3.4553e-04 - val_theta_ex_hat_loss: 3.4156e-04\n",
      "Epoch 114/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0056 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.0085e-04 - p_ex_hat_loss: 3.8916e-04 - q_ex_hat_loss: 9.3157e-04 - q_or_hat_loss: 8.0271e-04 - v_or_hat_loss: 6.2943e-06 - v_ex_hat_loss: 9.5232e-06 - load_v_hat_loss: 9.3073e-05 - prod_q_hat_loss: 2.8100e-04 - theta_or_hat_loss: 2.7159e-04 - theta_ex_hat_loss: 2.3910e-04 - val_loss: 0.0066 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.8095e-04 - val_p_ex_hat_loss: 4.5246e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.9673e-04 - val_v_or_hat_loss: 2.6654e-06 - val_v_ex_hat_loss: 6.1970e-06 - val_load_v_hat_loss: 1.1497e-04 - val_prod_q_hat_loss: 3.1825e-04 - val_theta_or_hat_loss: 3.5251e-04 - val_theta_ex_hat_loss: 2.9328e-04\n",
      "Epoch 115/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0056 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.9786e-04 - p_ex_hat_loss: 3.8985e-04 - q_ex_hat_loss: 9.1028e-04 - q_or_hat_loss: 7.9682e-04 - v_or_hat_loss: 5.9157e-06 - v_ex_hat_loss: 9.0880e-06 - load_v_hat_loss: 9.4088e-05 - prod_q_hat_loss: 2.8306e-04 - theta_or_hat_loss: 2.7551e-04 - theta_ex_hat_loss: 2.4147e-04 - val_loss: 0.0074 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.5388e-04 - val_p_ex_hat_loss: 6.0895e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 5.7026e-06 - val_v_ex_hat_loss: 9.2410e-06 - val_load_v_hat_loss: 1.0803e-04 - val_prod_q_hat_loss: 3.0680e-04 - val_theta_or_hat_loss: 4.6056e-04 - val_theta_ex_hat_loss: 3.5107e-04\n",
      "Epoch 116/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0056 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.0848e-04 - p_ex_hat_loss: 3.9812e-04 - q_ex_hat_loss: 9.0701e-04 - q_or_hat_loss: 7.8963e-04 - v_or_hat_loss: 7.3269e-06 - v_ex_hat_loss: 1.0402e-05 - load_v_hat_loss: 9.3751e-05 - prod_q_hat_loss: 2.7626e-04 - theta_or_hat_loss: 2.7569e-04 - theta_ex_hat_loss: 2.4315e-04 - val_loss: 0.0071 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.8502e-04 - val_p_ex_hat_loss: 5.6237e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.5245e-04 - val_v_or_hat_loss: 7.5249e-06 - val_v_ex_hat_loss: 7.7113e-06 - val_load_v_hat_loss: 1.2679e-04 - val_prod_q_hat_loss: 4.1000e-04 - val_theta_or_hat_loss: 3.0834e-04 - val_theta_ex_hat_loss: 2.8255e-04\n",
      "Epoch 117/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0056 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.1968e-04 - p_ex_hat_loss: 4.0118e-04 - q_ex_hat_loss: 9.1827e-04 - q_or_hat_loss: 7.9702e-04 - v_or_hat_loss: 7.4330e-06 - v_ex_hat_loss: 1.0214e-05 - load_v_hat_loss: 9.6481e-05 - prod_q_hat_loss: 2.8113e-04 - theta_or_hat_loss: 2.7150e-04 - theta_ex_hat_loss: 2.3706e-04 - val_loss: 0.0076 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.6209e-04 - val_p_ex_hat_loss: 5.9295e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.9722e-04 - val_v_or_hat_loss: 1.6832e-05 - val_v_ex_hat_loss: 2.2312e-05 - val_load_v_hat_loss: 1.1965e-04 - val_prod_q_hat_loss: 3.0900e-04 - val_theta_or_hat_loss: 4.5354e-04 - val_theta_ex_hat_loss: 4.2377e-04\n",
      "Epoch 118/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0057 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.2902e-04 - p_ex_hat_loss: 4.0946e-04 - q_ex_hat_loss: 9.3944e-04 - q_or_hat_loss: 8.0581e-04 - v_or_hat_loss: 9.5673e-06 - v_ex_hat_loss: 1.2481e-05 - load_v_hat_loss: 9.9420e-05 - prod_q_hat_loss: 2.8296e-04 - theta_or_hat_loss: 2.7199e-04 - theta_ex_hat_loss: 2.4650e-04 - val_loss: 0.0067 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 4.5882e-04 - val_p_ex_hat_loss: 4.2418e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.4510e-04 - val_v_or_hat_loss: 3.1468e-06 - val_v_ex_hat_loss: 6.9643e-06 - val_load_v_hat_loss: 1.0191e-04 - val_prod_q_hat_loss: 3.2665e-04 - val_theta_or_hat_loss: 2.9931e-04 - val_theta_ex_hat_loss: 2.5489e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0055 - a_or_hat_loss: 0.0011 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.9171e-04 - p_ex_hat_loss: 3.7616e-04 - q_ex_hat_loss: 8.9173e-04 - q_or_hat_loss: 7.6020e-04 - v_or_hat_loss: 5.6486e-06 - v_ex_hat_loss: 8.4935e-06 - load_v_hat_loss: 8.8757e-05 - prod_q_hat_loss: 2.6842e-04 - theta_or_hat_loss: 2.5928e-04 - theta_ex_hat_loss: 2.2851e-04 - val_loss: 0.0076 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.3961e-04 - val_p_ex_hat_loss: 4.1216e-04 - val_q_ex_hat_loss: 0.0014 - val_q_or_hat_loss: 9.8855e-04 - val_v_or_hat_loss: 3.3487e-06 - val_v_ex_hat_loss: 6.6036e-06 - val_load_v_hat_loss: 1.3764e-04 - val_prod_q_hat_loss: 8.2960e-04 - val_theta_or_hat_loss: 3.3173e-04 - val_theta_ex_hat_loss: 3.2500e-04\n",
      "Epoch 120/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0054 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7035e-04 - p_ex_hat_loss: 3.5647e-04 - q_ex_hat_loss: 8.6390e-04 - q_or_hat_loss: 7.5623e-04 - v_or_hat_loss: 5.9860e-06 - v_ex_hat_loss: 8.9115e-06 - load_v_hat_loss: 8.7830e-05 - prod_q_hat_loss: 2.7889e-04 - theta_or_hat_loss: 2.6065e-04 - theta_ex_hat_loss: 2.2960e-04 - val_loss: 0.0067 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 4.4911e-04 - val_p_ex_hat_loss: 4.2012e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 8.5978e-04 - val_v_or_hat_loss: 3.2212e-06 - val_v_ex_hat_loss: 6.2177e-06 - val_load_v_hat_loss: 1.1788e-04 - val_prod_q_hat_loss: 2.9474e-04 - val_theta_or_hat_loss: 2.9103e-04 - val_theta_ex_hat_loss: 2.6567e-04\n",
      "Epoch 121/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0053 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.6420e-04 - p_ex_hat_loss: 3.6023e-04 - q_ex_hat_loss: 8.4932e-04 - q_or_hat_loss: 7.4238e-04 - v_or_hat_loss: 4.7112e-06 - v_ex_hat_loss: 7.6270e-06 - load_v_hat_loss: 8.8555e-05 - prod_q_hat_loss: 2.6079e-04 - theta_or_hat_loss: 2.4868e-04 - theta_ex_hat_loss: 2.2424e-04 - val_loss: 0.0063 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.1381e-04 - val_p_ex_hat_loss: 3.8952e-04 - val_q_ex_hat_loss: 9.7989e-04 - val_q_or_hat_loss: 8.1538e-04 - val_v_or_hat_loss: 3.5637e-06 - val_v_ex_hat_loss: 6.8464e-06 - val_load_v_hat_loss: 9.7905e-05 - val_prod_q_hat_loss: 3.4248e-04 - val_theta_or_hat_loss: 2.8334e-04 - val_theta_ex_hat_loss: 2.3893e-04\n",
      "Epoch 122/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0055 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.9945e-04 - p_ex_hat_loss: 3.8134e-04 - q_ex_hat_loss: 8.8583e-04 - q_or_hat_loss: 7.7519e-04 - v_or_hat_loss: 8.5094e-06 - v_ex_hat_loss: 1.1296e-05 - load_v_hat_loss: 9.0394e-05 - prod_q_hat_loss: 2.6900e-04 - theta_or_hat_loss: 2.5212e-04 - theta_ex_hat_loss: 2.3065e-04 - val_loss: 0.0066 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.3329e-04 - val_p_ex_hat_loss: 4.4490e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 9.3716e-04 - val_v_or_hat_loss: 5.0000e-06 - val_v_ex_hat_loss: 7.3332e-06 - val_load_v_hat_loss: 1.4017e-04 - val_prod_q_hat_loss: 3.7110e-04 - val_theta_or_hat_loss: 2.9714e-04 - val_theta_ex_hat_loss: 2.8888e-040011 - p_or_hat_loss: 4.1911e-04 - p_ex_hat_loss: 3.9657e-04 - q_ex_hat_loss: 8.9827e-04 - q_or_hat_loss: 7.9352e-04 - v_or_hat_loss: 1.0591e-05 - v_ex_hat_loss: 1.3464e-05 - l\n",
      "Epoch 123/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0052 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7889e-04 - p_ex_hat_loss: 3.6367e-04 - q_ex_hat_loss: 8.5733e-04 - q_or_hat_loss: 7.3461e-04 - v_or_hat_loss: 5.5207e-06 - v_ex_hat_loss: 8.2125e-06 - load_v_hat_loss: 8.8201e-05 - prod_q_hat_loss: 2.4681e-04 - theta_or_hat_loss: 2.4493e-04 - theta_ex_hat_loss: 2.1820e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0015 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.7793e-04 - val_p_ex_hat_loss: 4.8197e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 8.3385e-06 - val_v_ex_hat_loss: 9.5539e-06 - val_load_v_hat_loss: 1.4173e-04 - val_prod_q_hat_loss: 3.8480e-04 - val_theta_or_hat_loss: 3.9534e-04 - val_theta_ex_hat_loss: 3.4697e-04\n",
      "Epoch 124/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0054 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.8801e-04 - p_ex_hat_loss: 3.6703e-04 - q_ex_hat_loss: 8.7219e-04 - q_or_hat_loss: 7.6560e-04 - v_or_hat_loss: 6.6624e-06 - v_ex_hat_loss: 9.3823e-06 - load_v_hat_loss: 9.3058e-05 - prod_q_hat_loss: 2.7640e-04 - theta_or_hat_loss: 2.5090e-04 - theta_ex_hat_loss: 2.3128e-04 - val_loss: 0.0066 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.5985e-04 - val_p_ex_hat_loss: 4.2939e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.5862e-04 - val_v_or_hat_loss: 4.7843e-06 - val_v_ex_hat_loss: 6.0680e-06 - val_load_v_hat_loss: 1.1779e-04 - val_prod_q_hat_loss: 4.7406e-04 - val_theta_or_hat_loss: 3.1486e-04 - val_theta_ex_hat_loss: 2.5859e-04\n",
      "Epoch 125/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0053 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7348e-04 - p_ex_hat_loss: 3.5355e-04 - q_ex_hat_loss: 8.6613e-04 - q_or_hat_loss: 7.4354e-04 - v_or_hat_loss: 5.9545e-06 - v_ex_hat_loss: 8.6380e-06 - load_v_hat_loss: 8.9440e-05 - prod_q_hat_loss: 2.6863e-04 - theta_or_hat_loss: 2.4514e-04 - theta_ex_hat_loss: 2.1983e-04 - val_loss: 0.0065 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.2341e-04 - val_p_ex_hat_loss: 4.2334e-04 - val_q_ex_hat_loss: 9.1905e-04 - val_q_or_hat_loss: 8.7121e-04 - val_v_or_hat_loss: 3.8663e-06 - val_v_ex_hat_loss: 8.7552e-06 - val_load_v_hat_loss: 1.0670e-04 - val_prod_q_hat_loss: 2.9388e-04 - val_theta_or_hat_loss: 2.8074e-04 - val_theta_ex_hat_loss: 3.2896e-04\n",
      "Epoch 126/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0052 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7636e-04 - p_ex_hat_loss: 3.5530e-04 - q_ex_hat_loss: 8.5097e-04 - q_or_hat_loss: 7.3602e-04 - v_or_hat_loss: 6.3037e-06 - v_ex_hat_loss: 8.9639e-06 - load_v_hat_loss: 8.8862e-05 - prod_q_hat_loss: 2.5560e-04 - theta_or_hat_loss: 2.4468e-04 - theta_ex_hat_loss: 2.2138e-04 - val_loss: 0.0064 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.3565e-04 - val_p_ex_hat_loss: 3.9466e-04 - val_q_ex_hat_loss: 9.1750e-04 - val_q_or_hat_loss: 8.1030e-04 - val_v_or_hat_loss: 3.4023e-06 - val_v_ex_hat_loss: 5.7268e-06 - val_load_v_hat_loss: 1.5414e-04 - val_prod_q_hat_loss: 4.1716e-04 - val_theta_or_hat_loss: 2.9998e-04 - val_theta_ex_hat_loss: 2.3772e-04\n",
      "Epoch 127/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0052 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7608e-04 - p_ex_hat_loss: 3.5728e-04 - q_ex_hat_loss: 8.3175e-04 - q_or_hat_loss: 7.2839e-04 - v_or_hat_loss: 6.4650e-06 - v_ex_hat_loss: 8.8422e-06 - load_v_hat_loss: 9.3285e-05 - prod_q_hat_loss: 2.4992e-04 - theta_or_hat_loss: 2.3753e-04 - theta_ex_hat_loss: 2.1531e-04 - val_loss: 0.0062 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.0342e-04 - val_p_ex_hat_loss: 4.3476e-04 - val_q_ex_hat_loss: 8.9478e-04 - val_q_or_hat_loss: 8.5446e-04 - val_v_or_hat_loss: 5.7139e-06 - val_v_ex_hat_loss: 8.5467e-06 - val_load_v_hat_loss: 1.0732e-04 - val_prod_q_hat_loss: 2.7849e-04 - val_theta_or_hat_loss: 2.8520e-04 - val_theta_ex_hat_loss: 2.4627e-04\n",
      "Epoch 128/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0052 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.6420e-04 - p_ex_hat_loss: 3.4765e-04 - q_ex_hat_loss: 8.4211e-04 - q_or_hat_loss: 7.4051e-04 - v_or_hat_loss: 6.2280e-06 - v_ex_hat_loss: 8.7362e-06 - load_v_hat_loss: 9.1508e-05 - prod_q_hat_loss: 2.6300e-04 - theta_or_hat_loss: 2.3731e-04 - theta_ex_hat_loss: 2.1658e-04 - val_loss: 0.0069 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 5.1878e-04 - val_p_ex_hat_loss: 4.9132e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 6.5808e-06 - val_v_ex_hat_loss: 8.5614e-06 - val_load_v_hat_loss: 9.7054e-05 - val_prod_q_hat_loss: 2.9692e-04 - val_theta_or_hat_loss: 3.5535e-04 - val_theta_ex_hat_loss: 3.3229e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0052 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.8269e-04 - p_ex_hat_loss: 3.7479e-04 - q_ex_hat_loss: 8.3720e-04 - q_or_hat_loss: 7.3417e-04 - v_or_hat_loss: 6.2893e-06 - v_ex_hat_loss: 8.7676e-06 - load_v_hat_loss: 8.7378e-05 - prod_q_hat_loss: 2.5301e-04 - theta_or_hat_loss: 2.3736e-04 - theta_ex_hat_loss: 2.2236e-04 - val_loss: 0.0062 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.2985e-04 - val_p_ex_hat_loss: 3.8111e-04 - val_q_ex_hat_loss: 9.8168e-04 - val_q_or_hat_loss: 9.1691e-04 - val_v_or_hat_loss: 6.5595e-06 - val_v_ex_hat_loss: 9.6303e-06 - val_load_v_hat_loss: 8.3559e-05 - val_prod_q_hat_loss: 2.9324e-04 - val_theta_or_hat_loss: 2.5728e-04 - val_theta_ex_hat_loss: 2.3282e-04\n",
      "Epoch 130/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0050 - a_or_hat_loss: 9.8431e-04 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.4926e-04 - p_ex_hat_loss: 3.3596e-04 - q_ex_hat_loss: 8.1709e-04 - q_or_hat_loss: 7.2296e-04 - v_or_hat_loss: 5.2773e-06 - v_ex_hat_loss: 7.6673e-06 - load_v_hat_loss: 7.9826e-05 - prod_q_hat_loss: 2.4508e-04 - theta_or_hat_loss: 2.2105e-04 - theta_ex_hat_loss: 2.0541e-04 - val_loss: 0.0065 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 4.7460e-04 - val_p_ex_hat_loss: 4.6968e-04 - val_q_ex_hat_loss: 9.5287e-04 - val_q_or_hat_loss: 8.8834e-04 - val_v_or_hat_loss: 5.1023e-06 - val_v_ex_hat_loss: 1.0119e-05 - val_load_v_hat_loss: 9.0078e-05 - val_prod_q_hat_loss: 2.8948e-04 - val_theta_or_hat_loss: 3.2733e-04 - val_theta_ex_hat_loss: 2.8863e-04\n",
      "Epoch 131/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0052 - a_or_hat_loss: 9.9336e-04 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.7302e-04 - p_ex_hat_loss: 3.5074e-04 - q_ex_hat_loss: 8.4142e-04 - q_or_hat_loss: 7.2359e-04 - v_or_hat_loss: 5.5235e-06 - v_ex_hat_loss: 7.8981e-06 - load_v_hat_loss: 9.7599e-05 - prod_q_hat_loss: 2.6691e-04 - theta_or_hat_loss: 2.4716e-04 - theta_ex_hat_loss: 2.2496e-04 - val_loss: 0.0062 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.5100e-04 - val_p_ex_hat_loss: 4.5088e-04 - val_q_ex_hat_loss: 8.8321e-04 - val_q_or_hat_loss: 8.2464e-04 - val_v_or_hat_loss: 2.4551e-06 - val_v_ex_hat_loss: 5.6040e-06 - val_load_v_hat_loss: 1.0658e-04 - val_prod_q_hat_loss: 2.7747e-04 - val_theta_or_hat_loss: 2.6510e-04 - val_theta_ex_hat_loss: 2.7084e-04\n",
      "Epoch 132/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0054 - a_or_hat_loss: 0.0010 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 4.0812e-04 - p_ex_hat_loss: 3.7934e-04 - q_ex_hat_loss: 8.7768e-04 - q_or_hat_loss: 7.5631e-04 - v_or_hat_loss: 7.3801e-06 - v_ex_hat_loss: 9.9239e-06 - load_v_hat_loss: 9.5189e-05 - prod_q_hat_loss: 2.7646e-04 - theta_or_hat_loss: 2.5218e-04 - theta_ex_hat_loss: 2.2965e-04 - val_loss: 0.0064 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.1191e-04 - val_p_ex_hat_loss: 3.8113e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 8.4761e-04 - val_v_or_hat_loss: 5.6868e-06 - val_v_ex_hat_loss: 8.3558e-06 - val_load_v_hat_loss: 1.1666e-04 - val_prod_q_hat_loss: 2.7087e-04 - val_theta_or_hat_loss: 3.4005e-04 - val_theta_ex_hat_loss: 2.7950e-04\n",
      "Epoch 133/200\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0051 - a_or_hat_loss: 9.9063e-04 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.6542e-04 - p_ex_hat_loss: 3.5144e-04 - q_ex_hat_loss: 8.3000e-04 - q_or_hat_loss: 7.1633e-04 - v_or_hat_loss: 5.7409e-06 - v_ex_hat_loss: 7.9409e-06 - load_v_hat_loss: 9.4380e-05 - prod_q_hat_loss: 2.5177e-04 - theta_or_hat_loss: 2.3674e-04 - theta_ex_hat_loss: 2.2118e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.8646e-04 - val_p_ex_hat_loss: 3.6997e-04 - val_q_ex_hat_loss: 9.0538e-04 - val_q_or_hat_loss: 8.8865e-04 - val_v_or_hat_loss: 2.5966e-06 - val_v_ex_hat_loss: 4.8614e-06 - val_load_v_hat_loss: 1.0433e-04 - val_prod_q_hat_loss: 2.6942e-04 - val_theta_or_hat_loss: 2.5448e-04 - val_theta_ex_hat_loss: 2.3025e-04\n",
      "Epoch 134/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0049 - a_or_hat_loss: 9.6439e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.5114e-04 - p_ex_hat_loss: 3.3321e-04 - q_ex_hat_loss: 7.9233e-04 - q_or_hat_loss: 7.0726e-04 - v_or_hat_loss: 5.2565e-06 - v_ex_hat_loss: 7.4035e-06 - load_v_hat_loss: 8.3104e-05 - prod_q_hat_loss: 2.3483e-04 - theta_or_hat_loss: 2.2153e-04 - theta_ex_hat_loss: 2.0249e-04 - val_loss: 0.0073 - val_a_or_hat_loss: 0.0014 - val_a_ex_hat_loss: 0.0016 - val_p_or_hat_loss: 7.1829e-04 - val_p_ex_hat_loss: 5.1192e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.4066e-04 - val_v_or_hat_loss: 2.1422e-05 - val_v_ex_hat_loss: 2.3471e-05 - val_load_v_hat_loss: 1.0822e-04 - val_prod_q_hat_loss: 3.4894e-04 - val_theta_or_hat_loss: 2.8075e-04 - val_theta_ex_hat_loss: 2.5650e-04\n",
      "Epoch 135/200\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0052 - a_or_hat_loss: 9.9068e-04 - a_ex_hat_loss: 0.0011 - p_or_hat_loss: 3.8519e-04 - p_ex_hat_loss: 3.5410e-04 - q_ex_hat_loss: 8.3692e-04 - q_or_hat_loss: 7.2624e-04 - v_or_hat_loss: 6.5675e-06 - v_ex_hat_loss: 8.8050e-06 - load_v_hat_loss: 8.6321e-05 - prod_q_hat_loss: 2.6087e-04 - theta_or_hat_loss: 2.4872e-04 - theta_ex_hat_loss: 2.2959e-04 - val_loss: 0.0064 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.8264e-04 - val_p_ex_hat_loss: 4.6827e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.4624e-04 - val_v_or_hat_loss: 3.7692e-06 - val_v_ex_hat_loss: 6.0788e-06 - val_load_v_hat_loss: 9.6296e-05 - val_prod_q_hat_loss: 2.7012e-04 - val_theta_or_hat_loss: 2.9277e-04 - val_theta_ex_hat_loss: 2.4540e-04\n",
      "Epoch 136/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0051 - a_or_hat_loss: 9.6930e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.5556e-04 - p_ex_hat_loss: 3.3550e-04 - q_ex_hat_loss: 8.5056e-04 - q_or_hat_loss: 7.1886e-04 - v_or_hat_loss: 5.5084e-06 - v_ex_hat_loss: 7.7035e-06 - load_v_hat_loss: 8.5917e-05 - prod_q_hat_loss: 2.5565e-04 - theta_or_hat_loss: 2.3657e-04 - theta_ex_hat_loss: 2.2007e-04 - val_loss: 0.0059 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.9545e-04 - val_p_ex_hat_loss: 3.4943e-04 - val_q_ex_hat_loss: 9.0293e-04 - val_q_or_hat_loss: 7.9358e-04 - val_v_or_hat_loss: 2.8664e-06 - val_v_ex_hat_loss: 5.1199e-06 - val_load_v_hat_loss: 1.0061e-04 - val_prod_q_hat_loss: 2.7613e-04 - val_theta_or_hat_loss: 2.7677e-04 - val_theta_ex_hat_loss: 2.7345e-04\n",
      "Epoch 137/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0051 - a_or_hat_loss: 9.6447e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.7330e-04 - p_ex_hat_loss: 3.5177e-04 - q_ex_hat_loss: 8.3282e-04 - q_or_hat_loss: 7.0907e-04 - v_or_hat_loss: 7.4925e-06 - v_ex_hat_loss: 9.8283e-06 - load_v_hat_loss: 9.0179e-05 - prod_q_hat_loss: 2.4771e-04 - theta_or_hat_loss: 2.4342e-04 - theta_ex_hat_loss: 2.1977e-04 - val_loss: 0.0058 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.2686e-04 - val_p_ex_hat_loss: 3.8041e-04 - val_q_ex_hat_loss: 8.4363e-04 - val_q_or_hat_loss: 7.6089e-04 - val_v_or_hat_loss: 3.3828e-06 - val_v_ex_hat_loss: 4.8690e-06 - val_load_v_hat_loss: 8.5976e-05 - val_prod_q_hat_loss: 3.2745e-04 - val_theta_or_hat_loss: 2.3538e-04 - val_theta_ex_hat_loss: 2.3122e-04\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0051 - a_or_hat_loss: 9.6160e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.6085e-04 - p_ex_hat_loss: 3.4734e-04 - q_ex_hat_loss: 8.3418e-04 - q_or_hat_loss: 7.1535e-04 - v_or_hat_loss: 6.6018e-06 - v_ex_hat_loss: 8.5824e-06 - load_v_hat_loss: 9.1156e-05 - prod_q_hat_loss: 2.5108e-04 - theta_or_hat_loss: 2.3504e-04 - theta_ex_hat_loss: 2.1566e-04 - val_loss: 0.0073 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 5.3181e-04 - val_p_ex_hat_loss: 5.1309e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 0.0010 - val_v_or_hat_loss: 1.6580e-05 - val_v_ex_hat_loss: 1.7073e-05 - val_load_v_hat_loss: 1.7098e-04 - val_prod_q_hat_loss: 4.0065e-04 - val_theta_or_hat_loss: 3.4476e-04 - val_theta_ex_hat_loss: 2.5333e-04\n",
      "Epoch 139/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0050 - a_or_hat_loss: 9.5275e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.5874e-04 - p_ex_hat_loss: 3.3720e-04 - q_ex_hat_loss: 8.0683e-04 - q_or_hat_loss: 7.0698e-04 - v_or_hat_loss: 6.2816e-06 - v_ex_hat_loss: 8.2682e-06 - load_v_hat_loss: 8.6101e-05 - prod_q_hat_loss: 2.5138e-04 - theta_or_hat_loss: 2.2902e-04 - theta_ex_hat_loss: 2.1038e-04 - val_loss: 0.0068 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 4.8887e-04 - val_p_ex_hat_loss: 3.9547e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.8041e-04 - val_v_or_hat_loss: 3.2098e-06 - val_v_ex_hat_loss: 4.9497e-06 - val_load_v_hat_loss: 1.5504e-04 - val_prod_q_hat_loss: 4.2731e-04 - val_theta_or_hat_loss: 3.4348e-04 - val_theta_ex_hat_loss: 3.0496e-04\n",
      "Epoch 140/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0051 - a_or_hat_loss: 9.6045e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.7497e-04 - p_ex_hat_loss: 3.4477e-04 - q_ex_hat_loss: 8.2467e-04 - q_or_hat_loss: 7.2468e-04 - v_or_hat_loss: 5.8830e-06 - v_ex_hat_loss: 7.8485e-06 - load_v_hat_loss: 8.6526e-05 - prod_q_hat_loss: 2.5703e-04 - theta_or_hat_loss: 2.2910e-04 - theta_ex_hat_loss: 2.1274e-04 - val_loss: 0.0072 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0015 - val_p_or_hat_loss: 4.5860e-04 - val_p_ex_hat_loss: 5.0439e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 9.4648e-04 - val_v_or_hat_loss: 1.8709e-05 - val_v_ex_hat_loss: 2.2178e-05 - val_load_v_hat_loss: 9.6141e-05 - val_prod_q_hat_loss: 2.5528e-04 - val_theta_or_hat_loss: 3.0468e-04 - val_theta_ex_hat_loss: 2.8707e-04\n",
      "Epoch 141/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0050 - a_or_hat_loss: 9.5823e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.5522e-04 - p_ex_hat_loss: 3.4201e-04 - q_ex_hat_loss: 8.1404e-04 - q_or_hat_loss: 6.9141e-04 - v_or_hat_loss: 5.8867e-06 - v_ex_hat_loss: 8.0224e-06 - load_v_hat_loss: 8.3599e-05 - prod_q_hat_loss: 2.3190e-04 - theta_or_hat_loss: 2.2435e-04 - theta_ex_hat_loss: 2.0449e-04 - val_loss: 0.0063 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.0378e-04 - val_p_ex_hat_loss: 4.2179e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 8.5314e-04 - val_v_or_hat_loss: 4.9710e-06 - val_v_ex_hat_loss: 6.2038e-06 - val_load_v_hat_loss: 1.0178e-04 - val_prod_q_hat_loss: 3.2668e-04 - val_theta_or_hat_loss: 3.0357e-04 - val_theta_ex_hat_loss: 2.5128e-04\n",
      "Epoch 142/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0049 - a_or_hat_loss: 9.5243e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.4899e-04 - p_ex_hat_loss: 3.2780e-04 - q_ex_hat_loss: 8.1051e-04 - q_or_hat_loss: 7.0354e-04 - v_or_hat_loss: 6.1717e-06 - v_ex_hat_loss: 8.2330e-06 - load_v_hat_loss: 8.3678e-05 - prod_q_hat_loss: 2.4765e-04 - theta_or_hat_loss: 2.2814e-04 - theta_ex_hat_loss: 2.1447e-04 - val_loss: 0.0079 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 6.7427e-04 - val_p_ex_hat_loss: 5.1951e-04 - val_q_ex_hat_loss: 0.0017 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 2.5538e-05 - val_v_ex_hat_loss: 2.6116e-05 - val_load_v_hat_loss: 1.5507e-04 - val_prod_q_hat_loss: 3.3330e-04 - val_theta_or_hat_loss: 2.9368e-04 - val_theta_ex_hat_loss: 3.0905e-04\n",
      "Epoch 143/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0051 - a_or_hat_loss: 9.5808e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.9618e-04 - p_ex_hat_loss: 3.7188e-04 - q_ex_hat_loss: 8.5754e-04 - q_or_hat_loss: 7.1030e-04 - v_or_hat_loss: 7.5651e-06 - v_ex_hat_loss: 9.5635e-06 - load_v_hat_loss: 8.0318e-05 - prod_q_hat_loss: 2.5479e-04 - theta_or_hat_loss: 2.3224e-04 - theta_ex_hat_loss: 2.1591e-04 - val_loss: 0.0068 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.7650e-04 - val_p_ex_hat_loss: 5.1098e-04 - val_q_ex_hat_loss: 0.0013 - val_q_or_hat_loss: 9.5079e-04 - val_v_or_hat_loss: 6.9137e-06 - val_v_ex_hat_loss: 7.9883e-06 - val_load_v_hat_loss: 9.2163e-05 - val_prod_q_hat_loss: 2.3896e-04 - val_theta_or_hat_loss: 2.3709e-04 - val_theta_ex_hat_loss: 2.3893e-04\n",
      "Epoch 144/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0049 - a_or_hat_loss: 9.4606e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.4207e-04 - p_ex_hat_loss: 3.3242e-04 - q_ex_hat_loss: 7.9404e-04 - q_or_hat_loss: 6.8793e-04 - v_or_hat_loss: 5.7414e-06 - v_ex_hat_loss: 7.7215e-06 - load_v_hat_loss: 8.5316e-05 - prod_q_hat_loss: 2.4461e-04 - theta_or_hat_loss: 2.1890e-04 - theta_ex_hat_loss: 2.0816e-04 - val_loss: 0.0062 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 5.4346e-04 - val_p_ex_hat_loss: 3.9086e-04 - val_q_ex_hat_loss: 9.0387e-04 - val_q_or_hat_loss: 8.2106e-04 - val_v_or_hat_loss: 6.4037e-06 - val_v_ex_hat_loss: 8.9300e-06 - val_load_v_hat_loss: 1.0118e-04 - val_prod_q_hat_loss: 2.9692e-04 - val_theta_or_hat_loss: 2.7281e-04 - val_theta_ex_hat_loss: 2.7709e-04\n",
      "Epoch 145/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0049 - a_or_hat_loss: 9.3859e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.5904e-04 - p_ex_hat_loss: 3.3156e-04 - q_ex_hat_loss: 7.9169e-04 - q_or_hat_loss: 6.9061e-04 - v_or_hat_loss: 6.0664e-06 - v_ex_hat_loss: 8.1368e-06 - load_v_hat_loss: 8.5442e-05 - prod_q_hat_loss: 2.3644e-04 - theta_or_hat_loss: 2.1835e-04 - theta_ex_hat_loss: 2.0863e-04 - val_loss: 0.0058 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.8252e-04 - val_p_ex_hat_loss: 3.4233e-04 - val_q_ex_hat_loss: 8.1633e-04 - val_q_or_hat_loss: 8.3670e-04 - val_v_or_hat_loss: 2.4070e-06 - val_v_ex_hat_loss: 4.0610e-06 - val_load_v_hat_loss: 1.3114e-04 - val_prod_q_hat_loss: 2.9930e-04 - val_theta_or_hat_loss: 2.2519e-04 - val_theta_ex_hat_loss: 2.1837e-04\n",
      "Epoch 146/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0048 - a_or_hat_loss: 9.2731e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.4235e-04 - p_ex_hat_loss: 3.1931e-04 - q_ex_hat_loss: 7.5845e-04 - q_or_hat_loss: 6.6856e-04 - v_or_hat_loss: 5.0885e-06 - v_ex_hat_loss: 7.0311e-06 - load_v_hat_loss: 8.3628e-05 - prod_q_hat_loss: 2.4369e-04 - theta_or_hat_loss: 2.1174e-04 - theta_ex_hat_loss: 1.9998e-04 - val_loss: 0.0056 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.6961e-04 - val_p_ex_hat_loss: 3.2616e-04 - val_q_ex_hat_loss: 9.6012e-04 - val_q_or_hat_loss: 7.3022e-04 - val_v_or_hat_loss: 7.4655e-06 - val_v_ex_hat_loss: 8.7825e-06 - val_load_v_hat_loss: 1.0744e-04 - val_prod_q_hat_loss: 2.3853e-04 - val_theta_or_hat_loss: 2.4272e-04 - val_theta_ex_hat_loss: 2.3035e-04\n",
      "Epoch 147/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0047 - a_or_hat_loss: 9.1633e-04 - a_ex_hat_loss: 9.9387e-04 - p_or_hat_loss: 3.3131e-04 - p_ex_hat_loss: 3.1940e-04 - q_ex_hat_loss: 7.5804e-04 - q_or_hat_loss: 6.6318e-04 - v_or_hat_loss: 5.4124e-06 - v_ex_hat_loss: 7.3349e-06 - load_v_hat_loss: 7.8718e-05 - prod_q_hat_loss: 2.3041e-04 - theta_or_hat_loss: 2.1080e-04 - theta_ex_hat_loss: 1.9861e-04 - val_loss: 0.0066 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.4229e-04 - val_p_ex_hat_loss: 4.9589e-04 - val_q_ex_hat_loss: 9.8491e-04 - val_q_or_hat_loss: 8.6658e-04 - val_v_or_hat_loss: 3.5406e-06 - val_v_ex_hat_loss: 5.8641e-06 - val_load_v_hat_loss: 9.4674e-05 - val_prod_q_hat_loss: 2.7770e-04 - val_theta_or_hat_loss: 4.4047e-04 - val_theta_ex_hat_loss: 4.4091e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0049 - a_or_hat_loss: 9.3309e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.4205e-04 - p_ex_hat_loss: 3.2788e-04 - q_ex_hat_loss: 7.9695e-04 - q_or_hat_loss: 6.8352e-04 - v_or_hat_loss: 5.8005e-06 - v_ex_hat_loss: 7.6906e-06 - load_v_hat_loss: 8.9370e-05 - prod_q_hat_loss: 2.4281e-04 - theta_or_hat_loss: 2.3892e-04 - theta_ex_hat_loss: 2.2215e-04 - val_loss: 0.0059 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.0388e-04 - val_p_ex_hat_loss: 3.6339e-04 - val_q_ex_hat_loss: 8.4004e-04 - val_q_or_hat_loss: 8.0660e-04 - val_v_or_hat_loss: 2.4595e-06 - val_v_ex_hat_loss: 4.3378e-06 - val_load_v_hat_loss: 7.8942e-05 - val_prod_q_hat_loss: 3.0517e-04 - val_theta_or_hat_loss: 2.3310e-04 - val_theta_ex_hat_loss: 3.2439e-04\n",
      "Epoch 149/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0047 - a_or_hat_loss: 9.2415e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.3401e-04 - p_ex_hat_loss: 3.0507e-04 - q_ex_hat_loss: 7.5891e-04 - q_or_hat_loss: 6.6138e-04 - v_or_hat_loss: 5.1110e-06 - v_ex_hat_loss: 7.0003e-06 - load_v_hat_loss: 7.4732e-05 - prod_q_hat_loss: 2.2673e-04 - theta_or_hat_loss: 2.1306e-04 - theta_ex_hat_loss: 2.0394e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 6.3502e-04 - val_p_ex_hat_loss: 5.2451e-04 - val_q_ex_hat_loss: 9.3257e-04 - val_q_or_hat_loss: 7.2764e-04 - val_v_or_hat_loss: 8.3671e-06 - val_v_ex_hat_loss: 8.7895e-06 - val_load_v_hat_loss: 8.5896e-05 - val_prod_q_hat_loss: 2.3660e-04 - val_theta_or_hat_loss: 2.1967e-04 - val_theta_ex_hat_loss: 2.3299e-04\n",
      "Epoch 150/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0047 - a_or_hat_loss: 9.1026e-04 - a_ex_hat_loss: 9.7717e-04 - p_or_hat_loss: 3.4056e-04 - p_ex_hat_loss: 3.1695e-04 - q_ex_hat_loss: 7.5517e-04 - q_or_hat_loss: 6.5480e-04 - v_or_hat_loss: 5.5549e-06 - v_ex_hat_loss: 7.3238e-06 - load_v_hat_loss: 7.6673e-05 - prod_q_hat_loss: 2.2422e-04 - theta_or_hat_loss: 2.0271e-04 - theta_ex_hat_loss: 1.9365e-04 - val_loss: 0.0059 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.0523e-04 - val_p_ex_hat_loss: 4.5692e-04 - val_q_ex_hat_loss: 9.7268e-04 - val_q_or_hat_loss: 8.3119e-04 - val_v_or_hat_loss: 1.0184e-05 - val_v_ex_hat_loss: 1.0782e-05 - val_load_v_hat_loss: 9.7337e-05 - val_prod_q_hat_loss: 2.9998e-04 - val_theta_or_hat_loss: 2.2896e-04 - val_theta_ex_hat_loss: 2.2390e-04\n",
      "Epoch 151/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0047 - a_or_hat_loss: 9.0520e-04 - a_ex_hat_loss: 9.9127e-04 - p_or_hat_loss: 3.3267e-04 - p_ex_hat_loss: 3.0991e-04 - q_ex_hat_loss: 7.6012e-04 - q_or_hat_loss: 6.6284e-04 - v_or_hat_loss: 5.3717e-06 - v_ex_hat_loss: 7.2085e-06 - load_v_hat_loss: 7.8197e-05 - prod_q_hat_loss: 2.3098e-04 - theta_or_hat_loss: 2.0862e-04 - theta_ex_hat_loss: 1.9461e-04 - val_loss: 0.0054 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.6476e-04 - val_p_ex_hat_loss: 3.1987e-04 - val_q_ex_hat_loss: 7.8657e-04 - val_q_or_hat_loss: 7.5475e-04 - val_v_or_hat_loss: 2.8595e-06 - val_v_ex_hat_loss: 4.5429e-06 - val_load_v_hat_loss: 7.9336e-05 - val_prod_q_hat_loss: 2.7493e-04 - val_theta_or_hat_loss: 2.4788e-04 - val_theta_ex_hat_loss: 2.2344e-04\n",
      "Epoch 152/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0047 - a_or_hat_loss: 9.0679e-04 - a_ex_hat_loss: 9.8683e-04 - p_or_hat_loss: 3.3577e-04 - p_ex_hat_loss: 3.2458e-04 - q_ex_hat_loss: 7.4319e-04 - q_or_hat_loss: 6.5875e-04 - v_or_hat_loss: 5.4911e-06 - v_ex_hat_loss: 7.2862e-06 - load_v_hat_loss: 7.9508e-05 - prod_q_hat_loss: 2.3149e-04 - theta_or_hat_loss: 2.0596e-04 - theta_ex_hat_loss: 1.9817e-04 - val_loss: 0.0061 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.8107e-04 - val_p_ex_hat_loss: 4.3280e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 8.0224e-04 - val_v_or_hat_loss: 2.8555e-06 - val_v_ex_hat_loss: 4.5887e-06 - val_load_v_hat_loss: 8.3238e-05 - val_prod_q_hat_loss: 2.5006e-04 - val_theta_or_hat_loss: 2.5189e-04 - val_theta_ex_hat_loss: 2.3756e-04\n",
      "Epoch 153/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0047 - a_or_hat_loss: 9.1700e-04 - a_ex_hat_loss: 9.9266e-04 - p_or_hat_loss: 3.4993e-04 - p_ex_hat_loss: 3.3132e-04 - q_ex_hat_loss: 7.6677e-04 - q_or_hat_loss: 6.5324e-04 - v_or_hat_loss: 6.3571e-06 - v_ex_hat_loss: 8.2865e-06 - load_v_hat_loss: 7.5746e-05 - prod_q_hat_loss: 2.2713e-04 - theta_or_hat_loss: 2.0549e-04 - theta_ex_hat_loss: 1.9527e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.4203e-04 - val_p_ex_hat_loss: 3.6106e-04 - val_q_ex_hat_loss: 8.0555e-04 - val_q_or_hat_loss: 7.7175e-04 - val_v_or_hat_loss: 3.3731e-06 - val_v_ex_hat_loss: 4.6605e-06 - val_load_v_hat_loss: 7.7416e-05 - val_prod_q_hat_loss: 2.4423e-04 - val_theta_or_hat_loss: 2.2247e-04 - val_theta_ex_hat_loss: 2.0343e-04\n",
      "Epoch 154/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0046 - a_or_hat_loss: 8.9872e-04 - a_ex_hat_loss: 9.8104e-04 - p_or_hat_loss: 3.2358e-04 - p_ex_hat_loss: 3.1039e-04 - q_ex_hat_loss: 7.3991e-04 - q_or_hat_loss: 6.4823e-04 - v_or_hat_loss: 4.7650e-06 - v_ex_hat_loss: 6.5667e-06 - load_v_hat_loss: 7.6773e-05 - prod_q_hat_loss: 2.2645e-04 - theta_or_hat_loss: 2.0487e-04 - theta_ex_hat_loss: 1.8979e-04 - val_loss: 0.0054 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.8861e-04 - val_p_ex_hat_loss: 4.1277e-04 - val_q_ex_hat_loss: 8.5926e-04 - val_q_or_hat_loss: 7.3005e-04 - val_v_or_hat_loss: 3.3314e-06 - val_v_ex_hat_loss: 4.9850e-06 - val_load_v_hat_loss: 7.8309e-05 - val_prod_q_hat_loss: 2.2266e-04 - val_theta_or_hat_loss: 2.0326e-04 - val_theta_ex_hat_loss: 2.0161e-0404 - p_or_hat_loss: 3.0848e-04 - p_ex_hat_loss: 3.0622e-04 - q_ex_hat_loss: 7.3082e-04 - q_or_hat_loss: 6.3683e-04 - v_or_hat_loss: 3.8531e-06 - v_ex_hat_loss: 5.6728e-06 - load_v_hat_loss: 7.3199e-05 - prod_q_hat_loss: 2.3134e-04 - theta_or_hat_loss: 2.0501e-04 - theta_ex_hat_los - ETA: 5s - loss: 0.0046 - a_or_hat_loss: 8.8613e-04 - a_ex_hat_loss: 9.7835e-04 - p_or_hat_loss: 3.1320e-04 - p_ex_hat_loss: 3.0764e-04 - q_ex_hat_loss: 7.3466e-04 - q_or_hat_loss: 6.4023e-04 - v_or_hat_loss: 4.0992e-06 - v_ex_hat_loss: 5.9042e-06 - load_v_hat_loss: \n",
      "Epoch 155/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0047 - a_or_hat_loss: 9.0105e-04 - a_ex_hat_loss: 9.8432e-04 - p_or_hat_loss: 3.3485e-04 - p_ex_hat_loss: 3.1843e-04 - q_ex_hat_loss: 7.4986e-04 - q_or_hat_loss: 6.5106e-04 - v_or_hat_loss: 5.5078e-06 - v_ex_hat_loss: 7.1818e-06 - load_v_hat_loss: 7.6175e-05 - prod_q_hat_loss: 2.3254e-04 - theta_or_hat_loss: 2.1155e-04 - theta_ex_hat_loss: 1.9784e-04 - val_loss: 0.0056 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.1355e-04 - val_p_ex_hat_loss: 3.8189e-04 - val_q_ex_hat_loss: 8.5273e-04 - val_q_or_hat_loss: 7.7676e-04 - val_v_or_hat_loss: 3.2599e-06 - val_v_ex_hat_loss: 5.4613e-06 - val_load_v_hat_loss: 8.3153e-05 - val_prod_q_hat_loss: 2.7362e-04 - val_theta_or_hat_loss: 2.0274e-04 - val_theta_ex_hat_loss: 2.1911e-04\n",
      "Epoch 156/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0046 - a_or_hat_loss: 8.8537e-04 - a_ex_hat_loss: 9.5698e-04 - p_or_hat_loss: 3.2141e-04 - p_ex_hat_loss: 3.0341e-04 - q_ex_hat_loss: 7.5104e-04 - q_or_hat_loss: 6.5061e-04 - v_or_hat_loss: 4.7542e-06 - v_ex_hat_loss: 6.5779e-06 - load_v_hat_loss: 7.6955e-05 - prod_q_hat_loss: 2.2988e-04 - theta_or_hat_loss: 1.9932e-04 - theta_ex_hat_loss: 1.9177e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.5662e-04 - val_p_ex_hat_loss: 3.3487e-04 - val_q_ex_hat_loss: 8.4716e-04 - val_q_or_hat_loss: 7.6777e-04 - val_v_or_hat_loss: 2.6122e-06 - val_v_ex_hat_loss: 4.4348e-06 - val_load_v_hat_loss: 1.0023e-04 - val_prod_q_hat_loss: 2.6450e-04 - val_theta_or_hat_loss: 2.2223e-04 - val_theta_ex_hat_loss: 2.4269e-04\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0045 - a_or_hat_loss: 8.8253e-04 - a_ex_hat_loss: 9.5917e-04 - p_or_hat_loss: 3.1365e-04 - p_ex_hat_loss: 2.9758e-04 - q_ex_hat_loss: 7.2968e-04 - q_or_hat_loss: 6.4007e-04 - v_or_hat_loss: 4.9447e-06 - v_ex_hat_loss: 6.6492e-06 - load_v_hat_loss: 7.5794e-05 - prod_q_hat_loss: 2.1391e-04 - theta_or_hat_loss: 1.9443e-04 - theta_ex_hat_loss: 1.8573e-04 - val_loss: 0.0064 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.9614e-04 - val_p_ex_hat_loss: 5.4464e-04 - val_q_ex_hat_loss: 9.5485e-04 - val_q_or_hat_loss: 9.8712e-04 - val_v_or_hat_loss: 3.2534e-06 - val_v_ex_hat_loss: 5.6763e-06 - val_load_v_hat_loss: 9.7198e-05 - val_prod_q_hat_loss: 2.6335e-04 - val_theta_or_hat_loss: 2.7498e-04 - val_theta_ex_hat_loss: 2.8485e-04\n",
      "Epoch 158/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0047 - a_or_hat_loss: 9.0390e-04 - a_ex_hat_loss: 9.8509e-04 - p_or_hat_loss: 3.4123e-04 - p_ex_hat_loss: 3.2883e-04 - q_ex_hat_loss: 7.4450e-04 - q_or_hat_loss: 6.4397e-04 - v_or_hat_loss: 5.7030e-06 - v_ex_hat_loss: 7.5276e-06 - load_v_hat_loss: 7.8352e-05 - prod_q_hat_loss: 2.2042e-04 - theta_or_hat_loss: 2.0738e-04 - theta_ex_hat_loss: 1.9626e-04 - val_loss: 0.0057 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.0306e-04 - val_p_ex_hat_loss: 3.8465e-04 - val_q_ex_hat_loss: 9.6700e-04 - val_q_or_hat_loss: 7.4865e-04 - val_v_or_hat_loss: 5.0183e-06 - val_v_ex_hat_loss: 8.2048e-06 - val_load_v_hat_loss: 1.1872e-04 - val_prod_q_hat_loss: 2.7253e-04 - val_theta_or_hat_loss: 2.4104e-04 - val_theta_ex_hat_loss: 2.1315e-04\n",
      "Epoch 159/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0045 - a_or_hat_loss: 8.8147e-04 - a_ex_hat_loss: 9.5644e-04 - p_or_hat_loss: 3.1392e-04 - p_ex_hat_loss: 2.9402e-04 - q_ex_hat_loss: 7.1387e-04 - q_or_hat_loss: 6.3538e-04 - v_or_hat_loss: 4.9898e-06 - v_ex_hat_loss: 6.7619e-06 - load_v_hat_loss: 7.2987e-05 - prod_q_hat_loss: 2.2166e-04 - theta_or_hat_loss: 1.9313e-04 - theta_ex_hat_loss: 1.8242e-04 - val_loss: 0.0059 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.0220e-04 - val_p_ex_hat_loss: 3.9117e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 8.6665e-04 - val_v_or_hat_loss: 1.4521e-05 - val_v_ex_hat_loss: 1.4722e-05 - val_load_v_hat_loss: 8.4524e-05 - val_prod_q_hat_loss: 2.9449e-04 - val_theta_or_hat_loss: 2.0947e-04 - val_theta_ex_hat_loss: 2.2788e-04\n",
      "Epoch 160/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0045 - a_or_hat_loss: 8.8389e-04 - a_ex_hat_loss: 9.5158e-04 - p_or_hat_loss: 3.2503e-04 - p_ex_hat_loss: 3.0550e-04 - q_ex_hat_loss: 7.3380e-04 - q_or_hat_loss: 6.3604e-04 - v_or_hat_loss: 4.9292e-06 - v_ex_hat_loss: 6.6081e-06 - load_v_hat_loss: 7.3820e-05 - prod_q_hat_loss: 2.1609e-04 - theta_or_hat_loss: 1.9118e-04 - theta_ex_hat_loss: 1.8728e-04 - val_loss: 0.0075 - val_a_or_hat_loss: 0.0016 - val_a_ex_hat_loss: 0.0017 - val_p_or_hat_loss: 6.8025e-04 - val_p_ex_hat_loss: 5.8908e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 9.3599e-04 - val_v_or_hat_loss: 2.2567e-05 - val_v_ex_hat_loss: 2.4185e-05 - val_load_v_hat_loss: 8.9956e-05 - val_prod_q_hat_loss: 2.5031e-04 - val_theta_or_hat_loss: 2.4102e-04 - val_theta_ex_hat_loss: 2.1220e-04\n",
      "Epoch 161/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0046 - a_or_hat_loss: 8.8831e-04 - a_ex_hat_loss: 9.7585e-04 - p_or_hat_loss: 3.2829e-04 - p_ex_hat_loss: 3.1220e-04 - q_ex_hat_loss: 7.4852e-04 - q_or_hat_loss: 6.3804e-04 - v_or_hat_loss: 6.7319e-06 - v_ex_hat_loss: 8.4103e-06 - load_v_hat_loss: 7.2990e-05 - prod_q_hat_loss: 2.2141e-04 - theta_or_hat_loss: 1.9692e-04 - theta_ex_hat_loss: 1.8221e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.4400e-04 - val_p_ex_hat_loss: 3.2122e-04 - val_q_ex_hat_loss: 8.2937e-04 - val_q_or_hat_loss: 7.7486e-04 - val_v_or_hat_loss: 3.2639e-06 - val_v_ex_hat_loss: 4.7802e-06 - val_load_v_hat_loss: 7.4621e-05 - val_prod_q_hat_loss: 2.1232e-04 - val_theta_or_hat_loss: 2.1884e-04 - val_theta_ex_hat_loss: 2.1523e-04\n",
      "Epoch 162/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0050 - a_or_hat_loss: 9.3538e-04 - a_ex_hat_loss: 0.0010 - p_or_hat_loss: 3.7668e-04 - p_ex_hat_loss: 3.4721e-04 - q_ex_hat_loss: 8.3007e-04 - q_or_hat_loss: 6.9088e-04 - v_or_hat_loss: 8.9865e-06 - v_ex_hat_loss: 1.0691e-05 - load_v_hat_loss: 8.4605e-05 - prod_q_hat_loss: 2.3991e-04 - theta_or_hat_loss: 2.2195e-04 - theta_ex_hat_loss: 2.0828e-04 - val_loss: 0.0058 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.9419e-04 - val_p_ex_hat_loss: 3.5922e-04 - val_q_ex_hat_loss: 9.2746e-04 - val_q_or_hat_loss: 7.6859e-04 - val_v_or_hat_loss: 8.4441e-06 - val_v_ex_hat_loss: 9.8820e-06 - val_load_v_hat_loss: 1.1047e-04 - val_prod_q_hat_loss: 3.3806e-04 - val_theta_or_hat_loss: 2.2705e-04 - val_theta_ex_hat_loss: 2.3144e-04\n",
      "Epoch 163/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0044 - a_or_hat_loss: 8.5392e-04 - a_ex_hat_loss: 9.3147e-04 - p_or_hat_loss: 3.1608e-04 - p_ex_hat_loss: 3.0356e-04 - q_ex_hat_loss: 6.9394e-04 - q_or_hat_loss: 6.0876e-04 - v_or_hat_loss: 4.2478e-06 - v_ex_hat_loss: 5.8772e-06 - load_v_hat_loss: 7.4085e-05 - prod_q_hat_loss: 2.1709e-04 - theta_or_hat_loss: 1.8784e-04 - theta_ex_hat_loss: 1.8394e-04 - val_loss: 0.0059 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.5704e-04 - val_p_ex_hat_loss: 3.9832e-04 - val_q_ex_hat_loss: 8.5530e-04 - val_q_or_hat_loss: 7.1388e-04 - val_v_or_hat_loss: 2.6603e-06 - val_v_ex_hat_loss: 5.0930e-06 - val_load_v_hat_loss: 1.9112e-04 - val_prod_q_hat_loss: 3.0185e-04 - val_theta_or_hat_loss: 3.1882e-04 - val_theta_ex_hat_loss: 3.4458e-04\n",
      "Epoch 164/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0045 - a_or_hat_loss: 8.7757e-04 - a_ex_hat_loss: 9.5617e-04 - p_or_hat_loss: 3.2085e-04 - p_ex_hat_loss: 3.0000e-04 - q_ex_hat_loss: 7.2908e-04 - q_or_hat_loss: 6.2965e-04 - v_or_hat_loss: 5.2408e-06 - v_ex_hat_loss: 6.9110e-06 - load_v_hat_loss: 7.8866e-05 - prod_q_hat_loss: 2.2238e-04 - theta_or_hat_loss: 2.0438e-04 - theta_ex_hat_loss: 1.9240e-04 - val_loss: 0.0063 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.9532e-04 - val_p_ex_hat_loss: 3.7512e-04 - val_q_ex_hat_loss: 9.5885e-04 - val_q_or_hat_loss: 0.0011 - val_v_or_hat_loss: 4.7001e-06 - val_v_ex_hat_loss: 6.7982e-06 - val_load_v_hat_loss: 1.4196e-04 - val_prod_q_hat_loss: 3.2224e-04 - val_theta_or_hat_loss: 2.0425e-04 - val_theta_ex_hat_loss: 2.3585e-04\n",
      "Epoch 165/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0044 - a_or_hat_loss: 8.7231e-04 - a_ex_hat_loss: 9.5396e-04 - p_or_hat_loss: 3.1789e-04 - p_ex_hat_loss: 3.0042e-04 - q_ex_hat_loss: 7.0726e-04 - q_or_hat_loss: 6.2783e-04 - v_or_hat_loss: 5.5236e-06 - v_ex_hat_loss: 7.1039e-06 - load_v_hat_loss: 7.2606e-05 - prod_q_hat_loss: 2.1522e-04 - theta_or_hat_loss: 1.8261e-04 - theta_ex_hat_loss: 1.7899e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.7218e-04 - val_p_ex_hat_loss: 3.7535e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.7431e-04 - val_v_or_hat_loss: 8.5226e-06 - val_v_ex_hat_loss: 1.0314e-05 - val_load_v_hat_loss: 1.1785e-04 - val_prod_q_hat_loss: 2.4514e-04 - val_theta_or_hat_loss: 2.3505e-04 - val_theta_ex_hat_loss: 2.3719e-04\n",
      "Epoch 166/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0044 - a_or_hat_loss: 8.6052e-04 - a_ex_hat_loss: 9.4071e-04 - p_or_hat_loss: 3.0577e-04 - p_ex_hat_loss: 2.9108e-04 - q_ex_hat_loss: 6.9800e-04 - q_or_hat_loss: 6.1093e-04 - v_or_hat_loss: 4.2310e-06 - v_ex_hat_loss: 5.8977e-06 - load_v_hat_loss: 6.9243e-05 - prod_q_hat_loss: 2.0197e-04 - theta_or_hat_loss: 1.8878e-04 - theta_ex_hat_loss: 1.7789e-04 - val_loss: 0.0067 - val_a_or_hat_loss: 0.0013 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 5.4215e-04 - val_p_ex_hat_loss: 5.1107e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 9.7192e-04 - val_v_or_hat_loss: 2.0682e-05 - val_v_ex_hat_loss: 2.1773e-05 - val_load_v_hat_loss: 7.5513e-05 - val_prod_q_hat_loss: 3.2165e-04 - val_theta_or_hat_loss: 2.5062e-04 - val_theta_ex_hat_loss: 2.5023e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0046 - a_or_hat_loss: 8.6855e-04 - a_ex_hat_loss: 9.6023e-04 - p_or_hat_loss: 3.3016e-04 - p_ex_hat_loss: 3.1400e-04 - q_ex_hat_loss: 7.3731e-04 - q_or_hat_loss: 6.5005e-04 - v_or_hat_loss: 5.9644e-06 - v_ex_hat_loss: 7.6227e-06 - load_v_hat_loss: 7.4173e-05 - prod_q_hat_loss: 2.2244e-04 - theta_or_hat_loss: 1.9362e-04 - theta_ex_hat_loss: 1.9259e-04 - val_loss: 0.0061 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.8070e-04 - val_p_ex_hat_loss: 4.1515e-04 - val_q_ex_hat_loss: 0.0011 - val_q_or_hat_loss: 7.7489e-04 - val_v_or_hat_loss: 6.9593e-06 - val_v_ex_hat_loss: 9.4332e-06 - val_load_v_hat_loss: 9.3291e-05 - val_prod_q_hat_loss: 3.4175e-04 - val_theta_or_hat_loss: 2.4749e-04 - val_theta_ex_hat_loss: 2.5986e-04\n",
      "Epoch 168/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0043 - a_or_hat_loss: 8.4810e-04 - a_ex_hat_loss: 9.3434e-04 - p_or_hat_loss: 3.0506e-04 - p_ex_hat_loss: 2.8879e-04 - q_ex_hat_loss: 6.8832e-04 - q_or_hat_loss: 5.9570e-04 - v_or_hat_loss: 4.3491e-06 - v_ex_hat_loss: 5.9267e-06 - load_v_hat_loss: 6.8898e-05 - prod_q_hat_loss: 2.1967e-04 - theta_or_hat_loss: 1.8485e-04 - theta_ex_hat_loss: 1.7442e-04 - val_loss: 0.0056 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.0706e-04 - val_p_ex_hat_loss: 3.4100e-04 - val_q_ex_hat_loss: 9.1958e-04 - val_q_or_hat_loss: 6.6690e-04 - val_v_or_hat_loss: 3.1589e-06 - val_v_ex_hat_loss: 5.0643e-06 - val_load_v_hat_loss: 1.1847e-04 - val_prod_q_hat_loss: 2.3898e-04 - val_theta_or_hat_loss: 2.8271e-04 - val_theta_ex_hat_loss: 3.3181e-04\n",
      "Epoch 169/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0045 - a_or_hat_loss: 8.5972e-04 - a_ex_hat_loss: 9.4384e-04 - p_or_hat_loss: 3.1940e-04 - p_ex_hat_loss: 3.0073e-04 - q_ex_hat_loss: 7.2000e-04 - q_or_hat_loss: 6.2227e-04 - v_or_hat_loss: 5.5699e-06 - v_ex_hat_loss: 7.2189e-06 - load_v_hat_loss: 7.8495e-05 - prod_q_hat_loss: 2.2315e-04 - theta_or_hat_loss: 1.9459e-04 - theta_ex_hat_loss: 1.9608e-04 - val_loss: 0.0061 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.6400e-04 - val_p_ex_hat_loss: 4.4450e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 8.0488e-04 - val_v_or_hat_loss: 1.2405e-05 - val_v_ex_hat_loss: 1.5524e-05 - val_load_v_hat_loss: 1.3263e-04 - val_prod_q_hat_loss: 2.4301e-04 - val_theta_or_hat_loss: 2.1870e-04 - val_theta_ex_hat_loss: 2.1978e-04\n",
      "Epoch 170/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0042 - a_or_hat_loss: 8.3351e-04 - a_ex_hat_loss: 9.2302e-04 - p_or_hat_loss: 2.8808e-04 - p_ex_hat_loss: 2.7728e-04 - q_ex_hat_loss: 6.6684e-04 - q_or_hat_loss: 5.8212e-04 - v_or_hat_loss: 3.9658e-06 - v_ex_hat_loss: 5.6180e-06 - load_v_hat_loss: 8.7383e-05 - prod_q_hat_loss: 2.0436e-04 - theta_or_hat_loss: 1.7766e-04 - theta_ex_hat_loss: 1.7184e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0012 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.3532e-04 - val_p_ex_hat_loss: 3.7902e-04 - val_q_ex_hat_loss: 9.8317e-04 - val_q_or_hat_loss: 8.0102e-04 - val_v_or_hat_loss: 2.0575e-05 - val_v_ex_hat_loss: 2.2133e-05 - val_load_v_hat_loss: 8.3431e-05 - val_prod_q_hat_loss: 2.6000e-04 - val_theta_or_hat_loss: 2.7073e-04 - val_theta_ex_hat_loss: 2.2681e-04\n",
      "Epoch 171/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0044 - a_or_hat_loss: 8.5284e-04 - a_ex_hat_loss: 9.4030e-04 - p_or_hat_loss: 3.1165e-04 - p_ex_hat_loss: 2.9185e-04 - q_ex_hat_loss: 7.0194e-04 - q_or_hat_loss: 6.0731e-04 - v_or_hat_loss: 5.0189e-06 - v_ex_hat_loss: 6.6033e-06 - load_v_hat_loss: 7.4952e-05 - prod_q_hat_loss: 2.0843e-04 - theta_or_hat_loss: 1.8843e-04 - theta_ex_hat_loss: 1.7925e-04 - val_loss: 0.0057 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.7860e-04 - val_p_ex_hat_loss: 3.6517e-04 - val_q_ex_hat_loss: 9.6169e-04 - val_q_or_hat_loss: 7.9949e-04 - val_v_or_hat_loss: 2.1117e-06 - val_v_ex_hat_loss: 3.8857e-06 - val_load_v_hat_loss: 8.3807e-05 - val_prod_q_hat_loss: 2.5214e-04 - val_theta_or_hat_loss: 2.1135e-04 - val_theta_ex_hat_loss: 2.0228e-04\n",
      "Epoch 172/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0043 - a_or_hat_loss: 8.5069e-04 - a_ex_hat_loss: 9.2678e-04 - p_or_hat_loss: 3.0239e-04 - p_ex_hat_loss: 2.8086e-04 - q_ex_hat_loss: 6.9141e-04 - q_or_hat_loss: 6.1162e-04 - v_or_hat_loss: 4.7592e-06 - v_ex_hat_loss: 6.2681e-06 - load_v_hat_loss: 6.7815e-05 - prod_q_hat_loss: 2.1084e-04 - theta_or_hat_loss: 1.7814e-04 - theta_ex_hat_loss: 1.7514e-04 - val_loss: 0.0053 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.3285e-04 - val_p_ex_hat_loss: 3.3506e-04 - val_q_ex_hat_loss: 8.3488e-04 - val_q_or_hat_loss: 7.2204e-04 - val_v_or_hat_loss: 2.3372e-06 - val_v_ex_hat_loss: 4.0549e-06 - val_load_v_hat_loss: 9.4707e-05 - val_prod_q_hat_loss: 2.3942e-04 - val_theta_or_hat_loss: 2.0500e-04 - val_theta_ex_hat_loss: 1.9282e-04\n",
      "Epoch 173/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0043 - a_or_hat_loss: 8.3943e-04 - a_ex_hat_loss: 9.3752e-04 - p_or_hat_loss: 2.9546e-04 - p_ex_hat_loss: 2.7715e-04 - q_ex_hat_loss: 6.9399e-04 - q_or_hat_loss: 5.9612e-04 - v_or_hat_loss: 4.3872e-06 - v_ex_hat_loss: 6.0162e-06 - load_v_hat_loss: 7.0141e-05 - prod_q_hat_loss: 2.0373e-04 - theta_or_hat_loss: 1.7665e-04 - theta_ex_hat_loss: 1.7334e-04 - val_loss: 0.0056 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.1421e-04 - val_p_ex_hat_loss: 3.5127e-04 - val_q_ex_hat_loss: 8.5384e-04 - val_q_or_hat_loss: 7.5943e-04 - val_v_or_hat_loss: 3.3360e-06 - val_v_ex_hat_loss: 4.4167e-06 - val_load_v_hat_loss: 7.2326e-05 - val_prod_q_hat_loss: 2.2252e-04 - val_theta_or_hat_loss: 2.2564e-04 - val_theta_ex_hat_loss: 2.3167e-04\n",
      "Epoch 174/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0045 - a_or_hat_loss: 8.6938e-04 - a_ex_hat_loss: 9.5540e-04 - p_or_hat_loss: 3.2962e-04 - p_ex_hat_loss: 3.0182e-04 - q_ex_hat_loss: 7.3973e-04 - q_or_hat_loss: 6.2977e-04 - v_or_hat_loss: 7.6027e-06 - v_ex_hat_loss: 9.0809e-06 - load_v_hat_loss: 7.4456e-05 - prod_q_hat_loss: 2.1542e-04 - theta_or_hat_loss: 1.9426e-04 - theta_ex_hat_loss: 1.9298e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.6592e-04 - val_p_ex_hat_loss: 3.8134e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 8.0284e-04 - val_v_or_hat_loss: 3.0696e-06 - val_v_ex_hat_loss: 5.3868e-06 - val_load_v_hat_loss: 1.0737e-04 - val_prod_q_hat_loss: 3.5411e-04 - val_theta_or_hat_loss: 2.5241e-04 - val_theta_ex_hat_loss: 2.6498e-04\n",
      "Epoch 175/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0043 - a_or_hat_loss: 8.3330e-04 - a_ex_hat_loss: 9.1949e-04 - p_or_hat_loss: 2.9669e-04 - p_ex_hat_loss: 2.7949e-04 - q_ex_hat_loss: 6.9455e-04 - q_or_hat_loss: 5.9766e-04 - v_or_hat_loss: 4.2848e-06 - v_ex_hat_loss: 5.9552e-06 - load_v_hat_loss: 7.3961e-05 - prod_q_hat_loss: 2.1103e-04 - theta_or_hat_loss: 1.8042e-04 - theta_ex_hat_loss: 1.7451e-04 - val_loss: 0.0054 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.6019e-04 - val_p_ex_hat_loss: 3.3142e-04 - val_q_ex_hat_loss: 7.7131e-04 - val_q_or_hat_loss: 6.9322e-04 - val_v_or_hat_loss: 2.8111e-06 - val_v_ex_hat_loss: 4.9738e-06 - val_load_v_hat_loss: 9.2182e-05 - val_prod_q_hat_loss: 2.3925e-04 - val_theta_or_hat_loss: 3.4664e-04 - val_theta_ex_hat_loss: 2.5774e-04\n",
      "Epoch 176/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0042 - a_or_hat_loss: 8.2566e-04 - a_ex_hat_loss: 9.1396e-04 - p_or_hat_loss: 2.8637e-04 - p_ex_hat_loss: 2.7167e-04 - q_ex_hat_loss: 6.5922e-04 - q_or_hat_loss: 5.9841e-04 - v_or_hat_loss: 4.3279e-06 - v_ex_hat_loss: 5.8338e-06 - load_v_hat_loss: 6.9887e-05 - prod_q_hat_loss: 2.0709e-04 - theta_or_hat_loss: 1.7664e-04 - theta_ex_hat_loss: 1.6858e-04 - val_loss: 0.0051 - val_a_or_hat_loss: 9.8972e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.3291e-04 - val_p_ex_hat_loss: 3.2623e-04 - val_q_ex_hat_loss: 8.4297e-04 - val_q_or_hat_loss: 6.7186e-04 - val_v_or_hat_loss: 2.0611e-06 - val_v_ex_hat_loss: 3.8246e-06 - val_load_v_hat_loss: 9.8053e-05 - val_prod_q_hat_loss: 2.2433e-04 - val_theta_or_hat_loss: 2.2363e-04 - val_theta_ex_hat_loss: 2.2909e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0044 - a_or_hat_loss: 8.3771e-04 - a_ex_hat_loss: 9.4108e-04 - p_or_hat_loss: 3.0907e-04 - p_ex_hat_loss: 2.9697e-04 - q_ex_hat_loss: 7.0439e-04 - q_or_hat_loss: 6.1533e-04 - v_or_hat_loss: 4.5722e-06 - v_ex_hat_loss: 6.0223e-06 - load_v_hat_loss: 8.3341e-05 - prod_q_hat_loss: 2.1090e-04 - theta_or_hat_loss: 1.8844e-04 - theta_ex_hat_loss: 1.8099e-04 - val_loss: 0.0058 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.5429e-04 - val_p_ex_hat_loss: 3.3410e-04 - val_q_ex_hat_loss: 9.0294e-04 - val_q_or_hat_loss: 6.9226e-04 - val_v_or_hat_loss: 2.5521e-06 - val_v_ex_hat_loss: 5.0391e-06 - val_load_v_hat_loss: 1.2371e-04 - val_prod_q_hat_loss: 4.2429e-04 - val_theta_or_hat_loss: 3.2655e-04 - val_theta_ex_hat_loss: 3.4113e-04\n",
      "Epoch 178/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0042 - a_or_hat_loss: 8.2691e-04 - a_ex_hat_loss: 9.1302e-04 - p_or_hat_loss: 2.9240e-04 - p_ex_hat_loss: 2.8353e-04 - q_ex_hat_loss: 6.7574e-04 - q_or_hat_loss: 5.9145e-04 - v_or_hat_loss: 4.9332e-06 - v_ex_hat_loss: 6.6366e-06 - load_v_hat_loss: 6.8493e-05 - prod_q_hat_loss: 2.0358e-04 - theta_or_hat_loss: 1.8257e-04 - theta_ex_hat_loss: 1.7940e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.8762e-04 - val_p_ex_hat_loss: 3.8617e-04 - val_q_ex_hat_loss: 0.0010 - val_q_or_hat_loss: 7.0720e-04 - val_v_or_hat_loss: 4.5112e-06 - val_v_ex_hat_loss: 6.0506e-06 - val_load_v_hat_loss: 8.3550e-05 - val_prod_q_hat_loss: 2.9036e-04 - val_theta_or_hat_loss: 1.9159e-04 - val_theta_ex_hat_loss: 2.0936e-04\n",
      "Epoch 179/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0042 - a_or_hat_loss: 8.2694e-04 - a_ex_hat_loss: 9.1966e-04 - p_or_hat_loss: 2.8661e-04 - p_ex_hat_loss: 2.6576e-04 - q_ex_hat_loss: 6.7937e-04 - q_or_hat_loss: 5.8914e-04 - v_or_hat_loss: 4.4603e-06 - v_ex_hat_loss: 6.0253e-06 - load_v_hat_loss: 6.8118e-05 - prod_q_hat_loss: 2.0593e-04 - theta_or_hat_loss: 1.6870e-04 - theta_ex_hat_loss: 1.7248e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.9634e-04 - val_p_ex_hat_loss: 4.5938e-04 - val_q_ex_hat_loss: 8.6669e-04 - val_q_or_hat_loss: 9.6061e-04 - val_v_or_hat_loss: 4.8219e-06 - val_v_ex_hat_loss: 5.5093e-06 - val_load_v_hat_loss: 1.2385e-04 - val_prod_q_hat_loss: 2.5855e-04 - val_theta_or_hat_loss: 2.0729e-04 - val_theta_ex_hat_loss: 2.7665e-04\n",
      "Epoch 180/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0042 - a_or_hat_loss: 8.1961e-04 - a_ex_hat_loss: 9.0649e-04 - p_or_hat_loss: 2.9942e-04 - p_ex_hat_loss: 2.8035e-04 - q_ex_hat_loss: 6.8187e-04 - q_or_hat_loss: 5.8783e-04 - v_or_hat_loss: 4.6053e-06 - v_ex_hat_loss: 6.1474e-06 - load_v_hat_loss: 7.1166e-05 - prod_q_hat_loss: 2.0322e-04 - theta_or_hat_loss: 1.7940e-04 - theta_ex_hat_loss: 1.7911e-04 - val_loss: 0.0069 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 5.8923e-04 - val_p_ex_hat_loss: 5.2133e-04 - val_q_ex_hat_loss: 0.0015 - val_q_or_hat_loss: 9.0521e-04 - val_v_or_hat_loss: 6.9075e-06 - val_v_ex_hat_loss: 8.4722e-06 - val_load_v_hat_loss: 9.9208e-05 - val_prod_q_hat_loss: 2.7321e-04 - val_theta_or_hat_loss: 2.9298e-04 - val_theta_ex_hat_loss: 3.0229e-04\n",
      "Epoch 181/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0043 - a_or_hat_loss: 8.3877e-04 - a_ex_hat_loss: 9.2192e-04 - p_or_hat_loss: 3.0838e-04 - p_ex_hat_loss: 2.8776e-04 - q_ex_hat_loss: 7.2615e-04 - q_or_hat_loss: 5.9009e-04 - v_or_hat_loss: 5.5548e-06 - v_ex_hat_loss: 7.0787e-06 - load_v_hat_loss: 7.2699e-05 - prod_q_hat_loss: 2.1248e-04 - theta_or_hat_loss: 1.7943e-04 - theta_ex_hat_loss: 1.8097e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.0247e-04 - val_p_ex_hat_loss: 3.6288e-04 - val_q_ex_hat_loss: 9.1715e-04 - val_q_or_hat_loss: 6.8512e-04 - val_v_or_hat_loss: 6.3097e-06 - val_v_ex_hat_loss: 6.3379e-06 - val_load_v_hat_loss: 8.7271e-05 - val_prod_q_hat_loss: 2.4485e-04 - val_theta_or_hat_loss: 2.4594e-04 - val_theta_ex_hat_loss: 2.4436e-04\n",
      "Epoch 182/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0042 - a_or_hat_loss: 8.1989e-04 - a_ex_hat_loss: 9.1184e-04 - p_or_hat_loss: 3.0108e-04 - p_ex_hat_loss: 2.8570e-04 - q_ex_hat_loss: 6.8227e-04 - q_or_hat_loss: 5.8759e-04 - v_or_hat_loss: 4.5898e-06 - v_ex_hat_loss: 6.0288e-06 - load_v_hat_loss: 6.4193e-05 - prod_q_hat_loss: 1.9488e-04 - theta_or_hat_loss: 1.7429e-04 - theta_ex_hat_loss: 1.7442e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.6527e-04 - val_p_ex_hat_loss: 3.7334e-04 - val_q_ex_hat_loss: 8.6404e-04 - val_q_or_hat_loss: 7.6742e-04 - val_v_or_hat_loss: 1.3252e-05 - val_v_ex_hat_loss: 1.4413e-05 - val_load_v_hat_loss: 7.1056e-05 - val_prod_q_hat_loss: 2.9735e-04 - val_theta_or_hat_loss: 1.9437e-04 - val_theta_ex_hat_loss: 1.9679e-04\n",
      "Epoch 183/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0041 - a_or_hat_loss: 8.1748e-04 - a_ex_hat_loss: 9.0725e-04 - p_or_hat_loss: 2.8678e-04 - p_ex_hat_loss: 2.7402e-04 - q_ex_hat_loss: 6.6554e-04 - q_or_hat_loss: 5.8237e-04 - v_or_hat_loss: 4.6225e-06 - v_ex_hat_loss: 6.1586e-06 - load_v_hat_loss: 6.2751e-05 - prod_q_hat_loss: 1.9728e-04 - theta_or_hat_loss: 1.6637e-04 - theta_ex_hat_loss: 1.7148e-04 - val_loss: 0.0053 - val_a_or_hat_loss: 0.0010 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 4.0480e-04 - val_p_ex_hat_loss: 4.0081e-04 - val_q_ex_hat_loss: 8.7844e-04 - val_q_or_hat_loss: 7.1744e-04 - val_v_or_hat_loss: 5.3644e-06 - val_v_ex_hat_loss: 6.6928e-06 - val_load_v_hat_loss: 9.4815e-05 - val_prod_q_hat_loss: 2.6706e-04 - val_theta_or_hat_loss: 2.0184e-04 - val_theta_ex_hat_loss: 1.9644e-04\n",
      "Epoch 184/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0041 - a_or_hat_loss: 8.0894e-04 - a_ex_hat_loss: 8.9955e-04 - p_or_hat_loss: 2.9124e-04 - p_ex_hat_loss: 2.7194e-04 - q_ex_hat_loss: 6.5902e-04 - q_or_hat_loss: 5.6974e-04 - v_or_hat_loss: 4.7100e-06 - v_ex_hat_loss: 6.2473e-06 - load_v_hat_loss: 6.5509e-05 - prod_q_hat_loss: 1.9825e-04 - theta_or_hat_loss: 1.6556e-04 - theta_ex_hat_loss: 1.6900e-04 - val_loss: 0.0056 - val_a_or_hat_loss: 0.0010 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.3941e-04 - val_p_ex_hat_loss: 3.0531e-04 - val_q_ex_hat_loss: 7.4939e-04 - val_q_or_hat_loss: 7.3275e-04 - val_v_or_hat_loss: 1.8215e-06 - val_v_ex_hat_loss: 3.5200e-06 - val_load_v_hat_loss: 1.0523e-04 - val_prod_q_hat_loss: 7.8493e-04 - val_theta_or_hat_loss: 2.1052e-04 - val_theta_ex_hat_loss: 2.4972e-04\n",
      "Epoch 185/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0041 - a_or_hat_loss: 7.9720e-04 - a_ex_hat_loss: 8.9597e-04 - p_or_hat_loss: 2.8024e-04 - p_ex_hat_loss: 2.6722e-04 - q_ex_hat_loss: 6.5295e-04 - q_or_hat_loss: 5.7582e-04 - v_or_hat_loss: 3.9724e-06 - v_ex_hat_loss: 5.5207e-06 - load_v_hat_loss: 7.5030e-05 - prod_q_hat_loss: 2.1902e-04 - theta_or_hat_loss: 1.7383e-04 - theta_ex_hat_loss: 1.7247e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 4.4441e-04 - val_p_ex_hat_loss: 4.0525e-04 - val_q_ex_hat_loss: 8.3232e-04 - val_q_or_hat_loss: 7.2956e-04 - val_v_or_hat_loss: 1.3569e-05 - val_v_ex_hat_loss: 1.5255e-05 - val_load_v_hat_loss: 7.8847e-05 - val_prod_q_hat_loss: 2.6392e-04 - val_theta_or_hat_loss: 1.9731e-04 - val_theta_ex_hat_loss: 1.9011e-04\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0040 - a_or_hat_loss: 7.8539e-04 - a_ex_hat_loss: 8.9041e-04 - p_or_hat_loss: 2.7677e-04 - p_ex_hat_loss: 2.6363e-04 - q_ex_hat_loss: 6.5075e-04 - q_or_hat_loss: 5.6152e-04 - v_or_hat_loss: 3.9117e-06 - v_ex_hat_loss: 5.3890e-06 - load_v_hat_loss: 6.3084e-05 - prod_q_hat_loss: 1.9569e-04 - theta_or_hat_loss: 1.6362e-04 - theta_ex_hat_loss: 1.6740e-04 - val_loss: 0.0063 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0014 - val_p_or_hat_loss: 4.6322e-04 - val_p_ex_hat_loss: 4.4749e-04 - val_q_ex_hat_loss: 0.0012 - val_q_or_hat_loss: 9.4534e-04 - val_v_or_hat_loss: 7.0999e-06 - val_v_ex_hat_loss: 8.4003e-06 - val_load_v_hat_loss: 5.9413e-05 - val_prod_q_hat_loss: 2.2901e-04 - val_theta_or_hat_loss: 1.9877e-04 - val_theta_ex_hat_loss: 1.9801e-04\n",
      "Epoch 187/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0041 - a_or_hat_loss: 7.9321e-04 - a_ex_hat_loss: 9.0039e-04 - p_or_hat_loss: 2.9115e-04 - p_ex_hat_loss: 2.7722e-04 - q_ex_hat_loss: 6.6286e-04 - q_or_hat_loss: 5.7541e-04 - v_or_hat_loss: 4.8431e-06 - v_ex_hat_loss: 6.3893e-06 - load_v_hat_loss: 6.8524e-05 - prod_q_hat_loss: 1.9944e-04 - theta_or_hat_loss: 1.6340e-04 - theta_ex_hat_loss: 1.6883e-04 - val_loss: 0.0052 - val_a_or_hat_loss: 9.8822e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.5138e-04 - val_p_ex_hat_loss: 3.1625e-04 - val_q_ex_hat_loss: 8.0872e-04 - val_q_or_hat_loss: 7.3172e-04 - val_v_or_hat_loss: 2.0351e-06 - val_v_ex_hat_loss: 3.2975e-06 - val_load_v_hat_loss: 9.8156e-05 - val_prod_q_hat_loss: 2.1048e-04 - val_theta_or_hat_loss: 1.7793e-04 - val_theta_ex_hat_loss: 2.9879e-04\n",
      "Epoch 188/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0043 - a_or_hat_loss: 8.0941e-04 - a_ex_hat_loss: 9.1855e-04 - p_or_hat_loss: 2.9776e-04 - p_ex_hat_loss: 2.8368e-04 - q_ex_hat_loss: 7.0789e-04 - q_or_hat_loss: 5.9805e-04 - v_or_hat_loss: 5.5398e-06 - v_ex_hat_loss: 7.0497e-06 - load_v_hat_loss: 7.2035e-05 - prod_q_hat_loss: 2.0591e-04 - theta_or_hat_loss: 1.7861e-04 - theta_ex_hat_loss: 1.8767e-04 - val_loss: 0.0048 - val_a_or_hat_loss: 9.9650e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.1591e-04 - val_p_ex_hat_loss: 3.0631e-04 - val_q_ex_hat_loss: 7.2926e-04 - val_q_or_hat_loss: 6.2202e-04 - val_v_or_hat_loss: 2.2514e-06 - val_v_ex_hat_loss: 3.8153e-06 - val_load_v_hat_loss: 6.3951e-05 - val_prod_q_hat_loss: 2.0251e-04 - val_theta_or_hat_loss: 1.9569e-04 - val_theta_ex_hat_loss: 1.8631e-04\n",
      "Epoch 189/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0040 - a_or_hat_loss: 7.8836e-04 - a_ex_hat_loss: 8.9685e-04 - p_or_hat_loss: 2.8081e-04 - p_ex_hat_loss: 2.7255e-04 - q_ex_hat_loss: 6.4574e-04 - q_or_hat_loss: 5.5819e-04 - v_or_hat_loss: 4.2774e-06 - v_ex_hat_loss: 5.7414e-06 - load_v_hat_loss: 5.9811e-05 - prod_q_hat_loss: 1.8850e-04 - theta_or_hat_loss: 1.6330e-04 - theta_ex_hat_loss: 1.6296e-04 - val_loss: 0.0051 - val_a_or_hat_loss: 9.6270e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 2.9965e-04 - val_p_ex_hat_loss: 3.3096e-04 - val_q_ex_hat_loss: 6.9197e-04 - val_q_or_hat_loss: 6.5212e-04 - val_v_or_hat_loss: 2.8451e-06 - val_v_ex_hat_loss: 4.5295e-06 - val_load_v_hat_loss: 5.9770e-05 - val_prod_q_hat_loss: 3.2060e-04 - val_theta_or_hat_loss: 3.2975e-04 - val_theta_ex_hat_loss: 2.6292e-04\n",
      "Epoch 190/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0040 - a_or_hat_loss: 7.7752e-04 - a_ex_hat_loss: 8.8636e-04 - p_or_hat_loss: 2.6177e-04 - p_ex_hat_loss: 2.5552e-04 - q_ex_hat_loss: 6.2517e-04 - q_or_hat_loss: 5.6220e-04 - v_or_hat_loss: 3.8180e-06 - v_ex_hat_loss: 5.2553e-06 - load_v_hat_loss: 6.4889e-05 - prod_q_hat_loss: 2.0028e-04 - theta_or_hat_loss: 1.6743e-04 - theta_ex_hat_loss: 1.6750e-04 - val_loss: 0.0055 - val_a_or_hat_loss: 0.0011 - val_a_ex_hat_loss: 0.0013 - val_p_or_hat_loss: 3.5410e-04 - val_p_ex_hat_loss: 3.6389e-04 - val_q_ex_hat_loss: 9.8140e-04 - val_q_or_hat_loss: 7.7401e-04 - val_v_or_hat_loss: 6.1172e-06 - val_v_ex_hat_loss: 9.0810e-06 - val_load_v_hat_loss: 7.0049e-05 - val_prod_q_hat_loss: 2.5043e-04 - val_theta_or_hat_loss: 1.8982e-04 - val_theta_ex_hat_loss: 1.9766e-04\n",
      "Epoch 191/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0040 - a_or_hat_loss: 7.8667e-04 - a_ex_hat_loss: 8.9313e-04 - p_or_hat_loss: 2.7423e-04 - p_ex_hat_loss: 2.6156e-04 - q_ex_hat_loss: 6.4345e-04 - q_or_hat_loss: 5.6076e-04 - v_or_hat_loss: 4.2350e-06 - v_ex_hat_loss: 5.7542e-06 - load_v_hat_loss: 6.6498e-05 - prod_q_hat_loss: 1.9532e-04 - theta_or_hat_loss: 1.6482e-04 - theta_ex_hat_loss: 1.7208e-04 - val_loss: 0.0052 - val_a_or_hat_loss: 9.6427e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.9180e-04 - val_p_ex_hat_loss: 4.6875e-04 - val_q_ex_hat_loss: 6.8151e-04 - val_q_or_hat_loss: 6.8468e-04 - val_v_or_hat_loss: 2.3778e-06 - val_v_ex_hat_loss: 3.3898e-06 - val_load_v_hat_loss: 8.1087e-05 - val_prod_q_hat_loss: 2.4825e-04 - val_theta_or_hat_loss: 1.6873e-04 - val_theta_ex_hat_loss: 1.7490e-04\n",
      "Epoch 192/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0040 - a_or_hat_loss: 7.8271e-04 - a_ex_hat_loss: 8.9452e-04 - p_or_hat_loss: 2.6422e-04 - p_ex_hat_loss: 2.5357e-04 - q_ex_hat_loss: 6.3868e-04 - q_or_hat_loss: 5.6032e-04 - v_or_hat_loss: 3.8809e-06 - v_ex_hat_loss: 5.3609e-06 - load_v_hat_loss: 6.2091e-05 - prod_q_hat_loss: 1.9164e-04 - theta_or_hat_loss: 1.5627e-04 - theta_ex_hat_loss: 1.6451e-04 - val_loss: 0.0050 - val_a_or_hat_loss: 9.6111e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.8032e-04 - val_p_ex_hat_loss: 2.9741e-04 - val_q_ex_hat_loss: 8.0928e-04 - val_q_or_hat_loss: 6.2402e-04 - val_v_or_hat_loss: 6.5244e-06 - val_v_ex_hat_loss: 9.1333e-06 - val_load_v_hat_loss: 9.1772e-05 - val_prod_q_hat_loss: 2.2876e-04 - val_theta_or_hat_loss: 2.3678e-04 - val_theta_ex_hat_loss: 2.7241e-04\n",
      "Epoch 193/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0040 - a_or_hat_loss: 7.7910e-04 - a_ex_hat_loss: 8.8497e-04 - p_or_hat_loss: 2.7518e-04 - p_ex_hat_loss: 2.6159e-04 - q_ex_hat_loss: 6.3655e-04 - q_or_hat_loss: 5.4803e-04 - v_or_hat_loss: 4.3143e-06 - v_ex_hat_loss: 5.8722e-06 - load_v_hat_loss: 5.9786e-05 - prod_q_hat_loss: 1.8853e-04 - theta_or_hat_loss: 1.5808e-04 - theta_ex_hat_loss: 1.7282e-04 - val_loss: 0.0046 - val_a_or_hat_loss: 9.6586e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 2.8187e-04 - val_p_ex_hat_loss: 2.5101e-04 - val_q_ex_hat_loss: 7.1336e-04 - val_q_or_hat_loss: 6.1747e-04 - val_v_or_hat_loss: 2.4384e-06 - val_v_ex_hat_loss: 4.2699e-06 - val_load_v_hat_loss: 7.4477e-05 - val_prod_q_hat_loss: 2.0217e-04 - val_theta_or_hat_loss: 1.6893e-04 - val_theta_ex_hat_loss: 1.8352e-04\n",
      "Epoch 194/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0039 - a_or_hat_loss: 7.6873e-04 - a_ex_hat_loss: 8.8141e-04 - p_or_hat_loss: 2.7205e-04 - p_ex_hat_loss: 2.6301e-04 - q_ex_hat_loss: 6.2345e-04 - q_or_hat_loss: 5.5524e-04 - v_or_hat_loss: 4.3681e-06 - v_ex_hat_loss: 5.7941e-06 - load_v_hat_loss: 6.0432e-05 - prod_q_hat_loss: 1.8581e-04 - theta_or_hat_loss: 1.5126e-04 - theta_ex_hat_loss: 1.5881e-04 - val_loss: 0.0048 - val_a_or_hat_loss: 9.3198e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.3717e-04 - val_p_ex_hat_loss: 3.2133e-04 - val_q_ex_hat_loss: 6.8978e-04 - val_q_or_hat_loss: 6.3435e-04 - val_v_or_hat_loss: 1.7827e-06 - val_v_ex_hat_loss: 3.2242e-06 - val_load_v_hat_loss: 8.9534e-05 - val_prod_q_hat_loss: 2.4276e-04 - val_theta_or_hat_loss: 1.6841e-04 - val_theta_ex_hat_loss: 1.8390e-04\n",
      "Epoch 195/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0039 - a_or_hat_loss: 7.6607e-04 - a_ex_hat_loss: 8.7924e-04 - p_or_hat_loss: 2.6347e-04 - p_ex_hat_loss: 2.5835e-04 - q_ex_hat_loss: 6.2348e-04 - q_or_hat_loss: 5.4653e-04 - v_or_hat_loss: 4.0164e-06 - v_ex_hat_loss: 5.5311e-06 - load_v_hat_loss: 6.1213e-05 - prod_q_hat_loss: 1.9444e-04 - theta_or_hat_loss: 1.4658e-04 - theta_ex_hat_loss: 1.5720e-04 - val_loss: 0.0049 - val_a_or_hat_loss: 0.0010 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.2651e-04 - val_p_ex_hat_loss: 2.9956e-04 - val_q_ex_hat_loss: 8.1175e-04 - val_q_or_hat_loss: 6.2629e-04 - val_v_or_hat_loss: 3.6007e-06 - val_v_ex_hat_loss: 4.7076e-06 - val_load_v_hat_loss: 5.7051e-05 - val_prod_q_hat_loss: 2.7114e-04 - val_theta_or_hat_loss: 1.8957e-04 - val_theta_ex_hat_loss: 2.0530e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0040 - a_or_hat_loss: 7.7099e-04 - a_ex_hat_loss: 8.8339e-04 - p_or_hat_loss: 2.7493e-04 - p_ex_hat_loss: 2.6422e-04 - q_ex_hat_loss: 6.3030e-04 - q_or_hat_loss: 5.5412e-04 - v_or_hat_loss: 4.0005e-06 - v_ex_hat_loss: 5.4085e-06 - load_v_hat_loss: 6.4826e-05 - prod_q_hat_loss: 1.9266e-04 - theta_or_hat_loss: 1.5687e-04 - theta_ex_hat_loss: 1.6754e-04 - val_loss: 0.0050 - val_a_or_hat_loss: 9.7818e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.8464e-04 - val_p_ex_hat_loss: 3.5477e-04 - val_q_ex_hat_loss: 7.5015e-04 - val_q_or_hat_loss: 6.2938e-04 - val_v_or_hat_loss: 2.3835e-06 - val_v_ex_hat_loss: 3.6596e-06 - val_load_v_hat_loss: 7.5233e-05 - val_prod_q_hat_loss: 3.0625e-04 - val_theta_or_hat_loss: 1.8245e-04 - val_theta_ex_hat_loss: 2.3072e-04\n",
      "Epoch 197/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0039 - a_or_hat_loss: 7.6797e-04 - a_ex_hat_loss: 8.6958e-04 - p_or_hat_loss: 2.6605e-04 - p_ex_hat_loss: 2.5185e-04 - q_ex_hat_loss: 6.2196e-04 - q_or_hat_loss: 5.3593e-04 - v_or_hat_loss: 3.6370e-06 - v_ex_hat_loss: 5.1757e-06 - load_v_hat_loss: 6.1113e-05 - prod_q_hat_loss: 1.8542e-04 - theta_or_hat_loss: 1.5364e-04 - theta_ex_hat_loss: 1.5812e-04 - val_loss: 0.0060 - val_a_or_hat_loss: 0.0010 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 4.1442e-04 - val_p_ex_hat_loss: 3.8940e-04 - val_q_ex_hat_loss: 8.4512e-04 - val_q_or_hat_loss: 7.6174e-04 - val_v_or_hat_loss: 5.9297e-06 - val_v_ex_hat_loss: 7.6567e-06 - val_load_v_hat_loss: 1.1954e-04 - val_prod_q_hat_loss: 2.8535e-04 - val_theta_or_hat_loss: 3.6660e-04 - val_theta_ex_hat_loss: 5.0862e-04\n",
      "Epoch 198/200\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0042 - a_or_hat_loss: 7.8835e-04 - a_ex_hat_loss: 9.0237e-04 - p_or_hat_loss: 3.1185e-04 - p_ex_hat_loss: 3.0023e-04 - q_ex_hat_loss: 6.8325e-04 - q_or_hat_loss: 5.8462e-04 - v_or_hat_loss: 5.9714e-06 - v_ex_hat_loss: 7.3854e-06 - load_v_hat_loss: 7.0039e-05 - prod_q_hat_loss: 2.0722e-04 - theta_or_hat_loss: 1.7120e-04 - theta_ex_hat_loss: 1.8128e-04 - val_loss: 0.0048 - val_a_or_hat_loss: 9.4205e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 3.7686e-04 - val_p_ex_hat_loss: 3.3590e-04 - val_q_ex_hat_loss: 7.2245e-04 - val_q_or_hat_loss: 6.3199e-04 - val_v_or_hat_loss: 2.5523e-06 - val_v_ex_hat_loss: 4.0298e-06 - val_load_v_hat_loss: 6.8370e-05 - val_prod_q_hat_loss: 2.2634e-04 - val_theta_or_hat_loss: 1.6589e-04 - val_theta_ex_hat_loss: 1.7202e-04\n",
      "Epoch 199/200\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0038 - a_or_hat_loss: 7.5242e-04 - a_ex_hat_loss: 8.6592e-04 - p_or_hat_loss: 2.5027e-04 - p_ex_hat_loss: 2.3790e-04 - q_ex_hat_loss: 6.1202e-04 - q_or_hat_loss: 5.3336e-04 - v_or_hat_loss: 3.3996e-06 - v_ex_hat_loss: 4.9211e-06 - load_v_hat_loss: 5.8701e-05 - prod_q_hat_loss: 1.7966e-04 - theta_or_hat_loss: 1.4722e-04 - theta_ex_hat_loss: 1.5423e-04 - val_loss: 0.0053 - val_a_or_hat_loss: 9.9428e-04 - val_a_ex_hat_loss: 0.0012 - val_p_or_hat_loss: 3.1539e-04 - val_p_ex_hat_loss: 3.4061e-04 - val_q_ex_hat_loss: 8.1711e-04 - val_q_or_hat_loss: 6.8989e-04 - val_v_or_hat_loss: 2.5380e-06 - val_v_ex_hat_loss: 3.9813e-06 - val_load_v_hat_loss: 7.6552e-05 - val_prod_q_hat_loss: 3.3187e-04 - val_theta_or_hat_loss: 2.3241e-04 - val_theta_ex_hat_loss: 2.4818e-04\n",
      "Epoch 200/200\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0039 - a_or_hat_loss: 7.5954e-04 - a_ex_hat_loss: 8.6887e-04 - p_or_hat_loss: 2.6162e-04 - p_ex_hat_loss: 2.4912e-04 - q_ex_hat_loss: 6.2171e-04 - q_or_hat_loss: 5.4524e-04 - v_or_hat_loss: 3.6122e-06 - v_ex_hat_loss: 5.0186e-06 - load_v_hat_loss: 6.0323e-05 - prod_q_hat_loss: 1.8753e-04 - theta_or_hat_loss: 1.5417e-04 - theta_ex_hat_loss: 1.5982e-04 - val_loss: 0.0048 - val_a_or_hat_loss: 9.1053e-04 - val_a_ex_hat_loss: 0.0011 - val_p_or_hat_loss: 2.9307e-04 - val_p_ex_hat_loss: 2.7017e-04 - val_q_ex_hat_loss: 8.4541e-04 - val_q_or_hat_loss: 6.2583e-04 - val_v_or_hat_loss: 2.0131e-06 - val_v_ex_hat_loss: 3.0926e-06 - val_load_v_hat_loss: 1.1903e-04 - val_prod_q_hat_loss: 2.3535e-04 - val_theta_or_hat_loss: 1.8514e-04 - val_theta_ex_hat_loss: 1.9314e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b590950040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leapNet.train(nb_iter=200,\n",
    "              train_dataset=neurips_benchmark3.train_dataset,\n",
    "              val_dataset=neurips_benchmark3.val_dataset\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39d0e9",
   "metadata": {},
   "source": [
    "save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4aba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leapNet.save(path_save)\n",
    "leapNet.save_metadata(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bc4e3",
   "metadata": {},
   "source": [
    "load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2dc484",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trained_models = os.path.join(\"trained_models\")\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lips.augmented_simulators import LeapNetAS\n",
    "\n",
    "# recreate the baseline\n",
    "leapNet = LeapNetAS(name=\"test_leapNetAS_benchmark3\",\n",
    "                    attr_x=(\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    attr_y=(\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"q_ex\", \"q_or\", \"v_or\", \"v_ex\", \"theta_or\", \"theta_ex\"),\n",
    "                    lr=3e-4, \n",
    "                    layer=Dense,\n",
    "                    layer_act=\"relu\",\n",
    "                    loss=\"mse\",  # loss used to train the model\n",
    "                    batch_size=128,\n",
    "                    topo_vect_to_tau=\"all\")\n",
    "# TODO create a wrapper for these 3 calls\n",
    "leapNet.load_metadata(path_trained_models)\n",
    "leapNet.init()\n",
    "leapNet.restore(path_trained_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea7989",
   "metadata": {},
   "source": [
    "# Evaluate it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2371fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A log file including some verifications is created at root directory with the name logs.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:33: UserWarning: There were some Nan in the pp_net.trafo[\"tap_neutral\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_neutral\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:41: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_percent\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_percent\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\milad.leyli-abadi\\Anaconda3\\envs\\RTE\\lib\\site-packages\\lightsim2grid\\_aux_add_trafo.py:46: UserWarning: There were some Nan in the pp_net.trafo[\"tap_pos\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_pos\\\"], they have been replaced by 0\")\n"
     ]
    }
   ],
   "source": [
    "leapNet_metrics_per_dataset = neurips_benchmark3.evaluate_augmented_simulator(leapNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450f275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val', 'test', 'test_ood_topo'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_benchmark3.predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f19e5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"predictions_LeapNet_test\", neurips_benchmark3.predictions[\"test\"])\n",
    "np.save(\"predictions_LeapNet_test_ood\", neurips_benchmark3.predictions[\"test_ood_topo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73c7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_file = open(\"ref_obs_ood.pkl\", \"wb\")\n",
    "pickle.dump(neurips_benchmark3._test_ood_topo_dataset.data, a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"predictions_LeapNet_test.pkl\", \"wb\")\n",
    "pickle.dump(neurips_benchmark3.predictions[\"test\"], a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"predictions_LeapNet_test_ood.pkl\", \"wb\")\n",
    "pickle.dump(neurips_benchmark3.predictions[\"test_ood_topo\"], a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948867b",
   "metadata": {},
   "source": [
    "### ML Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc6d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90\n",
      "{'a_ex': 0.007627280422307372,\n",
      " 'a_or': 0.008161371365289707,\n",
      " 'p_ex': 0.0070716083679348615,\n",
      " 'p_or': 0.006713402995507482,\n",
      " 'q_ex': 0.01872287409967809,\n",
      " 'q_or': 0.026856733574902935,\n",
      " 'theta_ex': 0.008855646218386186,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.0027800687775338343,\n",
      " 'v_or': 0.0027032407203839343}\n",
      "MAPE\n",
      "{'a_ex': 0.019798308458008926,\n",
      " 'a_or': 0.020379822565709783,\n",
      " 'p_ex': 0.01460759526570545,\n",
      " 'p_or': 0.013359139042767925,\n",
      " 'q_ex': 0.02137782497860824,\n",
      " 'q_or': 0.021455024094834484,\n",
      " 'theta_ex': 0.008508733215873797,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.0024370175344503144,\n",
      " 'v_or': 0.0023524734635076232}\n",
      "MAE\n",
      "{'a_ex': 3.9130992889404297,\n",
      " 'a_or': 2.7250747680664062,\n",
      " 'p_ex': 0.16841043531894684,\n",
      " 'p_or': 0.15682396292686462,\n",
      " 'q_ex': 0.10360975563526154,\n",
      " 'q_or': 0.1071694865822792,\n",
      " 'theta_ex': 0.0641272084852525,\n",
      " 'theta_or': 0.05289448516613774,\n",
      " 'v_ex': 0.14341893792152405,\n",
      " 'v_or': 0.1785714030265808}\n",
      "NRMSE\n",
      "{'a_ex': 0.004338228143751621,\n",
      " 'a_or': 0.004624119959771633,\n",
      " 'p_ex': 0.0026287524960935116,\n",
      " 'p_or': 0.002425617538392544,\n",
      " 'q_ex': 0.0037089355755597353,\n",
      " 'q_or': 0.004632395692169666,\n",
      " 'theta_ex': 0.002095972474541331,\n",
      " 'theta_or': 0.0016134345684847128,\n",
      " 'v_ex': 0.004186670761555433,\n",
      " 'v_or': 0.004654895979911089}\n"
     ]
    }
   ],
   "source": [
    "ML_metrics = 0\n",
    "print(\"MAPE90\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][ML_metrics][\"mape90\"])\n",
    "print(\"MAPE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][ML_metrics][\"mape_avg\"])\n",
    "print(\"MAE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][ML_metrics][\"MAE_avg\"])\n",
    "print(\"NRMSE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][ML_metrics][\"NRMSE_avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daacfdc",
   "metadata": {},
   "source": [
    "### OOD Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38ce6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE90\n",
      "{'a_ex': 0.13353149307680554,\n",
      " 'a_or': 0.1362641806290948,\n",
      " 'p_ex': 0.1498188134163031,\n",
      " 'p_or': 0.13974530298697216,\n",
      " 'q_ex': 0.23166653743605742,\n",
      " 'q_or': 0.26613770426753536,\n",
      " 'theta_ex': 0.10928676934889206,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.016116134482477444,\n",
      " 'v_or': 0.015510716400258287}\n",
      "MAPE\n",
      "{'a_ex': 0.16660052068382186,\n",
      " 'a_or': 0.16457392740735016,\n",
      " 'p_ex': 0.17867681365282212,\n",
      " 'p_or': 0.16137577897119917,\n",
      " 'q_ex': 0.18446503347992374,\n",
      " 'q_or': 0.1857152761019446,\n",
      " 'theta_ex': 0.09906898033527073,\n",
      " 'theta_or': nan,\n",
      " 'v_ex': 0.010273143069932756,\n",
      " 'v_or': 0.010370839340545229}\n",
      "MAE\n",
      "{'a_ex': 44.475318908691406,\n",
      " 'a_or': 31.157516479492188,\n",
      " 'p_ex': 2.0687756538391113,\n",
      " 'p_or': 1.895237684249878,\n",
      " 'q_ex': 0.9647682309150696,\n",
      " 'q_or': 0.9432681202888489,\n",
      " 'theta_ex': 1.3143264040202853,\n",
      " 'theta_or': 1.2318205872948247,\n",
      " 'v_ex': 0.5145779848098755,\n",
      " 'v_or': 0.676001787185669}\n",
      "NRMSE\n",
      "{'a_ex': 0.04387463629245758,\n",
      " 'a_or': 0.042918186634778976,\n",
      " 'p_ex': 0.032695792615413666,\n",
      " 'p_or': 0.03047908842563629,\n",
      " 'q_ex': 0.03442451357841492,\n",
      " 'q_or': 0.03568059578537941,\n",
      " 'theta_ex': 0.0356787294584036,\n",
      " 'theta_or': 0.03278467520084287,\n",
      " 'v_ex': 0.02659294381737709,\n",
      " 'v_or': 0.023121429607272148}\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE90\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"mape90\"])\n",
    "print(\"MAPE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"mape_avg\"])\n",
    "print(\"MAE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"MAE_avg\"])\n",
    "print(\"NRMSE\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][ML_metrics][\"NRMSE_avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eabce0",
   "metadata": {},
   "source": [
    "## Physics compliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb187861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pos\n",
      "0.000495\n",
      "0.0003\n",
      "voltage pos\n",
      "loss\n",
      "0.274485\n",
      "line_status\n",
      "{'a_ex_not_null': 0.0,\n",
      " 'a_or_not_null': 0.0,\n",
      " 'a_violations': 0.0,\n",
      " 'p_ex_not_null': 0.0,\n",
      " 'p_or_not_null': 0,\n",
      " 'p_violations': 0.0,\n",
      " 'q_ex_not_null': 0.0,\n",
      " 'q_or_not_null': 0.0,\n",
      " 'q_violations': 0.0}\n"
     ]
    }
   ],
   "source": [
    "PhysicCompliances = 1\n",
    "print(\"current pos\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][PhysicCompliances][\"BasicVerifications\"][\"currents\"][\"a_or\"][\"Violation_proportion\"])\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][PhysicCompliances][\"BasicVerifications\"][\"currents\"][\"a_ex\"][\"Violation_proportion\"])\n",
    "print(\"voltage pos\")\n",
    "#pprint(leapNet_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"voltages\"][\"v_or\"][\"Violation_proportion\"])\n",
    "#pprint(leapNet_metrics_per_dataset[\"test\"][1][\"BasicVerifications\"][\"voltages\"][\"v_ex\"][\"Violation_proportion\"])\n",
    "\n",
    "print(\"loss\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][PhysicCompliances][\"BasicVerifications\"][\"loss\"][\"violation_proportion\"])\n",
    "print(\"line_status\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test\"][PhysicCompliances][\"BasicVerifications\"][\"line_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bdd868",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'leapNet_metrics_per_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-929223be9b4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mleapNet_metrics_per_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"KCL_new\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'leapNet_metrics_per_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "leapNet_metrics_per_dataset[\"test\"][1][\"KCL_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9207f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pos\n",
      "0.00393\n",
      "0.004095\n",
      "voltage pos\n",
      "loss\n",
      "0.39763\n",
      "line_status\n",
      "{'a_ex_not_null': 0.0,\n",
      " 'a_or_not_null': 0.0,\n",
      " 'a_violations': 0.0,\n",
      " 'p_ex_not_null': 0.0,\n",
      " 'p_or_not_null': 0,\n",
      " 'p_violations': 0.0,\n",
      " 'q_ex_not_null': 0.0,\n",
      " 'q_or_not_null': 0.0,\n",
      " 'q_violations': 0.0}\n"
     ]
    }
   ],
   "source": [
    "PhysicCompliances = 1\n",
    "print(\"current pos\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][PhysicCompliances][\"BasicVerifications\"][\"currents\"][\"a_or\"][\"Violation_proportion\"])\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][PhysicCompliances][\"BasicVerifications\"][\"currents\"][\"a_ex\"][\"Violation_proportion\"])\n",
    "print(\"voltage pos\")\n",
    "#pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"voltages\"][\"v_or\"][\"Violation_proportion\"])\n",
    "#pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][1][\"BasicVerifications\"][\"voltages\"][\"v_ex\"][\"Violation_proportion\"])\n",
    "\n",
    "print(\"loss\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][PhysicCompliances][\"BasicVerifications\"][\"loss\"][\"violation_proportion\"])\n",
    "print(\"line_status\")\n",
    "pprint(leapNet_metrics_per_dataset[\"test_ood_topo\"][PhysicCompliances][\"BasicVerifications\"][\"line_status\"])\n",
    "#pprint(dc_metrics_per_dataset[\"test_ood_topo\"][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RTE",
   "language": "python",
   "name": "rte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
